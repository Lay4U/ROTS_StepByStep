<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Deep learning with long short-term memory networks for financial market predictions</title><meta name="author" content="Thomas Fischer"/><meta name="keywords" content="Finance,Statistical arbitrage,LSTM,Machine learning,Deep learning"/><meta name="description" content="European Journal of Operational Research, 270 (2017) 654-669. doi:10.1016/j.ejor.2017.11.054"/><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 .s2 { color: #0080AC; font-family:Tahoma, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s3 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 .a { color: #0080AC; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s4 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s5 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 13.5pt; }
 .s7 { color: #0080AC; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; vertical-align: 4pt; }
 .s8 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s9 { color: #0080AC; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s10 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10.5pt; }
 .s11 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s12 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s13 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s14 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 h1 { color: black; font-family:Cambria, serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 8pt; }
 .p, p { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; margin:0pt; }
 .s15 { color: #0080AC; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s16 { color: #0080AC; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s17 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: 2pt; }
 .s18 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; }
 .s19 { color: #0080AC; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s20 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: 2pt; }
 .s21 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; }
 .s22 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s23 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .h2, h2 { color: black; font-family:Cambria, serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 6pt; }
 .s24 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s25 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s26 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -2pt; }
 .s27 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s28 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s29 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt; }
 .s30 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s31 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -3pt; }
 .s32 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8.5pt; }
 .s33 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8.5pt; vertical-align: -2pt; }
 .s34 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8.5pt; }
 .s35 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s36 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8.5pt; vertical-align: 3pt; }
 .s37 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8.5pt; vertical-align: 3pt; }
 .s38 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8.5pt; vertical-align: -3pt; }
 .s39 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8.5pt; }
 .s40 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8.5pt; }
 .s41 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; vertical-align: 1pt; }
 .s42 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt; }
 .s43 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; }
 .s44 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; vertical-align: -2pt; }
 .s45 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s46 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 .s47 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s48 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: -1pt; }
 .s49 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -3pt; }
 .s50 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 4pt; }
 .s51 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 5pt; vertical-align: 2pt; }
 .s52 { color: #0080AC; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt; }
 .s53 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; vertical-align: -3pt; }
 .s54 { color: black; font-family:"Trebuchet MS", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9.5pt; vertical-align: 7pt; }
 .s55 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 1pt; }
 .s56 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8.5pt; vertical-align: -3pt; }
 .s57 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: underline; font-size: 6pt; }
 .s58 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s59 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 .s60 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s61 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -2pt; }
 .s62 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -1pt; }
 .s63 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; vertical-align: 5pt; }
 .s64 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7pt; }
 .s65 { color: black; font-family:Cambria, serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 6pt; }
 .s66 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s67 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 9pt; }
 .s68 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 7.5pt; }
 .s69 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 1.5pt; }
 .s70 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; }
 .s71 { color: black; font-family:Verdana, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s72 { color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 .s73 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6.5pt; }
 .s74 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: 2pt; }
 .s75 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: -2pt; }
 .s76 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: 2pt; }
 .s77 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: -1pt; }
 .s78 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; vertical-align: -1pt; }
 .s79 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 3pt; }
 .s80 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 1pt; }
 .s81 { color: black; font-family:"Lucida Sans Unicode", sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 4.5pt; }
 .s82 { color: #0080AC; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s83 { color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; }
 .s84 { color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 6pt; }
 li {display: block; }
 #l1 {padding-left: 0pt;counter-reset: c1 0; }
 #l1> li:before {counter-increment: c1; content: counter(c1, decimal)". "; color: black; font-family:Cambria, serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 8pt; }
 #l2 {padding-left: 0pt; }
 #l2> li:before {content: "• "; color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5.5pt; vertical-align: 1pt; }
 #l3 {padding-left: 0pt;counter-reset: c2 0; }
 #l3> li:before {counter-increment: c2; content: counter(c1, decimal)"."counter(c2, decimal)". "; color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l4 {padding-left: 0pt;counter-reset: c2 0; }
 #l4> li:before {counter-increment: c2; content: counter(c1, decimal)"."counter(c2, decimal)". "; color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l5 {padding-left: 0pt;counter-reset: c3 0; }
 #l5> li:before {counter-increment: c3; content: counter(c1, decimal)"."counter(c2, decimal)"."counter(c3, decimal)". "; color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l6 {padding-left: 0pt;counter-reset: c3 1; }
 #l6> li:before {counter-increment: c3; content: counter(c1, decimal)"."counter(c2, decimal)"."counter(c3, decimal)". "; color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l7 {padding-left: 0pt; }
 #l7> li:before {content: "• "; color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5.5pt; vertical-align: 1pt; }
 #l8 {padding-left: 0pt;counter-reset: c2 0; }
 #l8> li:before {counter-increment: c2; content: counter(c1, decimal)"."counter(c2, decimal)". "; color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l9 {padding-left: 0pt;counter-reset: c3 0; }
 #l9> li:before {counter-increment: c3; content: counter(c1, decimal)"."counter(c2, decimal)"."counter(c3, decimal)". "; color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l10 {padding-left: 0pt;counter-reset: e1 4; }
 #l10> li:before {counter-increment: e1; content: counter(e1, decimal)" "; color: black; font-style: normal; font-weight: normal; text-decoration: none; }
 #l11 {padding-left: 0pt;counter-reset: e2 1; }
 #l11> li:before {counter-increment: e2; content: counter(e1, decimal)"."counter(e2, decimal)". "; color: black; font-family:"Palatino Linotype", serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 8pt; }
 #l12 {padding-left: 0pt; }
 #l12> li:before {content: "• "; color: black; font-family:Arial, sans-serif; font-style: italic; font-weight: normal; text-decoration: none; font-size: 5.5pt; vertical-align: 1pt; }
 #l13 {padding-left: 0pt; }
 #l13> li:before {content: "– "; color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 li {display: block; }
 #l14 {padding-left: 0pt; }
 #l14> li:before {content: "– "; color: black; font-family:"Palatino Linotype", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt; }
 table, tbody {vertical-align: top; overflow: visible; }
</style></head><body><p style="text-indent: 0pt;text-align: left;"><span><img width="80" height="87" alt="Imprint logo" title="Imprint logo" src="Deep learning with long short-term memory networks for financial/Image_001.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="75" height="95" alt="Journal logo" title="Journal logo" src="Deep learning with long short-term memory networks for financial/Image_002.jpg"/></span></p><p style="text-indent: 0pt;line-height: 9pt;text-align: center;"><a href="http://www.ScienceDirect.com/" style=" color: black; font-family:Tahoma, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt;" target="_blank">Contents lists available at </a><a href="http://www.ScienceDirect.com/" class="s2" target="_blank">ScienceDirect</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s3" style="text-indent: 0pt;text-align: center;">European Journal of Operational Research</p><p style="padding-top: 12pt;text-indent: 0pt;text-align: center;"><a href="http://www.elsevier.com/locate/ejor" style=" color: black; font-family:Tahoma, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 8pt;" target="_blank">journal homepage: </a><a href="http://www.elsevier.com/locate/ejor" class="s2" target="_blank">www.elsevier.com/locate/ejor</a></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 173pt;text-indent: 0pt;text-align: left;"><a href="https://doi.org/10.1016/j.ejor.2017.11.054" class="a" target="_blank">European Journal of Operational Research 270 (2018) 654–669</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="608" height="0" alt="image" src="Deep learning with long short-term memory networks for financial/Image_003.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 3pt;text-align: left;"><span><img width="698" height="4" alt="image" src="Deep learning with long short-term memory networks for financial/Image_004.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s4" style="padding-left: 7pt;text-indent: 0pt;text-align: left;"><a name="bookmark0">Computational Intelligence and Information Management</a></p><p style="text-indent: 0pt;text-align: left;"><span><img width="37" height="37" alt="image" src="Deep learning with long short-term memory networks for financial/Image_005.png"/></span></p><p class="s5" style="padding-top: 5pt;padding-left: 7pt;text-indent: 0pt;line-height: 17pt;text-align: left;">Deep learning with long short-term memory networks for ﬁnancial market predictions</p><p style="padding-top: 8pt;padding-left: 7pt;text-indent: 0pt;text-align: left;"><a href="#bookmark27" class="s10">Thomas Fischer</a><a href="#bookmark27" class="s7">1</a><a href="#bookmark26" class="s8">,</a><a href="#bookmark26" class="s9">∗</a><a href="#bookmark27" class="s10">, Christopher Krauss</a><a href="#bookmark27" class="s7">1</a></p><p class="s11" style="padding-top: 5pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">Department of Statistics and Econometrics, University of Erlangen-Nürnberg, Lange Gasse 20, 90403 Nürnberg, Germany</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="694" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_006.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s12" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">a r t i c l e    i n f o</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="179" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_007.png"/></span></p><p class="s11" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Article history:</p><p class="s13" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Received 12 May 2017</p><p class="s13" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Accepted 27 November 2017</p><p class="s13" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Available online 5 December 2017</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="179" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_008.png"/></span></p><p class="s11" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">Keywords:</p><p class="s13" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Finance</p><p class="s13" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Statistical arbitrage LSTM</p><p class="s13" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Machine learning Deep learning</p><p class="s12" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: justify;">a b s t r a c t</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="475" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_009.png"/></span></p><p class="s14" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: justify;">Long short-term memory (LSTM) networks are a state-of-the-art technique for sequence learning. They are less commonly applied to ﬁnancial time series predictions, yet inherently suitable for this domain. We deploy LSTM networks for predicting out-of-sample directional movements for the constituent stocks of the S&amp;P 500 from 1992 until 2015. With daily returns of 0.46 percent and a Sharpe ratio of 5.8 prior to transaction costs, we ﬁnd LSTM networks to outperform memory-free classiﬁcation methods, i.e., a ran- dom forest (RAF), a deep neural net (DNN), and a logistic regression classiﬁer (LOG). The outperformance relative to the general market  is  very  clear  from  1992  to  2009,  but  as  of  2010,  excess  returns  seem  to have been arbitraged away with LSTM proﬁtability ﬂuctuating around zero after transaction costs. We further unveil sources of proﬁtability, thereby shedding light into the black box of artiﬁcial neural net- works. Speciﬁcally, we ﬁnd one common  pattern  among  the  stocks  selected  for  trading  –  they  exhibit high volatility and a short-term reversal return proﬁle. Leveraging these ﬁndings, we are able to formal- ize a rules-based short-term reversal strategy that yields 0.23 percent prior to transaction costs. Further regression analysis unveils  low exposure  of the  LSTM returns  to common sources  of  systematic risk  – also compared to the three benchmark models.</p><p class="s14" style="padding-top: 3pt;text-indent: 0pt;text-align: right;">© 2017 Elsevier B.V. All rights reserved.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="694" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_010.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l1"><li style="padding-top: 3pt;padding-left: 17pt;text-indent: -10pt;text-align: left;"><h1 style="display: inline;"><a name="bookmark1">Introduction</a></h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 7pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark96" class="s22">Prediction tasks on ﬁnancial time series are notoriously diﬃ- cult, primarily driven by the high degree of noise and the gener- ally accepted, semi-strong form of market eﬃciency (</a><a href="#bookmark96" class="s15">Fama, </a>1970<a href="#bookmark66" class="s22">). Yet, there is a plethora of well-known capital market anomalies that are in stark contrast with the notion of market eﬃciency. For example, </a><a href="#bookmark66" class="s15">Jacobs </a>(2015) <a href="#bookmark122" class="s22">or </a><a href="#bookmark122" class="s15">Green, Hand, and Zhang </a>(2013) <span style=" color: #000;">provide surveys comprising more than 100 of such capital market anoma- lies, which effectively rely on return predictive signals to outper- form the market. However, the ﬁnancial models used to establish a relationship between these return predictive signals, (the features) and future returns (the targets), are usually transparent in nature and not able to capture complex non-linear dependencies.</span></p><p class="s16" style="padding-left: 7pt;text-indent: 11pt;text-align: justify;"><a href="#bookmark64" class="s22">In the last years, initial evidence has been established that machine learning techniques are capable of identifying (non- linear) structures in ﬁnancial market data, see </a><a href="#bookmark64" class="s15">Huck (2009, </a>2010)<span style=" color: #000;">,</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="49" height="0" alt="image" src="Deep learning with long short-term memory networks for financial/Image_011.png"/></span></p><p class="s17" style="padding-left: 13pt;text-indent: 0pt;text-align: left;"><a name="bookmark26">∗  </a><span class="s18"> </span><span class="s13">Corresponding  author.</span></p><p class="s19" style="padding-top: 1pt;padding-left: 7pt;text-indent: 11pt;text-align: justify;"><a href="mailto:thomas.g.fischer@fau.de" class="s84" target="_blank" name="bookmark27">E-mail addresses: </a><a href="mailto:thomas.g.fischer@fau.de" class="a" target="_blank">thomas.g.ﬁscher@fa</a>u.de <a href="mailto:christopher.krauss@fau.de" class="s83" target="_blank">(T. Fischer), </a><a href="mailto:christopher.krauss@fau.de" class="a" target="_blank">christopher.krauss@fa</a>u.de <span style=" color: #000;">(C. Krauss).</span></p><p class="s20" style="padding-left: 7pt;text-indent: 5pt;line-height: 9pt;text-align: left;">1 <span class="s21"> </span><span class="s13">The authors have beneﬁted from many helpful discussions with Ingo Klein and three anonymous referees.</span></p><p class="s16" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><a href="#bookmark123" class="s15">Takeuchi and Lee </a><a href="#bookmark91" class="s15">(2013)</a><a href="#bookmark102" class="s22">, </a><a href="#bookmark102" class="s15">Moritz and Zimmermann </a><a href="#bookmark91" class="s15">(2014)</a><a href="#bookmark91" class="s22">, </a><a href="#bookmark67" class="s15">Dixon, </a><a href="#bookmark91" class="s15">Klabjan, and Bang (2015)</a><a href="#bookmark91" class="s22">, and further references in </a><a href="#bookmark91" class="s15">Atsalakis </a><a href="#bookmark118" class="s15">and </a><a href="#bookmark67" class="s15">Valavanis (2009) </a><a href="#bookmark67" class="s22">as well as </a><a href="#bookmark67" class="s15">Sermpinis, Theoﬁlatos, Kar</a><a href="#bookmark118" class="s15">athana- sopoulos, Georgopoulos, and Dunis (2013)</a><a href="#bookmark118" class="s22">. Speciﬁcally, we ex</a><a href="#bookmark81" class="s22">pand on the recent work of </a><a href="#bookmark81" class="s15">Krauss, Do, and Huck </a>(2017) <a href="#bookmark87" class="s22">on the same data sample for the sake of comparability. The authors use deep learning, random forests, gradient-boosted trees, and different en- sembles as forecasting methods on all S&amp;P 500 constituents from 1992 to 2015. One key ﬁnding is that deep neural networks with returns of 0.33 percent per day prior to transaction costs underper- form gradient-boosted trees with 0.37 percent and random forests with 0.43 percent. The latter fact is surprising, given that deep learning has “dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains” (</a><a href="#bookmark87" class="s15">LeCun, Bengio, and Hinton, </a>2015<a href="#bookmark81" class="s22">, p. 436). At ﬁrst sight, we would expect similar improvements in the domain of time series predictions. However, </a><a href="#bookmark81" class="s15">Krauss et al. </a>(2017<span style=" color: #000;">, p. 695) point out that “neural networks are notoriously diﬃcult to train” and that it “may well be that there are conﬁgurations  in  parameter space to further improve the performance” of deep learning.</span></p><p style="padding-left: 6pt;text-indent: 11pt;text-align: justify;">In this paper, we primarily focus on deep learning, and on fur- ther exploring its potential in a large-scale time series prediction problem. In this respect, we make three contributions to the liter- ature.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;text-align: left;"><a href="https://doi.org/10.1016/j.ejor.2017.11.054" class="a" target="_blank">https://doi.org/10.1016/j.ejor.2017.11.054</a></p><p class="s13" style="padding-left: 7pt;text-indent: 0pt;text-align: left;">0377-2217/© 2017 Elsevier B.V. All rights reserved.</p><ul id="l2"><li style="padding-top: 1pt;padding-left: 13pt;text-indent: -8pt;line-height: 11pt;text-align: justify;"><p class="s16" style="display: inline;"><a href="#bookmark116" class="s22" name="bookmark2">First, we focus on long short-term memory (LSTM) networks, one of the most advanced deep learning architectures for se- quence learning tasks, such as handwriting recognition, speech recognition, or time series prediction (</a><a href="#bookmark116" class="s15">Graves et al., 2009; Graves, Mohamed, &amp; Hinton, 2013; Hochreiter &amp; Schmidhuber, 1997; Schmidhuber, 2015</a><a href="#bookmark116" class="s22">). Surprisingly, to our knowledge, </a><a href="#bookmark128" class="s22">there has been  no previous  attempt to  deploy  LSTM networks  on a large, liquid, and survivor bias free stock universe to assess its performance in large-scale ﬁnancial market prediction tasks. Selected applications, as in </a><a href="#bookmark128" class="s15">Xiong, Nichols, and Shen </a>(2015)<a href="#bookmark108" class="s22">, fo- cus on predicting the volatility of the S&amp;P 500, on forecasting a small sample of foreign exchange rates (</a><a href="#bookmark108" class="s15">Giles, Lawrence, &amp; Tsoi, 2001</a><a href="#bookmark108" class="s22">), or on assessing the impact of incorporating new</a><a href="#bookmark120" class="s22">s for speciﬁc companies (</a><a href="#bookmark120" class="s15">Siah and Myers </a>(2016)<span style=" color: #000;">).  We  ﬁll  this void and apply LSTM networks to all S&amp;P  500  constituents from 1992 until 2015. Hereby, we provide an in-depth guide on data preprocessing, as well as development, training, and de- ployment of LSTM networks for ﬁnancial time series prediction tasks. Last but not least, we contrast our ﬁndings to selected benchmarks from the literature – a random forest (the best performing benchmark), a standard deep neural net (to show the value-add of the LSTM architecture), and a standard logis- tic regression (to establish a baseline). The LSTM network out- performs the memory-free methods with statistically and eco- nomically signiﬁcant returns of 0.46 percent per day – com- pared to 0.43 percent for the RAF, 0.32 percent for the stan- dard DNN, and 0.26 percent for the logistic regression. This rel- ative advantage also holds true with regard to predictional ac- curacy where a Diebold–Mariano test conﬁrms superior fore- casts of the LSTM networks compared to the applied bench- marks. Our ﬁndings are largely robust to microstructural effects. Speciﬁcally, when we implement the LSTM strategy on volume- weighted-average-prices (VWAPs) instead of closing prices, we see a decline in proﬁtability, but the results are still statistically and economically signiﬁcant. The same holds true for a weekly implementation with lower turnover – even after introducing a one-day-waiting rule after the signal. Only as of  2010,  the edge of the LSTM seems to have been arbitraged away, with LSTM proﬁtability ﬂuctuating around zero after transaction costs, and RAF proﬁtability dipping strictly into the negative domain.</span><a name="bookmark3">&zwnj;</a><a name="bookmark4">&zwnj;</a><a name="bookmark28">&zwnj;</a></p></li><li style="padding-left: 13pt;text-indent: -8pt;text-align: justify;"><p style="display: inline;">Second, we aim at shedding light into the black box of artiﬁ- cial neural networks – thereby unveiling sources of proﬁtability. Generally, we ﬁnd that stocks selected for trading exhibit high volatility, below-mean momentum, extremal directional move- ments in the last days prior to trading, and a tendency for re- versing these extremal movements in the near-term future.</p></li><li style="padding-left: 13pt;text-indent: -8pt;text-align: justify;"><p style="display: inline;">Third, we synthesize the ﬁndings of the latter part into a sim- pliﬁed, rules-based trading strategy that aims at capturing the</p></li></ul><p style="padding-top: 1pt;padding-left: 17pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">quintessence of the patterns the LSTM acts upon for selecting winning and losing stocks. A strategy that buys short-term ex- tremal losers and sells short-term extremal winners leads  to daily returns of 0.23 percent prior to transaction costs – so only about 50 percent of the LSTM returns. Regression analyses on systematic risk factors unveil a remaining alpha of 0.42 percent of the LSTM prior to transaction costs and generally lower ex- posure to common sources of systematic risk, compared to the benchmark models.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark28" class="s22">The remainder of this  paper  is  organized  as  follows. </a><a href="#bookmark28" class="s15">Section </a>2 <a href="#bookmark31" class="s22">brieﬂy covers the data  sample,  software  packages, and hardware. </a><a href="#bookmark31" class="s15">Section </a>3 <a href="#bookmark44" class="s22">provides an in-depth discussion of our methodology, i.e., the generation of training and trading sets, the construction of input sequences, the model architecture and train- ing as well as the forecasting and trading steps. </a><a href="#bookmark44" class="s15">Section </a>4 <a href="#bookmark62" class="s22">presents the results and discusses our most relevant ﬁndings in light of the existing literature. Finally, </a><a href="#bookmark62" class="s15">Section </a>5 <span style=" color: #000;">concludes.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 15pt;text-indent: -10pt;text-align: justify;"><h1 style="display: inline;">Data, software, hardware</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l3"><li style="padding-left: 20pt;text-indent: -15pt;text-align: justify;"><p class="s23" style="display: inline;">Data</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark84" class="s22">For the empirical application, we use the S&amp;P 500 index con- stituents from Thomson Reuters. For eliminating survivor bias, we ﬁrst obtain all month end constituent lists for the S&amp;P 500 from Thomson Reuters from December 1989 to September 2015. We consolidate these lists into one binary matrix, indicating whether the stock is an index constituent in the subsequent month. As such, we are able to approximately reproduce the S&amp;P 500 at any given point in time between December 1989 and September 2015. In a second step, for all stocks having ever been a constituent of the index during that time frame, we download daily total return in- dices from January 1990 until October 2015. Return indices are cum-dividend prices and account for all relevant corporate actions and stock splits, making them the most adequate metric for return computations. Following </a><a href="#bookmark84" class="s15">Clegg and Krauss </a>(2018)<a href="#bookmark29" class="s22">, we report aver- age summary statistics in </a><a href="#bookmark29" class="s15">Table </a>1<span style=" color: #000;">, split by industry sector. They are based on equal-weighted portfolios per sector, generated monthly, and constrained to index constituency of the S&amp;P 500.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-top: 6pt;padding-left: 21pt;text-indent: -16pt;text-align: justify;"><p class="s23" style="display: inline;">Software and hardware</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 17pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">Data preparation and  handling is  entirely conducted in  Python</p><p class="s16" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a href="#bookmark110" class="s22">3.5 (</a><a href="#bookmark110" class="s15">Python Software Foundation, </a>2016<a href="#bookmark126" class="s22">), relying on the packages numpy (</a><a href="#bookmark126" class="s15">Van Der Walt, Colbert, &amp; Varoquaux, </a>2011<a href="#bookmark99" class="s22">) and pandas (</a><a href="#bookmark99" class="s15">McKinney, </a>2010<a href="#bookmark85" class="s22">). Our deep learning LSTM networks are  devel- oped  with  keras  (</a><a href="#bookmark85" class="s15">Chollet,  </a>2016<span style=" color: #000;">)  on  top  of  Google  TensorFlow,  a</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 4pt;padding-left: 102pt;text-indent: 0pt;text-align: justify;"><a name="bookmark29">Table 1</a></h2><p class="s13" style="padding-left: 102pt;text-indent: 0pt;text-align: justify;">Average monthly summary statistics for S&amp;P 500 constituents from January 1990 until October 2015, split by industry. They are based on equal-weighted portfolios per industry as deﬁned by the Global Industry Classiﬁcation Standards Code, formed on a monthly basis, and restricted to index constituency of the S&amp;P</p><p class="s13" style="padding-left: 102pt;text-indent: 0pt;text-align: justify;">500. Monthly returns and standard deviations are denoted in percent.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:102.426pt" cellspacing="0"><tr style="height:14pt"><td style="width:73pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Industry</p></td><td style="width:50pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">No. of stocks</p></td><td style="width:49pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Mean return</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Standard deviation</p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Skewness</p></td><td style="width:36pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Kurtosis</p></td></tr><tr style="height:13pt"><td style="width:73pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">Industrials</p></td><td style="width:50pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">80.6</p></td><td style="width:49pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">0.99</p></td><td style="width:69pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">5.36</p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt"><p class="s25" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.19</span></p></td><td style="width:36pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">1.71</p></td></tr><tr style="height:9pt"><td style="width:73pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Consumer services</p></td><td style="width:50pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">72.6</p></td><td style="width:49pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1.07</p></td><td style="width:69pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">5.27</p></td><td style="width:40pt"><p class="s25" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.20</span></p></td><td style="width:36pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">2.59</p></td></tr><tr style="height:9pt"><td style="width:73pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Basic materials</p></td><td style="width:50pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">35.2</p></td><td style="width:49pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.90</p></td><td style="width:69pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">6.31</p></td><td style="width:40pt"><p class="s25" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.02</span></p></td><td style="width:36pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">2.24</p></td></tr><tr style="height:8pt"><td style="width:73pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Telecommunications</p></td><td style="width:50pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">10.7</p></td><td style="width:49pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.92</p></td><td style="width:69pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">6.50</p></td><td style="width:40pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.34</p></td><td style="width:36pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">4.76</p></td></tr><tr style="height:10pt"><td style="width:73pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Health care</p></td><td style="width:50pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">41.3</p></td><td style="width:49pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.33</p></td><td style="width:69pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">4.40</p></td><td style="width:40pt"><p class="s25" style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.40</span></p></td><td style="width:36pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.18</p></td></tr><tr style="height:9pt"><td style="width:73pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Technology</p></td><td style="width:50pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">50.3</p></td><td style="width:49pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1.41</p></td><td style="width:69pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">8.50</p></td><td style="width:40pt"><p class="s25" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.06</span></p></td><td style="width:36pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1.11</p></td></tr><tr style="height:9pt"><td style="width:73pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Financials</p></td><td style="width:50pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">78.0</p></td><td style="width:49pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1.13</p></td><td style="width:69pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">6.17</p></td><td style="width:40pt"><p class="s25" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.39</span></p></td><td style="width:36pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">2.44</p></td></tr><tr style="height:9pt"><td style="width:73pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Consumer  goods</p></td><td style="width:50pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">65.2</p></td><td style="width:49pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1.04</p></td><td style="width:69pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">4.53</p></td><td style="width:40pt"><p class="s25" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.44</span></p></td><td style="width:36pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">3.02</p></td></tr><tr style="height:9pt"><td style="width:73pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Oil and gas</p></td><td style="width:50pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">31.2</p></td><td style="width:49pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1.00</p></td><td style="width:69pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">6.89</p></td><td style="width:40pt"><p class="s25" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.03</span></p></td><td style="width:36pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1.06</p></td></tr><tr style="height:11pt"><td style="width:73pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Utilities</p></td><td style="width:50pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">34.6</p></td><td style="width:49pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.85</p></td><td style="width:69pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">4.54</p></td><td style="width:40pt"><p class="s25" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.43</span></p></td><td style="width:36pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1.72</p></td></tr><tr style="height:13pt"><td style="width:73pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">All</p></td><td style="width:50pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">499.7</p></td><td style="width:49pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">1.04</p></td><td style="width:69pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">4.78</p></td><td style="width:40pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s25" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.49</span></p></td><td style="width:36pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">2.01</p></td></tr></table><p class="s16" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><a href="#bookmark65" class="s22">powerful library for large-scale machine learning on heterogenous systems (</a><a href="#bookmark65" class="s15">Abadi et al., </a>2015<span style=" color: #000;">). Moreover, we make use of sci-kit learn</span></p><p class="s23" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="p">feature  vector  </span>V  <span class="p">of  dimension  </span>n<span class="s26">i</span><span class="s11"> </span><span class="s27">× </span>T<span class="s26">study</span><span class="p">,  where  </span>T<span class="s26">study</span><span class="s11">   </span><span class="p">denotes  the number of days in the study period. Then, we standardize the re-</span></p><p class="s16" style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><a href="#bookmark106" class="s22">(</a><a href="#bookmark106" class="s15">Pedregosa  et  al.,  </a>2011<a href="#bookmark127" class="s22">)  for  the  random  forest  and  logistic  regres- sion models and of H2O (</a><a href="#bookmark127" class="s15">H2O, </a>2016<span style=" color: #000;">) for the standard deep net. For</span></p><p class="s11" style="text-indent: 0pt;line-height: 6pt;text-align: left;">train</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;">turns by subtracting the mean (<span class="s28">μ</span><span class="s29">m</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 3pt;text-align: left;">standard deviation (<span class="s28">σ</span><span class="s29">m</span></p><p style="text-indent: 0pt;line-height: 11pt;text-align: left;">)  and  dividing  them  by  the</p><p style="padding-left: 70pt;text-indent: 0pt;line-height: 3pt;text-align: left;"><a href="#bookmark37" class="a">4</a></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">performance  evaluation,  we  revert  to  R,  a  programming  language</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s11" style="padding-left: 6pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><a name="bookmark30">m</a><span class="s30">,</span>s</p><p class="s31" style="padding-left: 6pt;text-indent: 20pt;line-height: 4pt;text-align: left;">tr<span class="s11">ain</span><span class="p">) obtained from the training set:</span></p><p class="s11" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 2pt;text-align: left;">m</p><p class="s16" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><a href="#bookmark112" class="s22">for statistical computing (</a><a href="#bookmark112" class="s15">R Core Team, </a>2016<a href="#bookmark109" class="s22">) and the package Per- formanceAnalytics by </a><a href="#bookmark109" class="s15">Peterson and Carl </a>(2014)<span style=" color: #000;">. The LSTM network</span></p><p class="s32" style="text-indent: 0pt;line-height: 8pt;text-align: left;">R</p><p style="text-indent: 0pt;text-align: left;"/><p class="s11" style="padding-top: 3pt;padding-left: 7pt;text-indent: 0pt;line-height: 6pt;text-align: left;"><span class="s33">˜</span>m<span class="s30">,</span>s</p><p class="s26" style="padding-left: 10pt;text-indent: 0pt;line-height: 9pt;text-align: left;">t     <span class="s11"> </span><span class="s34">=</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="62" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_012.png"/></span></p><p class="s35" style="text-indent: 0pt;line-height: 10pt;text-align: left;">σ</p><p style="text-indent: 0pt;text-align: left;"/><p class="s11" style="text-indent: 0pt;line-height: 6pt;text-align: left;">m</p><p style="text-indent: 0pt;text-align: left;"/><p class="s11" style="padding-left: 1pt;text-indent: 0pt;line-height: 17pt;text-align: left;"><span class="s36">R</span>t      <span class="s37">−</span><span class="s34"> </span><span class="s35">μ</span>train <span class="s38">.                                                     </span><span class="s39"> </span><span class="s40">(2)</span></p><p class="s11" style="padding-left: 20pt;text-indent: 0pt;line-height: 8pt;text-align: left;">train</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">is trained on NVIDIA GPUs, all other models are trained on a CPU</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><a name="bookmark5">cluster.</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ol></li><li style="padding-left: 16pt;text-indent: -10pt;text-align: left;"><h1 style="display: inline;"><a name="bookmark31">Methodology</a></h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 11pt;line-height: 11pt;text-align: justify;">Our methodology consists of ﬁve steps. First, we split our raw data in study periods, composed of training sets (for in-sample training) and trading sets (for out-of-sample predictions). Second,</p><p class="s11" style="text-indent: 0pt;line-height: 6pt;text-align: left;">t</p><p style="text-indent: 0pt;text-align: left;"/><p class="s11" style="text-indent: 0pt;line-height: 6pt;text-align: left;">t</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 3pt;padding-left: 6pt;text-indent: 11pt;line-height: 11pt;text-align: justify;">LSTM networks require sequences of input features for training, i.e., the values of the features at consecutive points in time. Our single feature is the standardized one-day return <i>R</i><span class="s41">˜</span><span class="s42">1</span><span class="s30">,</span><span class="s11">s</span>. We opt for a sequence length of 240, thus comprising the information of ap- proximately one trading year. Hence, we generate overlapping se- quences of 240 consecutive, standardized one-day returns <i>R</i><span class="s41">˜</span><span class="s42">1</span><span class="s30">,</span><span class="s11">s </span>in the following way: ﬁrst, we sort the feature vector <i>V </i>by stock <i>s </i>and date <i>t </i>in ascending order. Then, we construct sequences of the</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 2pt;text-align: left;">we  discuss  the  feature  space  and  targets  necessary  for  training</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 2pt;text-align: left;">form <span class="s43">{</span><i>R</i><span class="s41">˜</span><span class="s42">1</span><span class="s30">,</span><span class="s11">s</span></p><p class="s44" style="padding-left: 6pt;text-indent: 0pt;line-height: 2pt;text-align: left;">˜<span class="s13">1</span><span class="s30">,</span><span class="s11">s</span></p><p class="s44" style="padding-left: 6pt;text-indent: 0pt;line-height: 2pt;text-align: left;">˜<span class="s13">1</span><span class="s30">,</span><span class="s11">s</span></p><p style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">and making  predictions. Third,  we  provide an  in-depth discussion</p><p class="s23" style="padding-left: 6pt;text-indent: 29pt;line-height: 10pt;text-align: left;"><span class="s31">t</span><span class="s45">−</span><span class="s13">239</span><span class="s46">, </span>R<span class="s31">t</span><span class="s45">−</span><span class="s13">238</span><span class="s46">, . . . , </span>R<span class="s26">t</span><span class="s11">    </span><span class="s43">} </span><span class="p">for each stock </span>s <span class="p">and each </span>t <span class="s27">≥ </span><span class="p">240 of</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 6pt;text-align: left;">the study period. For the ﬁrst stock <i>s</i><span class="s47">1 </span><span class="s13"> </span>the sequence hence consists</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 4pt;text-align: left;">of LSTM networks. Fourth, we brieﬂy describe random forests, the</p><p class="s13" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 3pt;text-align: left;">1<span class="s30">,</span><i>s</i><span class="s48">1</span></p><p class="s13" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 3pt;text-align: left;">1<span class="s30">,</span><i>s</i><span class="s48">1</span></p><p class="s13" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 3pt;text-align: left;">1<span class="s30">,</span><i>s</i><span class="s48">1</span></p><p style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">deep net, and the logistic regression model we apply. Fifth, we de-</p><p class="s23" style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="p">of the standardized one-day returns </span><span class="s43">{</span>R<span class="s41">˜</span><span class="s49">1     </span><span class="s13"> </span><span class="s46">, </span>R<span class="s41">˜</span><span class="s49">2     </span><span class="s13"> </span><span class="s46">, . . . , </span>R<span class="s41">˜</span><span class="s49">2</span><span class="s13">40 </span><span class="s43">}</span><span class="p">. The sec-</span></p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;">velop the trading approach. The rest of this section follows the ﬁve</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;">ond sequence consists of <span class="s43">{</span><i>R</i><span class="s41">˜</span><span class="s50">1</span><span class="s30">,</span><span class="s11">s</span><span class="s51">1</span></p><p class="s13" style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;">1<span class="s30">,</span><i>s</i><span class="s48">1</span></p><p class="s13" style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;">1<span class="s30">,</span><i>s</i><span class="s48">1</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 10pt;text-align: justify;"><a name="bookmark6">step logic outlined above.</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l4"><li style="padding-left: 21pt;text-indent: -15pt;text-align: justify;"><p class="s23" style="display: inline;">Generation of training and trading sets</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 6pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark81" class="s22" name="bookmark9">Following </a><a href="#bookmark81" class="s15">Krauss et al. </a>(2017)<a href="#bookmark33" class="s22">, we deﬁne a “study period” as a training-trading set, consisting of a training period of 750 days (ap- proximately three years) and a trading period of 250 days (approxi- mately one year). We split our entire data set from 1990 until 2015 in 23 of these study periods with non-overlapping trading periods. In other words, the study periods are rolling blocks of 1000 days. Training is done with rolling windows on the ﬁrst 750 days, i.e., by rolling a look back input of 240 days (corresponding to the max- imum feature length, see </a><a href="#bookmark33" class="s15">Section </a>3.2<span style=" color: #000;">) across the block, and then predicting one day ahead. Trading is performed with the trained parameters on the last 250 days fully out-of-sample. Then, the en- tire system is rolled forward by 250 days – resulting in a total of 23 non-overlapping trading periods.</span><a name="bookmark10">&zwnj;</a><a name="bookmark32">&zwnj;</a></p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 11pt;line-height: 87%;text-align: justify;">Let <i>n</i><span class="s26">i</span><span class="s11"> </span>denote the number of stocks that are a S&amp;P 500 con- stituent at the very last day of the training period in study period <i>i</i>, so <i>n</i><span class="s26">i </span><span class="s11"> </span><a href="#bookmark35" class="s22">is very close to 500.</a><a href="#bookmark35" class="s52">2</a></p><p style="padding-left: 6pt;text-indent: 11pt;line-height: 85%;text-align: justify;">For the training set, we consider all <i>n</i><span class="s26">i</span><span class="s11"> </span>stocks with the history they have available. Some stocks exhibit a full 750 day training his-</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><a name="bookmark7">tory, some only a subset of this time frame, for example, when they are listed at a later stage. The trading set is also composed of all </a><i>n</i><span class="s26">i</span><span class="s11"> </span><a href="#bookmark36" class="s22">stocks. If a constituent exhibits no price data after a certain day within the trading period, it is considered for trading up until that day.</a><a href="#bookmark36" class="s52">3</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 22pt;text-indent: -16pt;text-align: justify;"><p class="s23" style="display: inline;"><a name="bookmark8">Feature and target generation</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l5"><li style="padding-left: 27pt;text-indent: -21pt;line-height: 10pt;text-align: justify;"><p class="s23" style="display: inline;"><a name="bookmark33">Features – return sequences for LSTM networks</a></p><p class="s49" style="padding-left: 6pt;text-indent: 105pt;line-height: 1pt;text-align: left;">2    <span class="s13"> </span><span class="s46">, </span><span class="s23">R</span><span class="s41">˜</span>3    <span class="s13"> </span><span class="s46">, . . . , </span><span class="s23">R</span><span class="s41">˜</span>2<span class="s13">41 </span><span class="s43">} </span><span class="p">and so forth. An il-</span></p><p class="s16" style="padding-left: 6pt;text-indent: 0pt;line-height: 0pt;text-align: justify;"><a href="#bookmark39" class="s22">lustration is provided in </a><a href="#bookmark39" class="s15">Fig. </a>1<span style=" color: #000;">. In total, each study period consists</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 0pt;text-align: justify;">of  approximately  380,000  of  those  sequences  of  which  approxi-</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: justify;">mately 255,000 are used for in-sample training and approximately</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a href="#bookmark38" class="s22">125,000 are used for out-of-sample predictions.</a><a href="#bookmark38" class="s52">5</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 28pt;text-indent: -22pt;line-height: 11pt;text-align: justify;"><p class="s23" style="display: inline;">Targets</p><p style="padding-left: 6pt;text-indent: 11pt;line-height: 92%;text-align: justify;"><a href="#bookmark123" class="s22">For the sake of comparability, we follow </a><a href="#bookmark123" class="s15">Takeuchi and Lee (2013) </a><a href="#bookmark123" class="s22">and deﬁne a binary classiﬁcation problem, i.e., the </a>response variable <i>Y</i><span class="s29">s</span><span class="s11">      </span>for each stock <i>s </i>and date <i>t </i>can take on two different</p><p class="s11" style="padding-left: 42pt;text-indent: 0pt;line-height: 2pt;text-align: left;">t<span class="s45">+</span><span class="s13">1</span></p><p class="s53" style="text-indent: 0pt;line-height: 10pt;text-align: left;">R<span class="s13">1</span><span class="s30">,</span><span class="s11">s</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: -4pt;line-height: 9pt;text-align: justify;">values. To deﬁne the two classes, we order all one-period returns</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 4pt;line-height: 79%;text-align: justify;"><span class="s31">t</span><span class="s45">+</span><span class="s13">1 </span>of all stocks <i>s </i>in period <i>t </i><span class="s27">+ </span>1 in ascending order and cut them into two equally sized classes. Class 0 is realized if the one-period return <i>R</i><span class="s42">1</span><span class="s30">,</span><span class="s11">s   </span>of stock <i>s </i>is smaller than the cross-sectional median re-</p><p class="s11" style="padding-left: 36pt;text-indent: 0pt;line-height: 2pt;text-align: left;">t<span class="s45">+</span><span class="s13">1</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 10pt;text-align: justify;">turn of all stocks in period <i>t </i><span class="s27">+ </span>1. Similarly, class 1 is realized if the</p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">one-period return of <i>s </i>is larger than or equal to the cross-sectional median.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ol></li><li style="padding-left: 22pt;text-indent: -16pt;text-align: justify;"><p class="s23" style="display: inline;">LSTM networks</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 6pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark104" class="s22">The description of LSTM networks follow</a><a href="#bookmark114" class="s22">s </a><a href="#bookmark114" class="s15">Graves </a><a href="#bookmark104" class="s15">(2013)</a><a href="#bookmark104" class="s22">, </a><a href="#bookmark104" class="s15">Olah (2015)</a><a href="#bookmark104" class="s22">, </a><a href="#bookmark85" class="s22">and </a><a href="#bookmark104" class="s15">Chollet (2016)</a><a href="#bookmark104" class="s22">. Valuable additional introductions can </a><a href="#bookmark78" class="s22">be found in </a><a href="#bookmark78" class="s15">Karpathy </a>(2015) <a href="#bookmark79" class="s22">and </a><a href="#bookmark79" class="s15">Britz </a>(2015)<span style=" color: #000;">, providing step-by-step graphical walkthroughs and code snippets.</span></p><p class="s16" style="padding-left: 6pt;text-indent: 11pt;text-align: justify;"><a href="#bookmark100" class="s22">LSTM networks belong to the class of recurrent neural networks (RNNs), i.e., neural networks whose “underlying topology of inter- neuronal connections contains at least one cycle” (</a><a href="#bookmark100" class="s15">Medsker, </a>2000<span style=" color: #000;">,</span></p><p style="padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a href="#bookmark130" class="s22">p. 82). They have been introduced by </a><a href="#bookmark130" class="s15">Hochreiter and Schmidhu- ber (1997) </a><a href="#bookmark130" class="s22">and were further reﬁned in the following years, e.g., </a><a href="#bookmark119" class="s22">by </a><a href="#bookmark107" class="s15">Gers, Schmidhuber, and Cummins </a><a href="#bookmark119" class="s15">(2000) </a><a href="#bookmark119" class="s22">and </a><a href="#bookmark119" class="s15">Graves and Schmid- huber (2005)</a><a href="#bookmark119" class="s22">, to name a few. LSTM networks are speciﬁcally </a>de- signed to learn long-term dependencies and are capable of over-</p><p class="s23" style="padding-left: 17pt;text-indent: 0pt;line-height: 6pt;text-align: left;"><span class="p">Let </span>P<span class="s29">s</span><span class="s11"> </span><span class="s27">= </span><span class="s54">t</span>P<span class="s29">s</span><span class="s54">)</span></p><p style="padding-left: 12pt;text-indent: 0pt;line-height: 6pt;text-align: left;">be deﬁned as the price process of stock <i>s </i>at</p><p style="padding-left: 15pt;text-indent: 0pt;line-height: 6pt;text-align: left;">coming  the  previously  inherent  problems  of  RNNs,  i.e.,  vanishing</p><p class="s11" style="padding-left: 58pt;text-indent: 0pt;line-height: 6pt;text-align: left;"><span class="s55">t </span> t<span class="s45">∈</span>T</p><p class="s11" style="text-indent: 0pt;line-height: 6pt;text-align: left;">t</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;">time <i>t</i>, with <i>s </i><span class="s27">∈ </span><span class="s43">{</span>1<span class="s46">, . . . , </span><i>n</i><span class="s26">i</span><span class="s43">} </span>and <i>R</i><span class="s29">m</span><span class="s30">,</span><span class="s11">s  </span>the simple return for a stock <i>s</i></p><p style="padding-left: 37pt;text-indent: -31pt;line-height: 10pt;text-align: left;">over <i>m </i>periods, i.e.,</p><p class="s56" style="padding-top: 2pt;text-indent: 0pt;line-height: 9pt;text-align: center;"><a name="bookmark34">P</a><span class="s11">s</span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="22" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_013.png"/></span></p><p class="s11" style="padding-left: 6pt;text-indent: 0pt;text-align: left;"><span class="s56">R</span>m<span class="s30">,</span>s             t</p><p class="s16" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><a href="#bookmark117" class="s22">and exploding gradients (</a><a href="#bookmark117" class="s15">Sak, Senior, &amp; Beaufays, </a>2014<span style=" color: #000;">).</span></p><p style="padding-left: 6pt;text-indent: 11pt;text-align: left;">LSTM networks are composed of an input layer, one or more hidden layers, and an output layer. The number of neurons in the</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 2pt;text-align: left;">input layer is equal to the number of explanatory variables (feature</p><p class="s11" style="padding-left: 10pt;text-indent: 0pt;line-height: 3pt;text-align: left;">t      <span class="s37">=</span><span class="s34"> </span><span class="s56">P</span>s</p><p class="s11" style="text-indent: 0pt;line-height: 6pt;text-align: right;">t<span class="s45">−</span>m</p><p class="s40" style="text-indent: 0pt;line-height: 1pt;text-align: left;"><span class="s34">− </span>1<span class="s39">.                                                        </span>(1)</p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 10pt;text-align: left;">space). The number of neurons in the output layer reﬂects the out-</p><p class="s53" style="text-indent: 0pt;line-height: 10pt;text-align: left;">R<span class="s13">1</span><span class="s30">,</span><span class="s11">s</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 6pt;text-indent: 0pt;line-height: 12pt;text-align: left;">For the LSTM networks, we ﬁrst calculate one-day (<i>m </i><span class="s27">= </span>1) returns</p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 12pt;text-align: left;"><span class="s26">t      </span>for each day <i>t </i>and each stock <i>s</i>, and stack them in one large</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 90%;text-align: justify;">put space, i.e., two neurons in our case indicating whether or not a stock outperforms the cross-sectional median in <i>t </i><span class="s27">+ </span>1. The main characteristic of LSTM networks is contained in the hidden layer(s)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="49" height="0" alt="image" src="Deep learning with long short-term memory networks for financial/Image_014.png"/></span></p><p class="s20" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><a name="bookmark35">2   </a><span class="s13">The S&amp;P 500 constituency count slightly ﬂuctuates around 500 over time.                       </span><span class="s57">                        </span><a name="bookmark36">&zwnj;</a><a name="bookmark37">&zwnj;</a></p><p class="s20" style="padding-left: 6pt;text-indent: 5pt;text-align: justify;"><a name="bookmark38">3</a><span class="s21"> </span><span class="s13">The reason for exhibiting no more price data is generally due to delisting. Delisting may be caused by various reasons, such as bankruptcy, mergers and ac- quisitions, etc. Note that we do not eliminate stocks during the trading period in case they drop out of the S&amp;P 500. The only criterion for being traded is that they have price information available for feature generation.</span></p><p class="s20" style="padding-left: 6pt;text-indent: 5pt;line-height: 9pt;text-align: justify;">4 <span class="s21"> </span><span class="s13">It is key to obtain mean and standard deviation from the training set only, in</span></p><p class="s13" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">order to avoid look-ahead biases.</p><p class="s20" style="padding-left: 6pt;text-indent: 5pt;text-align: justify;">5<span class="s21"> </span><span class="s13">We have 1000 days in the study period and a sequence length of 240 days. As such, 760 sequences can be created per stock. Given that there are approximately 500 stocks in the S&amp;P 500, we have a total of approximately 380,000 sequences.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 12pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="98" height="13" alt="image" src="Deep learning with long short-term memory networks for financial/Image_015.png"/></span></p><p class="s58" style="padding-left: 10pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="501" height="39" alt="image" src="Deep learning with long short-term memory networks for financial/Image_016.png"/></span> <span><img width="172" height="38" alt="image" src="Deep learning with long short-term memory networks for financial/Image_017.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="675" height="45" alt="image" src="Deep learning with long short-term memory networks for financial/Image_018.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 58pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="326" height="38" alt="image" src="Deep learning with long short-term memory networks for financial/Image_019.png"/></span>	<span><img width="79" height="16" alt="image" src="Deep learning with long short-term memory networks for financial/Image_020.png"/></span>	<span><img width="141" height="38" alt="image" src="Deep learning with long short-term memory networks for financial/Image_021.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="69" height="14" alt="image" src="Deep learning with long short-term memory networks for financial/Image_022.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="19" height="19" alt="image" src="Deep learning with long short-term memory networks for financial/Image_023.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="270" height="11" alt="image" src="Deep learning with long short-term memory networks for financial/Image_024.png"/></span></p><h2 style="padding-top: 3pt;padding-left: 85pt;text-indent: 0pt;text-align: left;"><a name="bookmark39">Fig. 1.  </a><span class="s13">Construction of input sequences for LSTM networks (both, feature vector and sequences, are shown transposed).</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 26pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="273" height="181" alt="image" src="Deep learning with long short-term memory networks for financial/Image_025.png"/></span>	<span><img width="19" height="19" alt="image" src="Deep learning with long short-term memory networks for financial/Image_026.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="61" height="14" alt="image" src="Deep learning with long short-term memory networks for financial/Image_027.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="19" height="19" alt="image" src="Deep learning with long short-term memory networks for financial/Image_028.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="71" height="14" alt="image" src="Deep learning with long short-term memory networks for financial/Image_029.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="244" height="11" alt="image" src="Deep learning with long short-term memory networks for financial/Image_030.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="297" height="11" alt="image" src="Deep learning with long short-term memory networks for financial/Image_031.png"/></span></p><p class="s19" style="padding-top: 3pt;padding-left: 144pt;text-indent: 0pt;text-align: left;"><a name="bookmark40"><span class="h2">Fig. 2.  </span></a><a href="#bookmark114" class="s83">Structure of LSTM memory cell following </a><a href="#bookmark114" class="a">Graves </a>(2013) <a href="#bookmark104" class="s83">and </a><a href="#bookmark104" class="a">Olah </a>(2015)<span style=" color: #000;">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">consisting of so called memory cells. Each of the memory cells has three gates maintaining and adjusting its cell state <i>s</i><span class="s60">t</span>: a forget gate (<i>f</i><span class="s60">t</span>), an input gate (<i>i</i><span class="s60">t</span>), and an output gate (<i>o</i><span class="s60">t</span><a href="#bookmark40" class="s22">). The structure of a memory cell is illustrated in </a><a href="#bookmark40" class="s15">Fig. </a><span style=" color: #0080AC;">2</span>.</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;">At every timestep <i>t</i>, each of the three gates is presented with the input <i>x</i><span class="s60">t</span><span class="s11"> </span>(one element of the input sequence) as well as the output <i>h</i><span class="s60">t</span><span class="s45">−</span><span class="s13">1 </span>of the memory cells at the previous timestep <i>t </i><span class="s27">− </span>1. Hereby, the gates act as ﬁlters, each fulﬁlling a different purpose:</p><ol id="l6"><ul id="l7"><li style="padding-top: 4pt;padding-left: 18pt;text-indent: -8pt;text-align: justify;"><p style="display: inline;">The forget gate deﬁnes which information is removed from the</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">into the  range between  0 (completely  forget) and  1  (completely remember):</p><p class="s32" style="padding-top: 4pt;padding-left: 5pt;text-indent: 1pt;text-align: justify;">f<span class="s60">t  </span><span class="s34">= </span>sigmoid<span class="s28">(</span>W<span class="s26">f</span><span class="s30">,</span><span class="s11">x </span>x<span class="s60">t</span><span class="s11"> </span><span class="s34">+ </span>W<span class="s26">f</span><span class="s30">,</span><span class="s11">h</span>h<span class="s60">t</span><span class="s45">−</span><span class="s13">1 </span><span class="s34">+ </span>b<span class="s26">f</span><span class="s11"> </span><span class="s28">)</span><span class="s39">.                              </span><span class="s40">(3)</span></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">In the second step, the LSTM layer determines which information should be added to the network’s cell states (<i>s</i><span class="s60">t</span>). This procedure comprises two operations: ﬁrst, candidate values <i>s</i>˜<span class="s60">t</span><span class="s11"> </span><span class="s46">, </span>that could po- tentially be added to the cell states, are computed. Second, the ac- tivation values <i>i</i><span class="s60">t </span><span class="s11"> </span>of the input gates are calculated:</p><p style="padding-left: 18pt;text-indent: 0pt;line-height: 10pt;text-align: left;">cell state.</p></li><li style="padding-left: 18pt;text-indent: -8pt;text-align: left;"><p style="display: inline;">The input gate speciﬁes which information is added to the cell state.</p><p class="s32" style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">s<span class="s40">˜</span><span class="s60">t </span><span class="s11"> </span><span class="s34">= </span><span class="s40">tanh</span><span class="s28">(</span>W<span class="s60">s</span><span class="s13">˜</span><span class="s30">,</span><span class="s11">x</span>x<span class="s60">t </span><span class="s11"> </span><span class="s34">+ </span>W<span class="s26">s</span><span class="s47">˜</span><span class="s61">,</span><span class="s11">h</span>h<span class="s60">t</span></p><p class="s13" style="padding-top: 1pt;text-indent: 0pt;text-align: left;"><span class="s62">−</span>1 <span class="s34">+ </span><span class="s32">b</span><i>s</i>˜<span class="s28">)</span><span class="s39">,                                     </span><span class="s40">(4)</span></p></li><li style="padding-left: 18pt;text-indent: -8pt;text-align: left;"><p style="display: inline;">The output gate speciﬁes which information from the cell state is used as output.</p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">The equations below are vectorized and describe the update of the memory cells in the LSTM layer at every timestep <i>t</i>. Hereby, the following notation is used:</p></li><li style="padding-top: 4pt;padding-left: 18pt;text-indent: -8pt;line-height: 11pt;text-align: left;"><p class="s23" style="display: inline;">x<span class="s60">t </span><span class="s11"> </span><span class="p">is the input vector at timestep </span>t<span class="p">.</span></p></li><li style="padding-left: 18pt;text-indent: -8pt;line-height: 85%;text-align: left;"><p class="s23" style="display: inline;">W<span class="s26">f</span><span class="s13">, </span><span class="s11">x</span><span class="p">, </span>W<span class="s26">f</span><span class="s13">,</span><span class="s11">h</span><span class="p">, </span>W<span class="s26">s</span><span class="s13">˜</span><span class="s30">,</span><span class="s11">x</span><span class="s46">, </span>W<span class="s26">s</span><span class="s13">˜</span><span class="s30">,</span><span class="s11">h</span><span class="s46">, </span>W<span class="s26">i</span><span class="s13">, </span><span class="s11">x</span><span class="p">, </span>W<span class="s26">i</span><span class="s13">,</span><span class="s11">h</span><span class="p">, </span>W<span class="s60">o</span><span class="s13">, </span><span class="s11">x</span><span class="p">, and </span>W<span class="s26">o</span><span class="s13">,</span><span class="s11">h  </span><span class="p">are weight ma- trices.</span></p><p class="s32" style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">i<span class="s60">t</span><span class="s11">  </span><span class="s34">= </span>sigmoid<span class="s28">(</span>W<span class="s60">i</span><span class="s30">,</span><span class="s11">x </span>x<span class="s60">t</span><span class="s11"> </span><span class="s34">+ </span>W<span class="s26">i</span><span class="s30">,</span><span class="s11">h</span>h<span class="s60">t</span><span class="s45">−</span><span class="s13">1 </span><span class="s34">+ </span>b<span class="s60">i</span><span class="s28">)</span><span class="s39">.                                   </span><span class="s40">(5)</span></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">In the third step, the new cell states <i>s</i><span class="s60">t</span><span class="s11"> </span>are calculated based on the results of the previous two steps with <span class="s27">◦ </span>denoting the Hadamard (elementwise) product:</p><p class="s32" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;">s<span class="s60">t </span><span class="s11"> </span><span class="s34">= </span>f<span class="s60">t</span><span class="s11"> </span><span class="s34">◦ </span>s<span class="s60">t</span><span class="s45">−</span><span class="s13">1 </span><span class="s34">+ </span>i<span class="s60">t</span><span class="s11"> </span><span class="s34">◦ </span>s<span class="s40">˜</span><span class="s60">t</span><span class="s11"> </span><span class="s39">.                                                     </span><span class="s40">(6)</span></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">In the last step, the output <i>h</i><span class="s60">t</span><span class="s11"> </span>of the memory cells is derived as denoted in the following two equations:</p></li><li style="padding-left: 18pt;text-indent: -8pt;line-height: 11pt;text-align: left;"><p class="s23" style="display: inline;">b<span class="s26">f</span><span class="p">, </span>b<span class="s26">s</span><span class="s13">˜</span><span class="s46">, </span>b<span class="s26">i</span><span class="p">, and </span>b<span class="s60">o </span><span class="s11"> </span><span class="p">are bias vectors.</span></p></li><li style="padding-left: 18pt;text-indent: -8pt;line-height: 93%;text-align: left;"><p class="s23" style="display: inline;">f<span class="s60">t</span><span class="p">, </span>i<span class="s60">t</span><span class="p">, and </span>o<span class="s60">t </span><span class="s11"> </span><span class="p">are vectors for the activation values of the respec- tive gates.</span></p><p class="s32" style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">o<span class="s60">t</span><span class="s11"> </span><span class="s34">= </span>sigmoid<span class="s28">(</span>W<span class="s60">o</span><span class="s30">,</span><span class="s11">x </span>x<span class="s60">t</span><span class="s11"> </span><span class="s34">+ </span>W<span class="s26">o</span><span class="s30">,</span><span class="s11">h</span>h<span class="s60">t</span></p><p class="s62" style="padding-top: 1pt;text-indent: 0pt;text-align: left;">−<span class="s13">1 </span><span class="s34">+ </span><span class="s32">b</span><span class="s60">o</span><span class="s28">)</span><span class="s39">,                                 </span><span class="s40">(7)</span></p></li><li style="padding-left: 18pt;text-indent: -8pt;line-height: 11pt;text-align: left;"><p style="display: inline;"><i>s</i><span class="s60">t </span><span class="s11"> </span>and <i>s</i>˜<span class="s60">t </span><span class="s11"> </span>are vectors for the cell states and candidate values.</p></li><li style="padding-left: 18pt;text-indent: -8pt;line-height: 11pt;text-align: left;"><p class="s23" style="display: inline;">h<span class="s60">t</span><span class="s11"> </span><span class="p">is a vector for the output of the LSTM layer.</span></p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;">During a forward pass, the cell states <i>s</i><span class="s60">t</span><span class="s11"> </span>and outputs <i>h</i><span class="s60">t</span><span class="s11"> </span>of the LSTM layer at timestep <i>t </i>are calculated as follows:</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 88%;text-align: justify;">In the ﬁrst step, the LSTM layer determines which information should be removed from its previous cell states <i>s</i><span class="s60">t</span><span class="s45">−</span><span class="s13">1</span>. Therefore, the activation values <i>f</i><span class="s60">t</span><span class="s11"> </span>of the forget gates at timestep <i>t </i>are computed based on the current input <i>x</i><span class="s60">t</span>, the outputs <i>h</i><span class="s60">t</span><span class="s45">−</span><span class="s13">1 </span>of the memory cells at the previous timestep (<i>t </i><span class="s27">− </span>1), and the bias terms <i>b</i><span class="s26">f</span><span class="s11"> </span>of the for- get gates. The sigmoid function ﬁnally scales all activation values</p><p class="s32" style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">h<span class="s60">t</span><span class="s11">  </span><span class="s34">= </span>o<span class="s60">t</span><span class="s11"> </span><span class="s34">◦ </span><span class="s40">tanh</span><span class="s28">(</span>s<span class="s60">t</span><span class="s11"> </span><span class="s28">)</span><span class="s39">.                                                         </span><span class="s40">(8)</span></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">When processing an input sequence, its features are presented timestep by timestep to the LSTM network.  Hereby,  the  input  at each timestep <i>t </i>(in our case, one single standardized return) is pro- cessed by the network as denoted in the equations above. Once the last element of the  sequence  has  been  processed,  the  ﬁnal  output for  the  whole  sequence  is  returned.</p><p style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">During training, and similar to traditional feed-forward net- works, the weights and bias terms are adjusted in such a way that they minimize the loss of the speciﬁed objective function across</p><p style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;">the  training  samples.  Since  we  are  dealing  with  a  classiﬁcation problem, we use cross-entropy as objective function.</p><p style="padding-left: 6pt;text-indent: 11pt;text-align: justify;">The number of weights and bias terms being trained is calcu- lated as follows: let <i>h </i>denote the number of hidden units of the LSTM layer, and <i>i </i>the number of input features, then the number</p><p class="s16" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><a href="#bookmark81" class="s22">dard deep net, i.e., for showing the advantage of the LSTM, and a logistic regression, i.e., a standard  classiﬁer  as  baseline.  Note that random forests, standard deep nets, and the feature genera- tion for memory-free methods follow the speciﬁcations outlined in </a><a href="#bookmark81" class="s15">Krauss et al. </a>(2017) <span style=" color: #000;">for benchmarking reasons. Speciﬁcally, we</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;">of parameters of the LSTM layer that needs to be trained is:</p><p class="s11" style="text-indent: 0pt;line-height: 6pt;text-align: left;">t</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;">use  cumulative  returns  <i>R</i><span class="s29">m</span><span class="s30">,</span><span class="s11">s</span></p><p style="padding-left: 3pt;text-indent: 0pt;line-height: 12pt;text-align: left;">as  features  with  <i>m </i><span class="s27">∈ </span><span class="s43">{{</span>1<span class="s46">, . . . , </span>20<span class="s43">} </span><span class="s27">∪</span></p><p class="s32" style="padding-left: 6pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s40">4</span>hi <span class="s34">+ </span><span class="s40">4</span>h <span class="s34">+ </span><span class="s40">4</span>h<span class="s42">2</span><span class="s13"> </span><span class="s34">= </span><span class="s40">4</span><span class="s28">(</span>hi <span class="s34">+ </span>h <span class="s34">+ </span>h<span class="s42">2</span><span class="s13"> </span><span class="s28">) </span><span class="s34">= </span><span class="s40">4</span><span class="s28">(</span>h<span class="s28">(</span>i <span class="s34">+ </span><span class="s40">1</span><span class="s28">) </span><span class="s34">+ </span>h<span class="s42">2</span><span class="s13"> </span><span class="s28">)</span><span class="s39">.            </span><span class="s40">(9)</span></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span class="s43">{</span>40<span class="s46">, </span>60</p><p class="s46" style="text-indent: 0pt;line-height: 8pt;text-align: left;">, . . . ,</p><p style="text-indent: 0pt;line-height: 10pt;text-align: left;">240<span class="s43">}}</span><span class="s46">,</span></p><p class="s16" style="padding-left: 1pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><a href="#bookmark34" class="s22">see </a><a href="#bookmark34" class="s15">Eq. </a>(1) <span style=" color: #000;">and the same targets as deﬁned in</span></p><p class="s23" style="padding-top: 5pt;padding-left: 6pt;text-indent: 0pt;line-height: 92%;text-align: justify;"><span class="p">Hereby 4</span>hi <span class="p">refers to the dimensions of the four weight matrices applied to the inputs at each gate, i.e., </span>W<span class="s26">f</span><span class="s30">,</span><span class="s11">x</span><span class="s46">, </span>W<span class="s26">s</span><span class="s13">˜</span><span class="s30">,</span><span class="s11">x</span><span class="s46">, </span>W<span class="s26">i</span><span class="s30">,</span><span class="s11">x</span><span class="s46">, </span><span class="p">and </span>W<span class="s60">o</span><span class="s13">, </span><span class="s11">x</span><span class="p">. The 4</span>h <span class="p">refers to the dimensions of the four bias vectors (</span>b <span class="s26">f</span><span class="s11"> </span><span class="s46">, </span>b<span class="s26">s</span><span class="s13">˜</span><span class="s46">, </span>b<span class="s26">i</span><span class="s46">, </span><span class="p">and </span>b<span class="s60">o</span><span class="p">). Finally, the 4</span>h<span class="s42">2</span><span class="s13"> </span><span class="p">corresponds to the dimensions of the weight matrices applied to the outputs at the previous timestep, i.e., </span>W<span class="s26">f</span><span class="s30">,</span><span class="s11">h</span><span class="s46">, </span>W<span class="s26">s</span><span class="s13">˜</span><span class="s30">,</span><span class="s11">h</span><span class="s46">, </span>W<span class="s26">i</span><span class="s30">,</span><span class="s11">h</span><span class="s46">, </span><span class="p">and </span>W<span class="s26">o</span><span class="s13">,</span><span class="s11">h</span><span class="p">.</span></p><p style="padding-left: 6pt;text-indent: 11pt;line-height: 9pt;text-align: left;">For the training of the LSTM network, we apply three advanced</p><p class="s16" style="padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a href="#bookmark124" class="s22">methods via keras. First, we make use of RMSprop, a mini-batch version of rprop (</a><a href="#bookmark124" class="s15">Tieleman &amp; Hinton, </a>2012<a href="#bookmark85" class="s22">), as optimizer. The se- lection of RMSprop is motivated from the literature as it is “usually a good choice for recurrent neural  networks”  (</a><a href="#bookmark85" class="s15">Chollet,  </a>2016<a href="#bookmark103" class="s22">).  Sec- ond, following </a><a href="#bookmark103" class="s15">Gal and Ghahramani </a>(2016)<span style=" color: #000;">, we apply dropout reg- ularization within the recurrent layer. Hereby, a fraction of the in- put units is randomly dropped at each update during training time, both at the input gates and the recurrent connections, resulting in reduced risk of overﬁtting and better generalization. Based on ini- tial experiments on the  year  1991  (which  is  not  used  as  part  of the out-of-sample trading periods), we have observed that higher dropout values go along with a decline in performance and there- fore settled on a relatively low dropout value  of  0.1.  Third,  we make use of early stopping to dynamically derive the number of epochs for training for each study  period  individually  and  to  fur- ther reduce the risk of overﬁtting. Hereby, the training samples are split into two sets:  one  training  and  one  validation  set.  The  ﬁrst set is used to train the network and to iteratively adjust its pa- rameters so that the loss function is  minimized.  After  each  epoch (one pass across the samples of the ﬁrst set), the network predicts the unseen samples from the validation set and a validation loss is computed. Once the validation loss does not decrease for </span><span class="s23">patience </span><a href="#bookmark85" class="s22">periods, the training is stopped and the weights of the model with the lowest validation loss is restored (see  ModelCheckpoint  call- back in </a><a href="#bookmark85" class="s15">Chollet, </a>2016<a href="#bookmark113" class="s22">). Following </a><a href="#bookmark113" class="s15">Granger </a>(1993)<span style=" color: #000;">,  who  suggests  to hold back about 20  percent  of  the  sample  as  “post-sample”  data, we use 80 percent of the training samples as training set and  20 percent as validation set (samples are assigned randomly to either training or validation set), a maximum training duration of 1000 epochs, and an early stopping patience of 10.  The  speciﬁed topol- ogy of our trained LSTM network is hence as follows:</span></p></li><li style="padding-top: 3pt;padding-left: 18pt;text-indent: -8pt;line-height: 10pt;text-align: justify;"><p style="display: inline;">Input layer with 1 feature and 240 timesteps.</p></li><li style="padding-left: 18pt;text-indent: -8pt;line-height: 11pt;text-align: justify;"><p style="display: inline;"><a name="bookmark12">LSTM layer with </a><i>h </i><span class="s27">= </span><a href="#bookmark81" class="s22">25 hidden neurons and a dropout value of 0.1. This conﬁguration yields 2752 parameters for the LSTM, leading to a sensible number of approximately 93 training ex- amples per parameter. This value has been chosen in analogy to the conﬁguration of the deep net in </a><a href="#bookmark81" class="s15">Krauss et al. </a><span style=" color: #0080AC;">(2017)</span>. A high number of observations per parameter allows for more robust estimates in case of such noisy training data, and reduces the risk of overﬁtting.</p></li><li style="padding-left: 18pt;text-indent: -8pt;line-height: 11pt;text-align: justify;"><p class="s19" style="display: inline;"><a href="#bookmark41" class="s22" name="bookmark11">Output layer (dense layer) with two neurons and softmax acti- vation function</a><span style=" color: #0080AC; font-family:&quot;Palatino Linotype&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt;">6</span> <span class="p">– a standard conﬁguration.</span></p><p class="s16" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="#bookmark32" class="s15">Section </a>3.2.2<span style=" color: #000;">. For the logistic regression model, we standardize the</span></p><p class="s16" style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><a href="#bookmark30" class="s22">returns as denoted in </a><a href="#bookmark30" class="s15">Eq. </a>(2)<a href="#bookmark42" class="s22">.</a><span style=" color: #0080AC; font-family:&quot;Palatino Linotype&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt;">7</span><span class="s19">  </span><span style=" color: #000;">In the subsequent paragraphs, we brieﬂy outline how we calibrate the benchmarking methods.</span></p><p style="padding-left: 6pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><i>Random forest: </i><a href="#bookmark129" class="s22">The ﬁrst algorithm for random decision forests has been suggested by </a><a href="#bookmark129" class="s15">Ho </a><span style=" color: #0080AC;">(1995)</span><a href="#bookmark80" class="s22">, and was later expanded by </a><a href="#bookmark80" class="s15">Breiman </a><span style=" color: #0080AC;">(2001)</span>. Simply speaking, random forests are composed of many deep yet decorrelated decision trees built on different boot- strap samples of the training data. Two key techniques are used in the random forest algorithm – random feature selection to decor- relate the trees and bagging, to build them on different bootstrap samples. The algorithm is fairly simple: for each of the <i>B </i>trees in the committee, a bootstrap sample is drawn from the training data. A decision tree is developed on the bootstrap sample. At each split, only a subset <i>m </i>of the <i>p </i>features is available as potential split cri- terion. The growing stops once the maximum depth <i>J </i>is reached. The ﬁnal output is a committee of <i>B </i>trees and classiﬁcation is per- formed as majority vote. We set the number of trees <i>B </i>to 1000<span class="s46">, </span>and maximum depth to <i>J </i><span class="s27">= </span>20<span class="s46">, </span>allowing for substantial higher or- der interactions. Random feature selection is left at a default value</p><p style="text-indent: 0pt;text-align: left;"><span><img width="7" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_032.png"/></span></p><p class="s23" style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><span class="p">of </span>m <span class="s27">= </span><span class="s63">√</span>p <a href="#bookmark106" class="s22">for classiﬁcation, see </a><a href="#bookmark106" class="s15">Pedregosa et al. </a><span class="s16">(2011)</span><span class="p">.</span></p><p style="padding-left: 6pt;text-indent: 11pt;text-align: justify;"><a href="#bookmark102" class="s22">We use a random forest as benchmark for two compelling rea- sons. First, it is a state-of-the-art machine learning model that re- quires virtually no tuning and usually delivers good results. Second, random forests in this conﬁguration are the best single technique </a><a href="#bookmark81" class="s22">in </a><a href="#bookmark81" class="s15">Krauss et al. </a><a href="#bookmark102" class="s15">(2017) </a><a href="#bookmark102" class="s22">and the method of choice in </a><a href="#bookmark102" class="s15">Moritz and Zimmermann (2014) </a><a href="#bookmark102" class="s22">– a large-scale machine learning </a>application on monthly stock market data. As such, random forests serve as a powerful benchmark for any innovative machine learning model.</p><p class="s23" style="padding-left: 6pt;text-indent: 11pt;text-align: justify;">Deep neural network: <a href="#bookmark111" class="s22">We deploy a standard DNN to show the relative advantage of LSTM networks. Speciﬁcally, we use a feed forward neural network with 31 input  neurons,  31  neurons  in  the ﬁrst, 10 in the second, 5 in the third hidden layer, and 2 neurons in the output layer. The activation function is maxout with two channels, following </a><a href="#bookmark111" class="s15">Goodfellow, Warde-Farley, Mirza, Courville, and Bengio (2013)</a><a href="#bookmark111" class="s22">, and softmax in  the  output  layer.  Dropout  is  set  </a><span class="p">to 0.5, and </span>L<a href="#bookmark81" class="s22">1 regularization with shrinkage 0.00001 is used – see </a><a href="#bookmark81" class="s15">Krauss et al. </a><span class="s16">(2017) </span><span class="p">for further details.</span></p><p class="s23" style="padding-left: 6pt;text-indent: 11pt;text-align: justify;">Logistic regression: <a href="#bookmark106" class="s22">As baseline model, we also deploy logistic regression. Details about our implementation are available in the documentation of sci-kit learn (</a><a href="#bookmark106" class="s15">Pedregosa et al., </a><span class="s16">2011</span><span class="p">) and the references therein. The optimal </span>L<span class="p">2 regularization is determined among 100 choices on a logarithmic scale between 0.0001 and 10,000 via 5-fold cross-validation on the respective training set and L-BFGS is deployed to ﬁnd an optimum, while restricting the max- imum number of iterations to 100. Logistic regression serves as a baseline, so that we can derive the incremental value-add of the much more complex and computationally intensive LSTM network in comparison to a standard classiﬁer.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s23" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">3.5.  Forecasting, ranking, and trading</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s23" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">3.4. Benchmark models – random forest, deep net, and logistic</p><p class="s46" style="text-indent: 0pt;line-height: 5pt;text-align: left;">P</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 6pt;padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">For all models, we forecast the probability  <span class="s41">ˆ</span> <span class="s29">s</span></p><p class="s11" style="text-indent: 0pt;line-height: 5pt;text-align: right;">t<span class="s45">+</span><span class="s13">1</span><span class="s64">|</span>t</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 1pt;text-indent: 0pt;text-align: left;">for each stock</p><p class="s23" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">regression</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 11pt;line-height: 11pt;text-align: left;">For benchmarking the LSTM, we choose random forests, i.e., a  robust  yet  high-performing  machine  learning  method,  a  stan-</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="49" height="0" alt="image" src="Deep learning with long short-term memory networks for financial/Image_033.png"/></span></p><p class="s20" style="padding-top: 1pt;padding-left: 6pt;text-indent: 5pt;text-align: left;"><a name="bookmark41">6 </a><span class="s21"> </span><span class="s13">Alternatively, one output neuron with a sigmoid activation function would also be a valid setup.</span><a name="bookmark42">&zwnj;</a></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 90%;text-align: justify;"><i>s </i>to out-/underperform the cross-sectional median in period <i>t </i><span class="s27">+ </span>1<span class="s46">, </span>making only use of information up until time <i>t</i>. Then, we rank all stocks for each period <i>t </i><span class="s27">+ </span>1 in descending order of this probability.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="49" height="0" alt="image" src="Deep learning with long short-term memory networks for financial/Image_034.png"/></span></p><p class="s20" style="padding-top: 1pt;padding-left: 6pt;text-indent: 5pt;text-align: justify;">7 <span class="s21"> </span><span class="s13">We perform no standardization of the returns for the other two models as this is automatically carried out for the deep neural network in its H2O implementation, or not required in case of the random forest.</span></p><h2 style="padding-top: 3pt;padding-left: 116pt;text-indent: 0pt;text-align: justify;"><a name="bookmark43">Table 2</a></h2><p class="s13" style="padding-left: 116pt;text-indent: 0pt;text-align: justify;">Panel A: <i>p</i>-values of Diebold–Mariano (DM) test for the null hypothesis that  the  forecasts  of method <i>i </i>have inferior accuracy than the forecasts of method <i>j</i>. Panel B: <i>p</i>-values of the Pesaran– Timmermann (PT) test  for the null hypothesis that predictions and  responses are independently distributed. Both panels are based on the <i>k </i><span class="s45">= </span>10 portfolio from December 1992 to October 2015.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:116.408pt" cellspacing="0"><tr style="height:14pt"><td style="width:40pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s65" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">A<span class="s24">: DM test</span></p></td><td style="width:21pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:39pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:40pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:40pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:40pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:46pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s65" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">B<span class="s24">: PT test</span></p></td><td style="width:33pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"/></tr><tr style="height:13pt"><td style="width:40pt;border-top-style:solid;border-top-width:1pt"><p class="s66" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">i</p></td><td style="width:21pt;border-top-style:solid;border-top-width:1pt"><p class="s66" style="padding-top: 2pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">j <span class="s25">=</span></p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">LSTM</p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">RAF</p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">DNN</p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">LOG</p></td><td style="width:46pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 9pt;text-indent: 0pt;text-align: left;">Method</p></td><td style="width:33pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Result</p></td></tr><tr style="height:8pt"><td style="width:40pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">LSTM</p></td><td style="width:21pt"/><td style="width:39pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 7pt;text-align: left;">–</p></td><td style="width:40pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0143</p></td><td style="width:40pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0037</p></td><td style="width:40pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0000</p></td><td style="width:46pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 7pt;text-align: left;">LSTM</p></td><td style="width:33pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0000</p></td></tr><tr style="height:9pt"><td style="width:40pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">RAF</p></td><td style="width:21pt"/><td style="width:39pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.9857</p></td><td style="width:40pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">–</p></td><td style="width:40pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3180</p></td><td style="width:40pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0000</p></td><td style="width:46pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">RAF</p></td><td style="width:33pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0000</p></td></tr><tr style="height:9pt"><td style="width:40pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">DNN</p></td><td style="width:21pt"/><td style="width:39pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.9963</p></td><td style="width:40pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.6820</p></td><td style="width:40pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">–</p></td><td style="width:40pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0000</p></td><td style="width:46pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">DNN</p></td><td style="width:33pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0000</p></td></tr><tr style="height:12pt"><td style="width:40pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">LOG</p></td><td style="width:21pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.0000</p></td><td style="width:40pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.0000</p></td><td style="width:40pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.0000</p></td><td style="width:40pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">–</p></td><td style="width:46pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">LOG</p></td><td style="width:33pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0000</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><a name="bookmark13">The top of the ranking corresponds to the most undervalued stocks that are expected to outperform the cross-sectional median in </a><i>t </i><span class="s27">+ </span>1. As such, we go long the top <i>k </i>and short the ﬂop <i>k </i>stocks of each ranking, for a long-short portfolio consisting of 2<i>k </i><a href="#bookmark64" class="s22">stocks – see </a><a href="#bookmark64" class="s15">Huck (2009, </a><span style=" color: #0080AC;">2010)</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ul></ol></li></ol></li><li style="padding-left: 16pt;text-indent: -10pt;text-align: justify;"><h1 style="display: inline;"><a name="bookmark44">Results</a></h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark68" class="s22" name="bookmark14">Our results are presented in three stages. First, we analyze re- turns prior to and after transaction costs of 5 bps per half-turn, following </a><a href="#bookmark68" class="s15">Avellaneda and Lee </a>(2010)<span style=" color: #000;">, and contrast the performance of the LSTM network against the random forest, the deep neural net, and the logistic regression. Second, we derive common pat- terns within the top and ﬂop stocks, thus unveiling sources of prof- itability. Third, we develop a simpliﬁed trading strategy based on these ﬁndings, and show that we can achieve part of the LSTM per- formance by capturing the most visible pattern with a transparent trading rule.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l8"><li style="padding-left: 21pt;text-indent: -15pt;text-align: justify;"><p class="s23" style="display: inline;"><a name="bookmark15">Performance review</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l9"><li style="padding-left: 26pt;text-indent: -20pt;line-height: 11pt;text-align: justify;"><p class="s23" style="display: inline;">Overview</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 94%;text-align: justify;">First, we analyze  the  characteristics  of  portfolios  consisting  of 2<i>k </i>stocks, i.e., the top <i>k </i>stocks we go long, and the ﬂop <i>k </i>stocks we go short. We choose <i>k </i><span class="s27">∈ </span>{10, 50, 100, 150, 200} and compare the performance of the novel  LSTM  with  the  other  approaches  along the dimensions mean return per day, annualized  standard  devia- tion, annualized Sharpe ratio, and accuracy – prior  to  transaction costs.</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 93%;text-align: justify;">We see the following trends. Irrespective of the portfolio size <i>k</i>, the LSTM shows favorable characteristics vis-a-vis the other ap- proaches. Speciﬁcally, daily returns prior to transaction costs are at 0.46 percent, compared to 0.43 percent for the RAF, 0.32 per- cent for the DNN, and 0.26 for the LOG for <i>k </i><span class="s27">= </span>10. Also for larger portfolio sizes, the LSTM achieves the highest mean returns per day, with the exception of <i>k </i><span class="s27">= </span>200<span class="s46">, </span>where it is tied with the RAF. With respect to standard deviation – a risk metric – the LSTM is on a similar level as the RAF, with slightly lower values for <i>k </i><span class="s27">= </span>10<span class="s46">, </span>and slightly higher values for increasing portfolio sizes. Both LSTM and RAF exhibit much lower standard deviation than the DNN and the logistic regression – across all levels of <i>k</i>. Sharpe ratio, or re- turn per unit of risk, is highest for the LSTM up until <i>k </i><span class="s27">= </span>100<span class="s46">, </span>and slightly less than the RAF for even larger portfolios, when the lower standard deviation of the RAF outweighs the higher return of the LSTM. Accuracy, meaning the share of correct classiﬁcations, is an important machine learning metric. We see a clear advantage of the LSTM for the <i>k </i><span class="s27">= </span>10 portfolio, a slight edge until <i>k </i><span class="s27">= </span>100<span class="s46">, </span>and a tie with the RAF for increasing sizes.</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 93%;text-align: justify;"><a name="bookmark16">We focus our subsequent analyses on the long-short portfolio with </a><i>k </i><span class="s27">= </span>10.</p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">median or not. In this paragraph, we benchmark the predictive ac- curacy of the LSTM forecasts against those of the other methods, and against random guessing. Furthermore, we compare the ﬁnan- cial performance of the LSTM with 100,000 randomly generated long-short portfolios.</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark90" class="s22">First, we deploy the </a><a href="#bookmark90" class="s15">Diebold and Mariano </a><span style=" color: #0080AC;">(1995) </span>(DM) test to evaluate the null that the forecasts of method <i>i </i>have  inferior  ac- curacy than the forecasts of method <i>j</i>, with <i>i</i>, <i>j </i><span class="s27">∈ </span>{<i>LSTM</i>, <i>RAF</i>, <i>DNN</i>, <i>LOG</i>} and <i>i </i><span class="s27">/= </span><i>j</i>. For each forecast of each method, we assign a 0  in case the individual stock of the <i>k </i><span class="s27">= </span>10 portfolio is correctly  classi- ﬁed and a 1 otherwise, and use this vector  of  classiﬁcation  errors as input for the DM test. In total, we hence consider 5750 <span class="s27">× </span>2 <span class="s27">× </span><i>k </i><span class="s27">= </span>115<span class="s46">,</span>000 individual forecasts for the stocks in  the  <i>k </i><span class="s27">= </span><a href="#bookmark43" class="s22">10  portfolio for 5750 trading  days  in  total.  Results  are  depicted  in  panel A of </a><a href="#bookmark43" class="s15">Table </a><span style=" color: #0080AC;">2</span>.  In  line  one,  for  the  null  that  the  LSTM  forecast is infe- rior to the forecasts of RAF, DNN, or LOG, we  obtain <i>p</i>-values of 0.0143,  0.0037,  and  0.0000,  respectively.  If  we  test at a ﬁve per- cent signiﬁcance level, and apply a Bonferroni  correction for  three comparisons, the adjusted signiﬁcance level is 1.67 percent, and we can still reject the individual null  hypotheses  that the LSTM fore- casts are less accurate than the RAF, DNN, or LOG forecasts. Hence, it makes sense to assume that the LSTM  forecasts are superior to those of the other considered methods. Similarly, we can reject the null that the RAF forecasts are inferior to the LOG forecasts as well as  the  null  that  the  DNN  forecasts  are  inferior  to  the  LOG  fore- casts. In other words, the  predictions of the sophisticated machine learning approaches all  outperform those of a standard logistic re- gression classiﬁer. Apparently, the former are able to capture com- plex dependencies  in our ﬁnancial time series data that cannot be extracted by a  standard logistic regression. However, from the DM test matrix, we  cannot infer that the RAF forecasts outperform the DNN forecasts  or vice versa – both methods seem to exhibit sim- ilar predictive  accuracy. Our key ﬁnding is though, that the LSTM network –  despite  its  signiﬁcantly  higher  computational  cost  –  is the  method of choice in terms of forecasting accuracy.</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;">Second, we use the Pesaran–Timmermann (PT) test to evalu- ate the null hypotheses that prediction and response are indepen- dently distributed for each of the forecasting methods. We ﬁnd <i>p</i>- values of zero up to the fourth digit, suggesting that the null can be rejected at any sensible level of signiﬁcance. In other words, each machine learning method we employ exhibits statistically sig- niﬁcant predictive accuracy.</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 94%;text-align: justify;">Third, we  provide  a  statistical  estimate  for  the  probability of the LSTM network having  randomly  achieved  these  results. For <i>k </i><span class="s27">= </span>10<span class="s46">, </span>we consider a total of  5750 <span class="s27">× </span>10 <span class="s27">× </span>2 <span class="s27">= </span>115<span class="s46">,</span>000  top and ﬂop  stocks,  of  which  54.3  percent  are  correctly  classiﬁed. If the true accuracy of the LSTM  network  was  indeed  50  per- cent, we could model the number of “successes”, i.e., the num- ber of correctly classiﬁed stocks <i>X </i>in the top/ﬂop with a binomial distribution,  so  <i>X </i><span class="s27">∼ </span><i>B</i><span class="s67">(</span><i>n </i><span class="s27">= </span>115<span class="s46">,</span>000<span class="s46">, </span><i>p </i><span class="s27">= </span>0<span class="s46">.</span>5<span class="s46">, </span><i>q </i><span class="s27">= </span>0<span class="s46">.</span>5<span class="s67">)</span>.  For  such  a</p><p style="text-indent: 0pt;text-align: right;">large <i>n</i>, <i>X</i></p><p class="s28" style="text-indent: 0pt;line-height: 9pt;text-align: left;">μ       σ</p><p style="text-indent: 0pt;text-align: left;"/><p class="s11" style="text-indent: 0pt;line-height: 2pt;text-align: left;">appr<span class="s30">.</span></p><p class="s27" style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;">∼  <span class="s46">N </span><span class="s67">(  </span>= <span class="s23">np</span><span class="s46">,   </span>=</p><p class="s63" style="text-indent: 0pt;line-height: 11pt;text-align: left;">√<span class="s23">npq</span><span class="s67">)</span><span class="p">. Now, we can easily compute</span></p></li><li style="padding-left: 27pt;text-indent: -21pt;line-height: 9pt;text-align: left;"><p class="s23" style="display: inline;">Details on predictive accuracy</p><p style="padding-left: 5pt;text-indent: 11pt;text-align: left;">The key task of the employed machine learning methods is to accurately predict whether a stock outperforms its cross-sectional</p><p class="s16" style="padding-left: 5pt;text-indent: 0pt;text-align: justify;"><a href="#bookmark93" class="s22">the probability of achieving more than 54.3 percent accuracy, if the LSTM network had a true accuracy of 50 percent. We use the R package Rmpfr of </a><a href="#bookmark93" class="s15">Maechler </a>(2016) <span style=" color: #000;">to evaluate multiple-precision</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s68" style="padding-left: 42pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span><img width="25" height="11" alt="image" src="Deep learning with long short-term memory networks for financial/Image_035.png"/></span>	<span><img width="25" height="11" alt="image" src="Deep learning with long short-term memory networks for financial/Image_036.png"/></span>	<span><img width="32" height="11" alt="image" src="Deep learning with long short-term memory networks for financial/Image_037.png"/></span>	<span><img width="32" height="11" alt="image" src="Deep learning with long short-term memory networks for financial/Image_038.png"/></span>	<span><img width="32" height="11" alt="image" src="Deep learning with long short-term memory networks for financial/Image_039.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s69" style="padding-left: 40pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="115" height="2" alt="image" src="Deep learning with long short-term memory networks for financial/Image_040.png"/></span>	<span><img width="115" height="2" alt="image" src="Deep learning with long short-term memory networks for financial/Image_041.png"/></span>	<span><img width="115" height="2" alt="image" src="Deep learning with long short-term memory networks for financial/Image_042.png"/></span>	<span><img width="115" height="2" alt="image" src="Deep learning with long short-term memory networks for financial/Image_043.png"/></span>	<span><img width="115" height="2" alt="image" src="Deep learning with long short-term memory networks for financial/Image_044.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 9pt;text-indent: 0pt;line-height: 5pt;text-align: left;"><span><img width="32" height="75" alt="image" src="Deep learning with long short-term memory networks for financial/Image_045.png"/></span>	<span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_046.png"/></span><span class="s21">	</span><span><img width="115" height="37" alt="image" src="Deep learning with long short-term memory networks for financial/Image_047.png"/></span>	<span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_048.png"/></span><span class="s21">	</span><span><img width="115" height="24" alt="image" src="Deep learning with long short-term memory networks for financial/Image_049.png"/></span>	<span><img width="115" height="21" alt="image" src="Deep learning with long short-term memory networks for financial/Image_050.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 9pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="681" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_051.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 9pt;text-indent: 0pt;line-height: 5pt;text-align: left;"><span><img width="32" height="75" alt="image" src="Deep learning with long short-term memory networks for financial/Image_052.png"/></span>	<span><img width="115" height="59" alt="image" src="Deep learning with long short-term memory networks for financial/Image_053.png"/></span>	<span><img width="114" height="37" alt="image" src="Deep learning with long short-term memory networks for financial/Image_054.png"/></span>	<span><img width="113" height="30" alt="image" src="Deep learning with long short-term memory networks for financial/Image_055.png"/></span>	<span><img width="114" height="27" alt="image" src="Deep learning with long short-term memory networks for financial/Image_056.png"/></span>	<span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_057.png"/></span><span class="s21">	</span><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_058.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 9pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="681" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_059.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 9pt;text-indent: 0pt;line-height: 5pt;text-align: left;"><span><img width="32" height="75" alt="image" src="Deep learning with long short-term memory networks for financial/Image_060.png"/></span>	<span><img width="113" height="59" alt="image" src="Deep learning with long short-term memory networks for financial/Image_061.png"/></span>	<span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_062.png"/></span><span class="s21">	</span><span><img width="113" height="46" alt="image" src="Deep learning with long short-term memory networks for financial/Image_063.png"/></span>	<span><img width="114" height="42" alt="image" src="Deep learning with long short-term memory networks for financial/Image_064.png"/></span>	<span><img width="115" height="40" alt="image" src="Deep learning with long short-term memory networks for financial/Image_065.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 9pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="681" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_066.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 9pt;text-indent: 0pt;line-height: 5pt;text-align: left;"><span><img width="32" height="75" alt="image" src="Deep learning with long short-term memory networks for financial/Image_067.png"/></span>	<span><img width="114" height="52" alt="image" src="Deep learning with long short-term memory networks for financial/Image_068.png"/></span>	<span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_069.png"/></span><span class="s21">	</span><span><img width="115" height="31" alt="image" src="Deep learning with long short-term memory networks for financial/Image_070.png"/></span>	<span><img width="115" height="28" alt="image" src="Deep learning with long short-term memory networks for financial/Image_071.png"/></span>	<span><img width="115" height="25" alt="image" src="Deep learning with long short-term memory networks for financial/Image_072.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_073.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_074.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_075.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_076.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_077.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_078.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_079.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_080.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_081.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_082.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_083.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_084.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_085.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_086.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_087.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_088.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_089.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_090.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_091.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_092.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_093.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_094.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_095.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_096.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_097.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_098.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_099.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_100.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_101.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_102.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_103.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_104.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_105.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_106.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_107.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_108.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_109.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_110.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_111.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_112.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_113.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_114.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_115.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_116.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_117.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_118.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_119.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_120.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_121.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_122.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_123.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_124.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_125.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_126.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_127.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_128.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_129.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_130.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_131.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_132.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_133.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_134.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_135.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_136.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_137.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_138.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_139.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_140.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_141.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_142.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_143.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_144.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_145.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_146.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_147.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_148.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_149.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_150.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_151.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_152.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_153.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_154.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_155.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_156.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_157.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_158.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_159.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_160.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_161.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_162.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_163.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_164.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="18" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_165.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="14" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_166.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="17" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_167.png"/></span></p><table style="border-collapse:collapse" cellspacing="0"><tr style="height:10pt"><td style="width:13pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="3" bgcolor="#0091EA"/><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="3"/><td style="width:12pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="3" bgcolor="#A3DBFF"/><td style="width:43pt;border-left-style:solid;border-left-width:1pt" colspan="4"><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 9pt;text-indent: 0pt;line-height: 5pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_168.png"/></span></p></td></tr><tr style="height:5pt"><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2"/><td style="width:12pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2" bgcolor="#716C6C"/><td style="width:22pt;border-left-style:solid;border-left-width:1pt" colspan="2"/></tr><tr style="height:21pt"><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"/><td style="width:13pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" bgcolor="#DFD6CF"/></tr></table><p style="text-indent: 0pt;text-align: left;"/><table style="border-collapse:collapse" cellspacing="0"><tr style="height:5pt"><td style="width:13pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2" bgcolor="#0091EA"/><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2"/><td style="width:12pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2" bgcolor="#A3DBFF"/><td style="width:43pt;border-left-style:solid;border-left-width:1pt" colspan="4"/></tr><tr style="height:9pt"><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"/><td style="width:12pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" bgcolor="#716C6C"/><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"/><td style="width:13pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" bgcolor="#DFD6CF"/></tr></table><p style="text-indent: 0pt;text-align: left;"/><table style="border-collapse:collapse" cellspacing="0"><tr style="height:6pt"><td style="width:13pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2" bgcolor="#0091EA"/><td style="width:30pt;border-right-style:solid;border-right-width:1pt" colspan="3"/><td style="width:12pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2" bgcolor="#716C6C"/><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2"/><td style="width:13pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2" bgcolor="#DFD6CF"/></tr><tr style="height:4pt"><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"/><td style="width:12pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" bgcolor="#A3DBFF"/><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"/></tr></table><p style="text-indent: 0pt;text-align: left;"/><table style="border-collapse:collapse" cellspacing="0"><tr style="height:17pt"><td style="width:13pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="3" bgcolor="#0091EA"/><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="3"/><td style="width:12pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="3" bgcolor="#A3DBFF"/><td style="width:43pt;border-left-style:solid;border-left-width:1pt" colspan="4"><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s70" style="padding-left: 9pt;text-indent: 0pt;line-height: 5pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_169.png"/></span>	<span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_170.png"/></span></p></td></tr><tr style="height:4pt"><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2"/><td style="width:12pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2" bgcolor="#716C6C"/><td style="width:22pt;border-left-style:solid;border-left-width:1pt" colspan="2"/></tr><tr style="height:11pt"><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"/><td style="width:13pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" bgcolor="#DFD6CF"/></tr></table><p style="text-indent: 0pt;text-align: left;"/><table style="border-collapse:collapse" cellspacing="0"><tr style="height:9pt"><td style="width:13pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2" bgcolor="#0091EA"/><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2"/><td style="width:12pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2" bgcolor="#A3DBFF"/><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2"/><td style="width:12pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" rowspan="2" bgcolor="#716C6C"/><td style="width:22pt;border-left-style:solid;border-left-width:1pt" colspan="2"><p style="padding-left: 9pt;text-indent: 0pt;line-height: 5pt;text-align: left;"><span><img width="13" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_171.png"/></span></p></td></tr><tr style="height:10pt"><td style="width:9pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt"/><td style="width:13pt;border-top-style:solid;border-top-width:1pt;border-left-style:solid;border-left-width:1pt;border-bottom-style:solid;border-bottom-width:1pt;border-right-style:solid;border-right-width:1pt" bgcolor="#DFD6CF"/></tr></table><p style="text-indent: 0pt;text-align: left;"/><h2 style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark45">Fig. 3.  </a><span class="s13">Daily performance characteristics for long-short portfolios of different sizes: mean return (excluding transaction costs), standard deviation, annualized Sharpe ratio (excluding transaction costs), and accuracy from December 1992 to October 2015.</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 25pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="660" height="87" alt="image" src="Deep learning with long short-term memory networks for financial/Image_172.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 96pt;text-indent: 0pt;line-height: 5pt;text-align: left;"><span><img width="28" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_173.png"/></span>	<span><img width="28" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_174.png"/></span>	<span><img width="23" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_175.png"/></span>	<span><img width="23" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_176.png"/></span>	<span><img width="23" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_177.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="4" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_178.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="16" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_179.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="17" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_180.png"/></span></p><h2 style="padding-left: 55pt;text-indent: 0pt;text-align: left;"><a name="bookmark46">Fig. 4.  </a><span class="s13">Empirical distribution of mean daily returns of 100,000 sampled monkey trading long-short portfolios (excluding transaction costs).</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">ﬂoating point numbers and compute a probability of 2.7742e<span class="s27">−</span>187 that a random classiﬁer performs as well as the LSTM by chance alone.</p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;text-align: justify;"><a href="#bookmark97" class="s22" name="bookmark17">Finally, we assess the ﬁnancial performance of 100,000 ran- domly sampled portfolios in the sense of Malkiel’s monkey throw- ing darts at the Wall Street Journal’s stock page (</a><a href="#bookmark97" class="s15">Malkiel, </a>2007<a href="#bookmark46" class="s22">). Hereby, we randomly sample 10 stocks for the long and 10 stocks for the short portfolio without replacement for each of the 5750 trading days. All these portfolios over the 5750 days can be inter- preted as those being picked by one monkey. Then, we compute the mean average daily return of the combined long-short portfo- lios over these 5750 days to evaluate the monkey’s performance. The results of 100,000 replications, i.e., of 100,000 different mon- keys, are illustrated in </a><a href="#bookmark46" class="s15">Fig. </a>4<a href="#bookmark45" class="s22">. As expected, we see an average daily return of zero prior to transaction costs. More importantly, even the best performing “monkey” with an average daily return of 0.05 percent, does not even come close to the results of the applied models shown in </a><a href="#bookmark45" class="s15">Fig. </a>3<span style=" color: #000;">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 26pt;text-indent: -21pt;line-height: 11pt;text-align: justify;"><p class="s23" style="display: inline;">Details on ﬁnancial performance</p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;text-align: justify;"><a href="#bookmark47" class="s15">Table </a>3 <span style=" color: #000;">provides insights of the ﬁnancial performance of the LSTM, compared to the benchmarks, prior to and after transaction costs.</span></p><p class="s23" style="padding-top: 2pt;padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;">Return characteristics: <a href="#bookmark47" class="s22">In panel A of </a><a href="#bookmark47" class="s15">Table </a><span class="s16">3</span><span class="p">, we see  that  the LSTM exhibits favorable return characteristics. Mean returns of 0.46 percent before and 0.26 percent after transaction costs are statis- tically signiﬁcant, with a Newey–West </span>t<span class="p">-statistic of 16.9336 before and 9.5792 after transaction costs, compared to a critical value of 1.9600 (5 percent signiﬁcance level). The median is only slightly smaller than the mean return, and quartiles as well as minimum and maximum values suggest that results are not caused by out- liers. The share of positive returns is at 55.74 percent after trans- action costs, an astonishingly high value for a long-short portfolio. The second best model is the RAF, with mean returns of 0.23 per- cent after transaction costs, albeit at slightly higher standard de- viation (0.0209 LSTM vs. 0.0215 RAF). The DNN places third with mean returns of 0.12 percent per day after transaction costs – still statistically signiﬁcant – compared to the logistic regression. The simplest model achieves mean returns of 0.06 percent per day af- ter transaction costs, which are no longer  signiﬁcantly  different from zero (Newey–West </span>t<a href="#bookmark81" class="s22">-statistic of 1.6666 compared to critical value of 1.9600). Note that the LSTM shows strong performance compared to the literature. The ensemble in </a><a href="#bookmark81" class="s15">Krauss et al. </a><span class="s16">(2017)</span><span class="p">, which consists of a deep net, gradient-boosted trees, and a random forest yields average returns of 0.25 percent per day on the same time frame, data set, and after transaction costs. In other words,</span></p><h2 style="padding-top: 3pt;padding-left: 38pt;text-indent: 0pt;text-align: justify;"><a name="bookmark47">Table 3</a></h2><p class="s13" style="padding-left: 38pt;text-indent: 0pt;text-align: justify;">Panels A, B, and C illustrate performance characteristics of the <i>k </i><span class="s45">= </span><a href="http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html" class="s83" target="_blank">10 portfolio, before and after transaction costs for LSTM, compared to RAF, DNN, LOG, and to the general market (MKT) from December 1992 to October 2015. MKT represents the general market as in Kenneth R. French’s data library, see </a><span style=" color: #0080AC;">here</span>. Panel A depicts daily return characteristics. Panel B depicts daily risk characteristics. Panel C depicts annualized risk-return metrics. Newey–West standard errors with a one-lag correction are used.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 38pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="603" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_181.png"/></span></p><p class="s13" style="padding-top: 1pt;padding-left: 139pt;text-indent: 0pt;text-align: left;">Before transaction costs                                                       After transaction costs</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:38.693pt" cellspacing="0"><tr style="height:13pt"><td style="width:99pt;border-bottom-style:solid;border-bottom-width:1pt" colspan="2"/><td style="width:34pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">LSTM</p></td><td style="width:41pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">RAF</p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">DNN</p></td><td style="width:35pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">LOG</p></td><td style="width:11pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:34pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">LSTM</p></td><td style="width:41pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">RAF</p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">DNN</p></td><td style="width:35pt;border-top-style:solid;border-top-width:1pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">LOG</p></td><td style="width:44pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">MKT</p></td></tr><tr style="height:12pt"><td style="width:18pt;border-top-style:solid;border-top-width:1pt"><p class="s65" style="padding-top: 2pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">A</p></td><td style="width:81pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">Mean return (long)</p></td><td style="width:34pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">0.0029</p></td><td style="width:41pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">0.0030</p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">0.0022</p></td><td style="width:35pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">0.0021</p></td><td style="width:11pt;border-top-style:solid;border-top-width:1pt"/><td style="width:34pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">0.0019</p></td><td style="width:41pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">0.0020</p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">0.0012</p></td><td style="width:35pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">0.0011</p></td><td style="width:44pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">–</p></td></tr><tr style="height:10pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Mean return (short)</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0017</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0012</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0010</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0005</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0007</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0002</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0000</p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.0005</span></p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">–</p></td></tr><tr style="height:8pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Mean return</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0046</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0043</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0032</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0026</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0026</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0023</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0012</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0006</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0004</p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Standard error</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0004</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0004</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0004</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0004</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0001</p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s66" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">t<span class="s24">-statistic</span></p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">16.9336</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">14.1136</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">8.9486</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">7.0006</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">9.5792</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">7.5217</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">3.3725</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.6666</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">2.8305</p></td></tr><tr style="height:10pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Minimum</p></td><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.2176</span></p></td><td style="width:41pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.2058</span></p></td><td style="width:40pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1842</span></p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1730</span></p></td><td style="width:11pt"/><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.2196</span></p></td><td style="width:41pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.2078</span></p></td><td style="width:40pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1862</span></p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1750</span></p></td><td style="width:44pt"><p class="s25" style="padding-left: 13pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.0895</span></p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Quartile 1</p></td><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0053</span></p></td><td style="width:41pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0050</span></p></td><td style="width:40pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0084</span></p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0089</span></p></td><td style="width:11pt"/><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0073</span></p></td><td style="width:41pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0070</span></p></td><td style="width:40pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0104</span></p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0109</span></p></td><td style="width:44pt"><p class="s25" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0046</span></p></td></tr><tr style="height:8pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Median</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0040</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0032</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0025</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0022</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0020</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0012</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0005</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0002</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0008</p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Quartile 3</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0140</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0124</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0140</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0133</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0120</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0104</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0120</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0113</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0058</p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Maximum</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1837</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3822</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4284</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4803</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1817</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3802</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4264</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4783</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1135</p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Share  <span class="s71">&gt; </span>0</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.6148</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.6078</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5616</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5584</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5574</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5424</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5146</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5070</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5426</p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Standard  dev.</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0209</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0215</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0262</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0269</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0209</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0215</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0262</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0269</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0117</p></td></tr><tr style="height:10pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Skewness</p></td><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1249</span></p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">2.3052</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.2724</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.8336</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1249</span></p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">2.3052</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.2724</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.8336</p></td><td style="width:44pt"><p class="s25" style="padding-left: 13pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1263</span></p></td></tr><tr style="height:10pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Kurtosis</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 7pt;text-align: left;">11.6967</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">40.2716</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">20.6760</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">30.2379</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 7pt;text-align: left;">11.6967</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">40.2716</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">20.6760</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">30.2379</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 7pt;text-align: left;">7.9791</p></td></tr><tr style="height:12pt"><td style="width:18pt"><p class="s65" style="padding-top: 2pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">B</p></td><td style="width:81pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">1-percent VaR</p></td><td style="width:34pt"><p class="s25" style="padding-top: 1pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0525</span></p></td><td style="width:41pt"><p class="s25" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0475</span></p></td><td style="width:40pt"><p class="s25" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0676</span></p></td><td style="width:35pt"><p class="s25" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0746</span></p></td><td style="width:11pt"/><td style="width:34pt"><p class="s25" style="padding-top: 1pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0545</span></p></td><td style="width:41pt"><p class="s25" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0495</span></p></td><td style="width:40pt"><p class="s25" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0696</span></p></td><td style="width:35pt"><p class="s25" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0766</span></p></td><td style="width:44pt"><p class="s25" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0320</span></p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1-percent CVaR</p></td><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0801</span></p></td><td style="width:41pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0735</span></p></td><td style="width:40pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0957</span></p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0995</span></p></td><td style="width:11pt"/><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0821</span></p></td><td style="width:41pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0755</span></p></td><td style="width:40pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0977</span></p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.1015</span></p></td><td style="width:44pt"><p class="s25" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0461</span></p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">5-percent VaR</p></td><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0245</span></p></td><td style="width:41pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0225</span></p></td><td style="width:40pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0333</span></p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0341</span></p></td><td style="width:11pt"/><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0265</span></p></td><td style="width:41pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0245</span></p></td><td style="width:40pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0353</span></p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0361</span></p></td><td style="width:44pt"><p class="s25" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0179</span></p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">5-percent CVaR</p></td><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0430</span></p></td><td style="width:41pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0401</span></p></td><td style="width:40pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0550</span></p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0568</span></p></td><td style="width:11pt"/><td style="width:34pt"><p class="s25" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0450</span></p></td><td style="width:41pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0421</span></p></td><td style="width:40pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0570</span></p></td><td style="width:35pt"><p class="s25" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0588</span></p></td><td style="width:44pt"><p class="s25" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0277</span></p></td></tr><tr style="height:10pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Max.  drawdown</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.4660</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.3187</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.5594</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.5595</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.5233</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.7334</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.9162</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.9884</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.5467</p></td></tr><tr style="height:11pt"><td style="width:18pt"><p class="s65" style="padding-top: 2pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">C</p></td><td style="width:81pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">Return p.a.</p></td><td style="width:34pt"><p class="s24" style="padding-top: 1pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">2.0127</p></td><td style="width:41pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">1.7749</p></td><td style="width:40pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">1.0610</p></td><td style="width:35pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">0.7721</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-top: 1pt;padding-left: 2pt;text-indent: 0pt;text-align: left;">0.8229</p></td><td style="width:41pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">0.6787</p></td><td style="width:40pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">0.2460</p></td><td style="width:35pt"><p class="s24" style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">0.0711</p></td><td style="width:44pt"><p class="s24" style="padding-top: 1pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">0.0925</p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Excess return p.a.</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.9360</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.7042</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.0085</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.7269</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.7764</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.6359</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2142</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0437</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0646</p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Standard dev. p.a.</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3323</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3408</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4152</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4266</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3323</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3408</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4152</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4266</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1852</p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Downside dev. p.a.</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2008</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1857</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2524</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2607</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2137</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1988</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2667</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2751</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1307</p></td></tr><tr style="height:9pt"><td style="width:18pt"/><td style="width:81pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Sharpe ratio p.a.</p></td><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">5.8261</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">5.0001</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">2.4288</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.7038</p></td><td style="width:11pt"/><td style="width:34pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">2.3365</p></td><td style="width:41pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.8657</p></td><td style="width:40pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5159</p></td><td style="width:35pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1024</p></td><td style="width:44pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3486</p></td></tr><tr style="height:12pt"><td style="width:18pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:81pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Sortino ratio p.a.</p></td><td style="width:34pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">10.0224</p></td><td style="width:41pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">9.5594</p></td><td style="width:40pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">4.2029</p></td><td style="width:35pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">2.9614</p></td><td style="width:11pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:34pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 2pt;text-indent: 0pt;line-height: 8pt;text-align: left;">3.8499</p></td><td style="width:41pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">3.4135</p></td><td style="width:40pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.9225</p></td><td style="width:35pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 7pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2583</p></td><td style="width:44pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 13pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.7077</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: left;"><a name="bookmark18">the LSTM as single model achieves a slightly stronger performance than  a  fully-ﬂedged  ensemble.</a></p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 94%;text-align: justify;"><i>Risk characteristics: </i><a href="#bookmark47" class="s22">In panel B of </a><a href="#bookmark47" class="s15">Table </a><span style=" color: #0080AC;">3</span>, we observe a mixed picture with respect to risk characteristics. In terms of daily value at risk (VaR), the LSTM achieves second place after the RAF, with a 1-percent VaR of <span class="s27">−</span>5.45 percent compared to <span class="s27">−</span>4.95 percent for the RAF. The riskiest strategy stems from the logistic regression model, where a loss of <span class="s27">−</span>7.66 percent is exceeded in one percent of all cases – more than twice as risky as a buy-and-hold investment in the general market. However, the LSTM has the lowest maximum drawdown of 52.33 percent – compared to all other models and the general market.</p><p class="s23" style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">Annualized risk-return metrics: <a href="#bookmark47" class="s22">In panel C of </a><a href="#bookmark47" class="s15">Table </a><span class="s16">3</span><span class="p">, we ana- lyze risk-return metrics on an annualized basis. We see that the LSTM achieves the highest annualized returns of 82.29 percent af- ter transaction costs, compared to the RAF (67.87 percent),  the DNN (24.60 percent), the LOG (7.11 percent) and the general mar- ket (9.25 percent). Annualized standard deviation is at the second lowest level of 33.23 percent, compared to all benchmarks. The Sharpe ratio scales excess return by standard deviation, and thus can be interpreted as a signal-to-noise ratio in ﬁnance, or the re- turn per unit of risk. We see that the LSTM achieves the highest level of 2.34, with the RAF coming in second with 1.87, while all other methods have a Sharpe ratio well below 1.0.</span></p><p style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">From a ﬁnancial perspective, we have two key ﬁndings. First, the LSTM outperforms the RAF by a clear margin in terms of re- turn characteristics and risk-return metrics. We are thus able to show that choosing LSTM networks – which are inherently suitable for time series prediction tasks – outperform shallow tree-based models as well as standard deep learning. Second, we demonstrate that a standard logistic regression is not able to capture the same level of information from the feature space – even though we perform in-sample cross-validation to ﬁnd optimal regularization values.</p></li><li style="padding-top: 2pt;padding-left: 27pt;text-indent: -21pt;line-height: 11pt;text-align: left;"><p class="s23" style="display: inline;">A critical review of LSTM proﬁtability over time</p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;text-align: justify;"><a href="#bookmark48" class="s22">In </a><a href="#bookmark48" class="s15">Fig. </a>5<span style=" color: #000;">, we display strategy performance over time, i.e., from January 1993 to October 2015. We focus on the most competitive techniques, i.e., the LSTM and the random forest.</span></p><p class="s23" style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">1993/01–2000/12: <span class="p">These early times are characterized by strong performance – with the LSTM being superior to the RAF with re- spect to average returns per day, Sharpe ratio, and accuracy in al- most all years. Cumulative payouts on 1 USD average invest per day reach a level of over 11 USD for the LSTM and over 8 USD for the RAF until 2000. When considering this outperformance, it is important to note that LSTM networks have been introduced in 1997, and can only be feasibly deployed ever since the emergence of GPU computing in the late 2000s. As such, the exceptionally high returns in the 90s may well be driven by the fact that LSTMs were either unknown to or completely unfeasible for the majority of market professionals at that time. A similar argument holds true for random forests.</span></p><p class="s23" style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">2001/01–2009/12: <span class="p">The second period corresponds to a time of moderation. The LSTM is still able to produce positive returns after transaction costs in all years, albeit at much lower levels compared to the 90s. When considering cumulative payouts, we see that the outperformance of the LSTM compared to the random forest per- sists up to the ﬁnancial crisis. A key advantage of these tree-based methods is their robustness to noise and outliers – which plays out during such volatile times. The RAF achieves exceptionally high re- turns and consistent accuracy values at a Sharpe ratio of up to 6. As such, total payouts on 1 USD investment amount to 4 USD for the LSTM, and to 5.6 USD for the RAF – with the majority of the RAF payouts being achieved during the ﬁnancial crisis.</span></p><p style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">It seems reasonable to believe that this period of moderation is caused by an increasing diffusion of such strategies among in- dustry professionals, thus gradually eroding proﬁtability. However, for the RAF, the global ﬁnancial crisis in 2008/2009 constitutes an exception – with a strong resurgence in proﬁtability. Following the</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s72" style="padding-left: 24pt;text-indent: 0pt;line-height: 10pt;text-align: left;">	<span><img width="31" height="14" alt="image" src="Deep learning with long short-term memory networks for financial/Image_182.png"/></span><span class="s58"> </span><span><img width="43" height="14" alt="image" src="Deep learning with long short-term memory networks for financial/Image_183.png"/></span><span class="s59">	</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s69" style="padding-left: 22pt;text-indent: 0pt;line-height: 2pt;text-align: left;"><span><img width="197" height="2" alt="image" src="Deep learning with long short-term memory networks for financial/Image_184.png"/></span>	<span><img width="197" height="2" alt="image" src="Deep learning with long short-term memory networks for financial/Image_185.png"/></span>	<span><img width="197" height="2" alt="image" src="Deep learning with long short-term memory networks for financial/Image_186.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-left: 38pt;text-indent: 0pt;line-height: 7pt;text-align: left;"><span><img width="153" height="9" alt="image" src="Deep learning with long short-term memory networks for financial/Image_187.png"/></span>	<span><img width="153" height="9" alt="image" src="Deep learning with long short-term memory networks for financial/Image_188.png"/></span>	<span><img width="153" height="9" alt="image" src="Deep learning with long short-term memory networks for financial/Image_189.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 13pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="209" height="148" alt="image" src="Deep learning with long short-term memory networks for financial/Image_190.png"/></span>	<span><img width="213" height="148" alt="image" src="Deep learning with long short-term memory networks for financial/Image_191.png"/></span>	<span><img width="213" height="148" alt="image" src="Deep learning with long short-term memory networks for financial/Image_192.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 12pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="209" height="130" alt="image" src="Deep learning with long short-term memory networks for financial/Image_193.png"/></span>	<span><img width="212" height="130" alt="image" src="Deep learning with long short-term memory networks for financial/Image_194.png"/></span>	<span><img width="216" height="130" alt="image" src="Deep learning with long short-term memory networks for financial/Image_195.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 13pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="208" height="130" alt="image" src="Deep learning with long short-term memory networks for financial/Image_196.png"/></span>	<span><img width="207" height="130" alt="image" src="Deep learning with long short-term memory networks for financial/Image_197.png"/></span>	<span><img width="212" height="130" alt="image" src="Deep learning with long short-term memory networks for financial/Image_198.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s73" style="padding-left: 65pt;text-indent: 0pt;line-height: 7pt;text-align: left;"><span><img width="83" height="9" alt="image" src="Deep learning with long short-term memory networks for financial/Image_199.png"/></span>	<span><img width="83" height="9" alt="image" src="Deep learning with long short-term memory networks for financial/Image_200.png"/></span>	<span><img width="83" height="9" alt="image" src="Deep learning with long short-term memory networks for financial/Image_201.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 9pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="213" height="113" alt="image" src="Deep learning with long short-term memory networks for financial/Image_202.png"/></span>	<span><img width="213" height="113" alt="image" src="Deep learning with long short-term memory networks for financial/Image_203.png"/></span>	<span><img width="213" height="113" alt="image" src="Deep learning with long short-term memory networks for financial/Image_204.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 454pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><span><img width="39" height="11" alt="image" src="Deep learning with long short-term memory networks for financial/Image_205.png"/></span>	<span><img width="34" height="11" alt="image" src="Deep learning with long short-term memory networks for financial/Image_206.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="32" height="13" alt="image" src="Deep learning with long short-term memory networks for financial/Image_207.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="43" height="13" alt="image" src="Deep learning with long short-term memory networks for financial/Image_208.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="32" height="13" alt="image" src="Deep learning with long short-term memory networks for financial/Image_209.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="43" height="13" alt="image" src="Deep learning with long short-term memory networks for financial/Image_210.png"/></span></p><p class="s13" style="padding-top: 5pt;padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><a name="bookmark48"><span class="h2">Fig.  5.  </span></a>Contrast  of  LSTM  and  RAF  performance  from  January  1993  to  October  2015  for  the  <i>k </i><span class="s45">= </span>10  portfolio,  i.e.,  development of  cumulative  proﬁts  on  1  USD  average investment per day, average daily returns by year, annualized Sharpe ratio, and average accuracy per year, after transaction costs.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><a href="#bookmark69" class="s22">literature, these proﬁts may be driven by two factors. First, it is reasonable to believe that investors are “losing sight of the trees for the forest” (</a><a href="#bookmark69" class="s15">Jacobs and Weber, </a>2015<a href="#bookmark84" class="s22">, p. 75) at times of ﬁnancial turmoil – thus creating realtive-value arbitrage opportunities, see </a><a href="#bookmark84" class="s15">Clegg and Krauss </a>(2018)<a href="#bookmark125" class="s22">. Second, at times of high volatility, limits to arbitrage are exceptionally high as well, making it hard to cap- ture such relative-value arbitrage opportunities. Speciﬁcally, short selling costs may rise for hard to borrow stocks – see </a><a href="#bookmark125" class="s15">Gregoriou (2012)</a><a href="#bookmark94" class="s22">, </a><a href="#bookmark125" class="s15">Engelberg, Reed, and Ringgenberg (2017)</a><a href="#bookmark125" class="s22">, or, in even more</a></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">severe cases, short-selling may be banned altogether. But also the long side is affected, e.g., when widening spreads and decreasing liquidity set a cap on returns.</p><p class="s23" style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">2010/01–2015/10: <span class="p">The third period corresponds to a time of de- terioration. The random forest loses its edge, and destroys more than 1 USD in value, based on an average investment of 1 USD per day. By contrast, the LSTM continues realizing higher accuracy scores in almost all years and is able to keep capital approximately constant, after transaction costs. When comparing to the literature,</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 9pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="682" height="159" alt="image" src="Deep learning with long short-term memory networks for financial/Image_211.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><a name="bookmark49"><span class="h2">Fig. 6.  </span></a>Time-varying share of industries in the <i>k </i><span class="s45">= </span>10 portfolio minus share of these industries in the S&amp;P 500, calculated over number of stocks. A positive value indicates that the industry is overweighted and vice versa.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><a href="#bookmark81" class="s22" name="bookmark19">it is remarkable  to  see  that  the  ensemble  presented  in  </a><a href="#bookmark81" class="s15">Krauss et al. (2017) </a><a href="#bookmark81" class="s22">also runs into a massive drawdown as of 2010 </a><a href="#bookmark72" class="s22">– whereas the single-model LSTM returns ﬂuctuate around zero. Re- gardless, the edge of the presented machine learning methods seems to have been arbitraged away. This effect can be observed in many academic research papers targeting quantitative strategies – see, for example, </a><a href="#bookmark72" class="s15">Bogomolov </a>(2013)<a href="#bookmark115" class="s22">, </a><a href="#bookmark115" class="s15">Rad, Low, and Faff </a>(2016)<a href="#bookmark121" class="s22">,  </a><a href="#bookmark121" class="s15">Green, Hand, and Zhang </a>(2017)<a href="#bookmark84" class="s22">, </a><a href="#bookmark84" class="s15">Clegg and Krauss </a>(2018)<span style=" color: #000;">, among others.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 27pt;text-indent: -21pt;line-height: 11pt;text-align: justify;"><p class="s23" style="display: inline;">Industry breakdown</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 93%;text-align: justify;">Coming from the LSTM’s ability to identify structure, we next analyze  potential  preferences  for  certain  industries  in  the  <i>k </i><span class="s27">=</span></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: justify;">10 portfolio. Speciﬁcally, we consider the difference between the</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">share of an industry in the <i>k </i><span class="s27">= </span>10 portfolio and the share of that industry in the S&amp;P 500 at that time. A positive value indicates that the industry is overweighted by the LSTM network, and a negative value indicates that it is underweighted.</p><p style="padding-left: 5pt;text-indent: 11pt;text-align: justify;"><a href="#bookmark49" class="s15" name="bookmark20">Fig. </a><span style=" color: #0080AC;">6 </span>depicts our ﬁndings for the most interesting industries – oil and gas, technology, ﬁnancials, and all others. First, we see that there is a signiﬁcant overweight of technology stocks building up end of the 90s – corresponding to the growing dot-com bubble and its bust. Second, we observe a rise in ﬁnancial stocks around the years 2008/2009 – corresponding to the global ﬁnancial crisis. And third, oil and gas stocks gain in weight as of 2014 – falling together with the recent oil glut and the signiﬁcant drop in crude oil prices. Note: a more detailed breakdown depicting the relative overweight for each of the GICS industries individually for the top <i>k </i>and the ﬂop <i>k </i><a href="#bookmark51" class="s22">portfolio is provided in the Appendix.</a><span style=" color: #0080AC; font-family:&quot;Palatino Linotype&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt;">8</span><span class="s19"> </span>It is interesting to see that the overweight in each industry adequately captures major market developments. We hypothesize that this behavior is driven by increasing volatility levels, and further elaborate on that point in the following section.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ol id="l10"><ol id="l11"><li style="padding-left: 22pt;text-indent: -16pt;text-align: justify;"><p class="s23" style="display: inline;">Common patterns in the top and ﬂop stocks</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a name="bookmark50">Machine learning approaches – most notably artiﬁcial neural networks – are commonly considered as black-box methods. In this section, we aim for shining light into that black-box, thus unveiling common patterns in the top and ﬂop stocks.</a></p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;">First, we conduct a very simple yet effective analysis. For every day, we extract all 240-day return sequences for the top and ﬂop <i>k </i><a href="#bookmark52" class="s22">stocks.</a><span style=" color: #0080AC; font-family:&quot;Palatino Linotype&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt;">9</span><span class="s19"> </span>Then, we stack all 5750 <span class="s27">× </span>10 top and the same number of ﬂop sequences on top of each other. For better representation, we accumulate the 240 returns of each sequence to a return index, starting at a level of 0 on day <i>t </i><span class="s27">− </span>240 and then average these re- turn index sequences. We hence obtain two generalized sequences,</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="49" height="0" alt="image" src="Deep learning with long short-term memory networks for financial/Image_212.png"/></span></p><p class="s20" style="padding-top: 1pt;padding-left: 11pt;text-indent: 0pt;text-align: left;"><a name="bookmark51">8 </a><span class="s21"> </span><span class="s13">We thank an anonymous referee for this suggestion.</span><a name="bookmark52">&zwnj;</a></p><p class="s20" style="padding-left: 11pt;text-indent: 0pt;text-align: left;">9 <span class="s21"> </span><a href="#bookmark33" class="s83">A return sequence is generated as described in </a><a href="#bookmark33" class="a">Section </a><span class="s19">3.2</span><span class="s13">.</span></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><a href="#bookmark53" class="s22">containing the patterns of the top 10 and of the ﬂop 10 stocks. Results are depicted in </a><a href="#bookmark53" class="s15">Fig. </a><span style=" color: #0080AC;">7</span><a href="#bookmark73" class="s22">, contrasted to the behavior of the cross-section across all stocks (mean). We see that the top and the ﬂop stocks both exhibit below-mean momentum in the sense of </a><a href="#bookmark73" class="s15">Jegadeesh and Titman </a><span style=" color: #0080AC;">(1993)</span>, i.e., they perform poorly from day <i>t </i><span class="s27">− </span>240 until day <i>t </i><span class="s27">− </span>10<span class="s46">, </span>compared to the cross-section. From day <i>t </i><span class="s27">− </span>9 until <i>t </i>(note: the prediction is made on day <i>t</i>), the top stocks start crashing at accelerating pace, losing about 50 percent of what they have gained during the previous 230 days on average. By con- trast, the ﬂop stocks show an inverse pattern during the past 10 days prior to trading, and exhibit increasingly higher returns. It is compelling to see that the LSTM extracted such a strong common- ality among the ﬂop stocks and the top stocks.</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;">Second, based on this visual insight, we construct further time- series characteristics for the top and ﬂop stocks. Thereby, we fol- low the same methodology as above for generating the descriptive statistics, i.e., we compute the 240-day return sequence for each stock, calculate the desired statistic, and average over all <i>k </i>stocks, with <i>k </i><span class="s27">∈ </span>{1, 5, 10, 100, 200}. Speciﬁcally, we consider the following statistics:</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l12"><li style="padding-left: 18pt;text-indent: -8pt;line-height: 11pt;text-align: justify;"><p style="display: inline;"><a href="#bookmark33" class="s22">(Multi-)period returns, as deﬁned in </a><a href="#bookmark33" class="s15">Section </a><span style=" color: #0080AC;">3.2</span>, with <i>m </i><span class="s27">∈ </span>{1, 5, 20, 240}, denoted as Return_t_t-m in the graphic, where <i>m </i>is counting backwards from day <i>t</i>, the last element of the se- quence (i.e., the day on which the prediction for <i>t </i><span class="s27">+ </span>1 is made). Moreover, we consider the cumulative return from day <i>t </i><span class="s27">− </span>20 of the sequence until day <i>t </i><span class="s27">− </span>240 of the sequence, denoted as Return_t-20_t-240.</p></li><li style="padding-left: 18pt;text-indent: -8pt;text-align: justify;"><p style="display: inline;">Sample standard deviations, computed over the same time frames as above, and following the same naming conventions.</p></li><li style="padding-left: 18pt;text-indent: -8pt;text-align: justify;"><p style="display: inline;">Sample skewness and kurtosis over the full 240 days of each sequence.</p></li><li style="padding-left: 18pt;text-indent: -8pt;text-align: justify;"><p class="s16" style="display: inline;"><a href="#bookmark105" class="s22">The coeﬃcients of a Carhart regression in the sense of </a><a href="#bookmark105" class="s15">Gatev, Goetzmann, and Rouwenhorst (2006)</a><a href="#bookmark82" class="s22">, </a><a href="#bookmark105" class="s15">Carhart (1997)</a><a href="#bookmark105" class="s22">. Thus, </a><a href="#bookmark73" class="s22">we extract the alpha of each stock (FF_Alpha – denoting the id- iosyncratic return of the stock beyond market movements), the beta (FF_Mkt-RF – denoting how much the stock moves when the market moves by  1  percent),  the  small  minus  big  fac- tor (FF_SMB – denoting the loading on small versus large cap stocks), the high minus low factor (FF_HML – denoting the loading on value versus growth stocks), the momentum factor (FF_Mom – denoting the loading on the momentum factor in the sense of </a><a href="#bookmark73" class="s15">Jegadeesh and Titman </a>(1993)<a href="#bookmark82" class="s22">, </a><a href="#bookmark82" class="s15">Carhart </a>(1997)<a href="#bookmark55" class="s22">, the short-term reversal factor (FF_ST_Rev – denoting the loading on short-term reversal effects) and the R squared (FF_R_squared – denoting the percentage of return variance explained by the factor model). Please note that these coeﬃcients refer to the in- dividual stocks’ 240 days history prior to being selected by the LSTM for trading and not to the exposure of the resulting LSTM strategy to these factors (see </a><a href="#bookmark55" class="s15">Section </a>4.3 <span style=" color: #000;">for this analysis).</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="682" height="109" alt="image" src="Deep learning with long short-term memory networks for financial/Image_213.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s21" style="padding-left: 26pt;text-indent: 0pt;line-height: 5pt;text-align: left;"><span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_214.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_215.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_216.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_217.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_218.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_219.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_220.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_221.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_222.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_223.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_224.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_225.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_226.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_227.png"/></span>	<span><img width="15" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_228.png"/></span>	<span><img width="12" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_229.png"/></span>	<span><img width="11" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_230.png"/></span>	<span><img width="12" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_231.png"/></span>	<span><img width="12" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_232.png"/></span>	<span><img width="12" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_233.png"/></span>	<span><img width="12" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_234.png"/></span>	<span><img width="11" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_235.png"/></span>	<span><img width="12" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_236.png"/></span>	<span><img width="12" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_237.png"/></span>	<span><img width="2" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_238.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-left: 47pt;text-indent: 0pt;text-align: left;"><a name="bookmark53">Fig. 7.  </a><span class="s13">Averaged, normalized return index of top and ﬂop 10 stocks over sequence of the 240 one day returns prior to trading for LSTM strategy.</span></h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 23pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="645" height="321" alt="image" src="Deep learning with long short-term memory networks for financial/Image_239.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s13" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a name="bookmark54"><span class="h2">Fig. 8.   </span></a>Time-series characteristics of top and ﬂop <i>k </i>stocks for LSTM strategy. Statistics are ﬁrst computed over the 240-day return sequences for each stock in the top or ﬂop <i>k</i><a href="#bookmark50" class="s83">, as described in the bullet list in </a><a href="#bookmark50" class="a">Section </a><span style=" color: #0080AC;">4.2 </span>(including naming conventions) and then averaged over all top <i>k </i>or all ﬂop <i>k </i>stocks. The mean is calculated similarly, however across all stocks. Note that there is a color-coding along each row, separately for top and ﬂop <i>k </i>stocks. Thereby, the darker the green, the higher the value, and the darker the red, the lower the value. (For interpretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this article.)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 6pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark54" class="s22">Results are shown in </a><a href="#bookmark54" class="s15">Fig. </a><span style=" color: #0080AC;">8</span>. The graphical patterns from the last paragraph now become apparent in a quantitative manner – across different values of <i>k</i><a href="#bookmark92" class="s22">. First, the top stocks exhibit highly neg- ative returns in the last days prior to the prediction, and the ﬂop stocks highly positive returns. This behavior corresponds to short- term reversal strategies, as outlined </a><a href="#bookmark70" class="s22">in </a><a href="#bookmark70" class="s15">Jegadeesh </a><a href="#bookmark92" class="s15">(1990)</a><a href="#bookmark92" class="s22">, </a><a href="#bookmark92" class="s15">Lehmann (1990)</a><a href="#bookmark95" class="s22">, </a><a href="#bookmark92" class="s15">Lo and MacKinlay (1990) </a><a href="#bookmark92" class="s22">– to name a few. The LSTM </a>net- work seems to independently ﬁnd the stock market anomaly, that stocks that sharply fall in the last days then tend to rise in the next period and vice versa. The effect is stronger, the smaller <i>k</i><a href="#bookmark73" class="s22">, i.e., the lower the number  of  stocks  considered  in  the  portfo- lio. Second, both top and ﬂop stocks exhibit weak momentum in the sense of </a><a href="#bookmark73" class="s15">Jegadeesh and Titman </a><span style=" color: #0080AC;">(1993)</span>. For example, the top</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">10  stocks  show  an  average  momentum  of  9.1  percent  from  day <i>t </i><span class="s27">− </span>240 until day <i>t </i><span class="s27">− </span>20 of the sequence, compared to 11.7 percent, i.e., the mean across all stocks. The ﬂop stocks exhibit a similar pattern. The smaller <i>k</i><a href="#bookmark86" class="s22">, the stronger the underperformance with respect to the momentum effect. Third, when considering stan- dard deviation, it becomes obvious that volatility plays an impor- tant role (see also </a><a href="#bookmark86" class="s15">LeBaron, </a><span style=" color: #0080AC;">1992</span><a href="#bookmark71" class="s22">). Clearly, high volatility stocks are preferred compared to the market, and volatility  is increas- ing for the more extreme parts of the ranking. Volatility in the sense of beta can be an important return predictive signal – see </a><a href="#bookmark71" class="s15">Baker, Bradley, and Wurgler </a><span style=" color: #0080AC;">(2011)</span><a href="#bookmark101" class="s22">, </a><a href="#bookmark101" class="s15">Frazzini and Pedersen </a><span style=" color: #0080AC;">(2014)</span>,</p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><a href="#bookmark131" class="s15">Hong and Sraer </a><span style=" color: #0080AC;">(2016)</span><a href="#bookmark76" class="s22">,  and  a  higher  beta  is  a  key  characteris- tic of the selected stocks. Also,  skewness  is  similar  to  the  gen- eral market, and the returns of the top and ﬂop stocks are more leptokurtic than the general market – a potential return predic- tive signal remotely relating to the works </a><a href="#bookmark83" class="s22">of </a><a href="#bookmark83" class="s15">Kumar </a><a href="#bookmark76" class="s15">(2009)</a><a href="#bookmark76" class="s22">, </a><a href="#bookmark76" class="s15">Boyer, Mitton, and Vorkink (2010)</a><a href="#bookmark74" class="s22">, </a><a href="#bookmark76" class="s15">Bali, Cakici, and Whitelaw (2011) </a>on stocks with “lottery-type” features. Finally, we see that the above mentioned time-series characteristics are also conﬁrmed in the re- gression coeﬃcients. Top and ﬂop <i>k </i>stocks exhibit higher beta, a negative loading on the momentum factor and a positive loading on the short-term reversal factor – with the respective magnitude increasing with lower values for <i>k</i>. We observe a slight loading on the SMB factor, meaning that smaller stocks among the S&amp;P</p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">500 constituents are selected – which usually  have higher vola- tility.</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;">Given that the LSTM network independently extracted these patterns from 240-day sequences of standardized returns, it is astonishing to see how well some of them relate to commonly known capital market anomalies. This ﬁnding is compelling, given that none of the identiﬁed characteristics is explicitly coded as fea- ture, but instead derived by the LSTM network all by itself – an- other key difference to the memory-free models, such as the ran- dom forest, who are provided with mutli-period returns as fea- tures.</p></li></ul></li><li style="padding-top: 2pt;padding-left: 22pt;text-indent: -16pt;text-align: left;"><p class="s23" style="display: inline;"><a name="bookmark21">Sources of proﬁtability</a><a name="bookmark55">&zwnj;</a><a name="bookmark56">&zwnj;</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><span class="s23">Simpliﬁed trading strategy: </span><a href="#bookmark53" class="s22">In this section, we build on the pre- vious analysis and construct a simpliﬁed trading strategy. From </a><a href="#bookmark53" class="s15">Figs. </a>7 <a href="#bookmark54" class="s22">and </a>8<a href="#bookmark81" class="s22">, we see that the most dominant characteristic is the slump or steep rise in returns in the last days prior to trading. On a similar note, </a><a href="#bookmark81" class="s15">Krauss et al. </a>(2017) <a href="#bookmark102" class="s22">ﬁnd that the last returns are the most important variables for their machine learning models, and so do </a><a href="#bookmark102" class="s15">Moritz and Zimmermann </a>(2014)<a href="#bookmark70" class="s22">. For the sake of simplicity, we build on this most salient point, and loosely follow </a><a href="#bookmark70" class="s15">Jegadeesh (1990)</a><a href="#bookmark92" class="s22">, </a><a href="#bookmark70" class="s15">Lehmann (1990)</a><a href="#bookmark70" class="s22">, two of the creators of the short-term </a><span style=" color: #000;">re- versal anomaly. Speciﬁcally, we go long the top </span><span class="s23">k </span><span style=" color: #000;">stocks with the most negative 5-day cumulative return prior to the trading day, and short the ﬂop </span><span class="s23">k </span><a href="#bookmark54" class="s22">stocks with the most positive 5-day cumu- lative return prior to the trading day – all equal-weight. For this very simple yet transparent strategy, we ﬁnd average daily returns of 0.23 percent, prior to transaction costs, or 0.03 percent after transaction costs. We hence see that capitalizing only on the most prominent feature, i.e., the past 5-day cumulative return, merely yields about 50 percent of the returns of the LSTM strategy prior to transaction costs. After transaction costs, the short-term reversal strategy looses its edge, contrary to the LSTM. Hence, we may cau- tiously conclude that additional explanatory power is contained in the other features, forming more subtle patterns not directly dis- cernible from the aggregated perspective in </a><a href="#bookmark54" class="s15">Fig. </a>8<span style=" color: #000;">. Building on this ﬁnding, we next move on and evaluate the exposure of LSTM re- turns to common sources of systematic risk.</span></p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;text-align: justify;"><a name="bookmark22"><span class="s23">Exposure to systematic sources of risk: </span></a><a href="#bookmark81" class="s22">As commonly performed in portfolio analysis and similar to </a><a href="#bookmark81" class="s15">Krauss et al. </a>(2017)<a href="#bookmark98" class="s22">, we evaluate the exposure of the long-short portfolio to common sources of sys- tematic risk. We use the Fama–French three factor model (FF3) as in </a><a href="#bookmark98" class="s15">Fama and French </a>(1996)<a href="#bookmark82" class="s22">, enhanced by three additional factors. It thus consists of a market factor, a factor measuring exposure to small minus big capitalization stocks (SMB), and a factor measur- ing exposure to high minus low book-to-market stocks (HML). In addition, we include a momentum factor (</a><a href="#bookmark82" class="s15">Carhart, </a>1997<a href="#bookmark105" class="s22">), a short- term reversal factor (</a><a href="#bookmark105" class="s15">Gatev et al., </a>2006<a href="#bookmark57" class="s22">), and a long-term reversal factor. All data used for these factor models are obtained from Ken- neth French’s website.</a><span style=" color: #0080AC; font-family:&quot;Palatino Linotype&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt;">10</span><span class="s19"> </span><a href="#bookmark56" class="s22">The underlying idea is to measure addi- tional exposure to cross-sectional price dynamics. Our ﬁndings are summarized in </a><a href="#bookmark56" class="s15">Table </a>4<span style=" color: #000;">. At ﬁrst, we observe that the LSTM returns exhibit by far the lowest coeﬃcient of determination of 0.0330 among all models. In other words – only a fraction of daily LSTM raw returns of 0.46 percent can be explained by such common sources of systematic risk. Indeed, an alpha of 0.42 percent per day remains (intercept). By contrast, the RAF has a higher coeﬃcient of determination of 0.1338, and only 0.34 percent of daily alpha re- main (compared to raw returns of 0.43 percent). Even though </span><span class="s23">R</span><span class="s42">2</span><span class="s13"> </span><a href="#bookmark105" class="s22">is low (which can often be the case in ﬁnancial  research  –  see </a><a href="#bookmark105" class="s15">Gatev et al., </a>2006<span style=" color: #000;">) – we can still compare factor loadings with our expectations. The LSTM is basically market-neutral, meaning that the long and the short portfolio (in which we invest equal dol- lar amounts) exhibit similar beta. By contrast, the other strategies seem to favor slightly higher beta stocks on the long leg than on the short leg. The SMB factor is generally non-signiﬁcant and close to zero across all models. Exposure to HML varies across strategies. Whereas the LSTM favors glamour stocks (negative and signiﬁcant loading), the RAF has a tendency to select value stocks (positive and signiﬁcant loading); DNN and the simple logistic regression do not have any exposure. Most interesting are the factors capturing cross-sectional price dynamics, given that they are largely in line with the features we are feeding. We see that all models have pos- itive and statistically signiﬁcant exposure towards the momentum</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="49" height="0" alt="image" src="Deep learning with long short-term memory networks for financial/Image_240.png"/></span></p><p class="s20" style="padding-top: 1pt;padding-left: 9pt;text-indent: 0pt;text-align: left;"><a name="bookmark57">10</a><span class="s21">  </span><a href="http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html" class="s83" target="_blank">We thank French for providing all relevant data for these models on his </a><span class="s19">website</span><span class="s13">.</span></p><h2 style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;text-align: justify;">Table 4</h2><p class="s13" style="padding-left: 13pt;text-indent: 0pt;text-align: justify;">Exposure to systematic sources of risk of the LSTM, RAF, DNN, and LOG strate- gies prior to transaction costs from December 1992 to October 2015. Standard errors are depicted in parentheses.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="312" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_241.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:13.835pt" cellspacing="0"><tr style="height:9pt"><td style="width:70pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:44pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 6pt;text-align: left;">LSTM</p></td><td style="width:41pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 6pt;text-align: left;">RAF</p></td><td style="width:40pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 6pt;text-align: left;">DNN</p></td><td style="width:40pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 6pt;text-align: left;">LOG</p></td></tr><tr style="height:12pt"><td style="width:70pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">(Intercept)</p></td><td style="width:44pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">0<span class="s71">.</span>0042<span class="s74">∗∗∗</span></p></td><td style="width:41pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0<span class="s71">.</span>0034<span class="s74">∗∗∗</span></p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0<span class="s71">.</span>0021<span class="s74">∗∗∗</span></p></td><td style="width:40pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0<span class="s71">.</span>0014<span class="s74">∗∗∗</span></p></td></tr><tr style="height:9pt"><td style="width:70pt"/><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0003)</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0003)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0003)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0003)</p></td></tr><tr style="height:18pt"><td style="width:70pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Market</p></td><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s25">−</span>0<span class="s71">.</span>0023</p><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0255)</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>2107<span class="s74">∗∗∗</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">(0.0248)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>0926<span class="s74">∗∗</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">(0.0293)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>1845<span class="s74">∗∗∗</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">(0.0303)</p></td></tr><tr style="height:10pt"><td style="width:70pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">SMB</p></td><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s25">−</span>0<span class="s71">.</span>0576</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0117</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s25">−</span>0<span class="s71">.</span>1190<span class="s74">∗</span></p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s25">−</span>0<span class="s71">.</span>1414<span class="s74">∗</span></p></td></tr><tr style="height:8pt"><td style="width:70pt"/><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0484)</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0470)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0556)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0574)</p></td></tr><tr style="height:10pt"><td style="width:70pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">HML</p></td><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s25">−</span>0<span class="s71">.</span>2192<span class="s74">∗∗∗</span></p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>5377<span class="s74">∗∗∗</span></p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s25">−</span>0<span class="s71">.</span>0269</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1103</p></td></tr><tr style="height:8pt"><td style="width:70pt"/><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0574)</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0557)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0659)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0681)</p></td></tr><tr style="height:9pt"><td style="width:70pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Momentum</p></td><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>1241<span class="s74">∗∗∗</span></p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>1098<span class="s74">∗∗</span></p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>8903<span class="s74">∗∗∗</span></p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>6865<span class="s74">∗∗∗</span></p></td></tr><tr style="height:9pt"><td style="width:70pt"/><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0345)</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0334)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0396)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0409)</p></td></tr><tr style="height:9pt"><td style="width:70pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Short-term  reversal</p></td><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>3792<span class="s74">∗∗∗</span></p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>7475<span class="s74">∗∗∗</span></p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0<span class="s71">.</span>9620<span class="s74">∗∗∗</span></p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.0885<span class="s74">∗∗∗</span></p></td></tr><tr style="height:9pt"><td style="width:70pt"/><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0336)</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0327)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0386)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">(0.0399)</p></td></tr><tr style="height:10pt"><td style="width:70pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Long-term reversal</p></td><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0549</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s25">−</span>0<span class="s71">.</span>1827<span class="s74">∗∗</span></p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s25">−</span>0<span class="s71">.</span>1675<span class="s74">∗</span></p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><span class="s25">−</span>0<span class="s71">.</span>1771<span class="s74">∗</span></p></td></tr><tr style="height:9pt"><td style="width:70pt"/><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0683)</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0663)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0785)</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">(0.0811)</p></td></tr><tr style="height:11pt"><td style="width:70pt"><p class="s75" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">R<span class="s70">2</span></p></td><td style="width:44pt"><p class="s24" style="padding-top: 1pt;padding-left: 5pt;text-indent: 0pt;text-align: left;">0.0330</p></td><td style="width:41pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.1338</p></td><td style="width:40pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.1825</p></td><td style="width:40pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.1734</p></td></tr><tr style="height:9pt"><td style="width:70pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Adj. <i>R</i><span class="s76">2</span></p></td><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;text-align: left;">0.0320</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.1329</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.1816</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.1725</p></td></tr><tr style="height:9pt"><td style="width:70pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Num. obs.</p></td><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">5750</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">5750</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">5750</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">5750</p></td></tr><tr style="height:8pt"><td style="width:70pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">RMSE</p></td><td style="width:44pt"><p class="s24" style="padding-left: 5pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0206</p></td><td style="width:41pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0200</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0237</p></td><td style="width:40pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0244</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 13pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="312" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_242.png"/></span></p><p class="s30" style="padding-left: 13pt;text-indent: 0pt;text-align: justify;"><span class="s17">∗∗∗</span><span class="s18"> </span><span class="s11">p </span>&lt; .<span class="s13">001</span>, <span class="s17">∗∗</span><span class="s18"> </span><span class="s11">p </span>&lt; .<span class="s13">01</span>, <span class="s17">∗</span><span class="s18"> </span><span class="s11">p </span>&lt; .<span class="s13">05</span>.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">and the short-term reversal factor – meaning that shorter-term cross-sectional price dynamics are captured. Interestingly enough, these price-based factor loadings are more dominant for the logis- tic regression compared to the LSTM. This increase in loadings may be due to the fact that the simpler model is structurally unable to extract higher-order patterns from the supplied features – given that we did not feed any interactions. Lastly, the long-term rever- sal factor is insigniﬁcant for the LSTM, and has slightly negative loadings for the other strategies, albeit at lower levels of signiﬁ- cance. We believe that this factor has generally lower explanatory power, given that we are addressing a very short trading horizon. In a nutshell, the LSTM returns can barely be explained by system- atic sources of risk – and much less so than those of the other machine learning models we have deployed.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li style="padding-left: 22pt;text-indent: -16pt;text-align: justify;"><p class="s23" style="display: inline;">Robustness to market microstructure</p></li></ol></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark70" class="s22">A key result of the last subsection is that the LSTM-based stock selection exhibits similarities to a typical contrarian investment strategy. Microstructural effects, particularly the bid-ask bounce, are commonly known to introduce an upward bias to such contrar- ian investment strategies – </a><a href="#bookmark88" class="s22">see </a><a href="#bookmark88" class="s15">Conrad and Kaul </a><a href="#bookmark70" class="s15">(1989)</a><a href="#bookmark70" class="s22">, </a><a href="#bookmark70" class="s15">Jegadeesh (1990)</a><a href="#bookmark75" class="s22">, </a><a href="#bookmark70" class="s15">Jegadeesh and Titman (1995)</a><a href="#bookmark105" class="s22">, </a><a href="#bookmark70" class="s15">Gatev et al. (2006)</a><a href="#bookmark70" class="s22">. The </a>un- derlying reason is simple. The LSTM strategy tends to buy recent losers and sell recent winners. Conditional on being among the top <i>k </i>stocks, the winner’s quote is more likely to be an ask quote, and conditional on being among the ﬂop <i>k </i><a href="#bookmark105" class="s22">stocks, the loser’s quote is more likely to be a bid quote – similar to the reasoning on the con- trarian investment strategy presented in </a><a href="#bookmark105" class="s15">Gatev et al. </a><span style=" color: #0080AC;">(2006)</span><a href="#bookmark57" class="s22">. Im- plicitly, we would thus be buying at the bid in case of the losers, and selling at the ask in case of the winners. The inverse applies when covering positions – part of the surge in prices of the re- cent loser may be driven by the jump from bid to ask, and part of the slump in prices of the recent winner may be driven by the jump from ask to bid. In light of these considerations, it is neces- sary to analyze the robustness of our ﬁndings.</a><span style=" color: #0080AC; font-family:&quot;Palatino Linotype&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt;">11</span><span class="s19"> </span>There are several solutions to this issue.</p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark92" class="s22">First, longer trading horizons are typically more robust to mi- crostructural effects. Following e.g., </a><a href="#bookmark92" class="s15">Lehmann </a>(1990) <span style=" color: #000;">in his short-</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="49" height="0" alt="image" src="Deep learning with long short-term memory networks for financial/Image_243.png"/></span></p><p class="s20" style="padding-top: 1pt;padding-left: 9pt;text-indent: 0pt;text-align: justify;">11<span class="s21">  </span><span class="s13">We thank an anonymous referee for suggesting this robustness check.</span></p><h2 style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: justify;"><a name="bookmark58">Table 5</a></h2><p class="s13" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: justify;">Panel A names the LSTM model variants, with different trading frequencies and types of execution (M<span class="s77">1</span><span class="s21">  </span>through M<span class="s77">5</span><span class="s21"> </span>). Panels B, C, and D illustrate performance characteristics of the <i>k </i><span class="s45">= </span><a href="http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html" class="s83" target="_blank">10 portfolio, before and after transaction costs for all ﬁve model variants, compared to the general market (MKT) from January 1998 to October 2015. MKT represents the general market as in Kenneth R. French’s data library, see </a><span style=" color: #0080AC;">here</span>. Panel B depicts daily return characteristics. Panel C depicts daily risk characteristics. Panel D depicts annualized risk-return metrics. Newey–West standard errors are used.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="689" height="1" alt="image" src="Deep learning with long short-term memory networks for financial/Image_244.png"/></span></p><p class="s13" style="padding-top: 1pt;padding-left: 104pt;text-indent: 0pt;text-align: left;">Before transaction costs                                                                           After transaction costs</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:6.6pt" cellspacing="0"><tr style="height:20pt"><td style="width:17pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">A</p></td><td style="width:74pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;padding-right: 36pt;text-indent: 0pt;text-align: left;">Model Frequency</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">M<span class="s78">1</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Daily</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">M<span class="s78">2</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Daily</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">M<span class="s78">3</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Weekly</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">M<span class="s78">4</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Weekly</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">M<span class="s78">5</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Weekly</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">M<span class="s78">1</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Daily</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">M<span class="s78">2</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Daily</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">M<span class="s78">3</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Weekly</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">M</p><p class="s79" style="padding-right: 11pt;text-indent: 0pt;line-height: 2pt;text-align: center;">4</p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Weekly</p></td><td style="width:39pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">M<span class="s78">5</span></p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Weekly</p></td><td style="width:38pt;border-top-style:solid;border-top-width:1pt"><p class="s24" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">MKT</p><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">–</p></td></tr><tr style="height:12pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Execution</p></td><td style="width:39pt"><p class="s80" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Close<span class="s70">t</span></p></td><td style="width:39pt"><p class="s80" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">VW<span class="s24">AP</span><span class="s70">t</span></p></td><td style="width:39pt"><p class="s80" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Close<span class="s70">t</span></p></td><td style="width:39pt"><p class="s80" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">VW<span class="s24">AP</span><span class="s70">t</span></p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">Close<span class="s78">t</span><span class="s81">+</span><span class="s70">1</span></p></td><td style="width:39pt"><p class="s80" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Close<span class="s70">t</span></p></td><td style="width:39pt"><p class="s80" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">VW<span class="s24">AP</span><span class="s70">t</span></p></td><td style="width:39pt"><p class="s80" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Close<span class="s70">t</span></p></td><td style="width:39pt"><p class="s80" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">VW<span class="s24">AP</span><span class="s70">t</span></p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">Close<span class="s78">t</span><span class="s81">+</span><span class="s70">1</span></p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">–</p></td></tr><tr style="height:10pt"><td style="width:17pt"><p class="s24" style="padding-right: 1pt;text-indent: 0pt;text-align: center;">B</p></td><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">Mean return (long)</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0025</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0021</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0014</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0012</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0013</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0015</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0011</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0012</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0010</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0011</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0003</p></td></tr><tr style="height:10pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Mean return (short)</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0014</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0015</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0001</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0001</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0000</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0004</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0005</p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.0001</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.0001</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.0002</span></p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">–</p></td></tr><tr style="height:8pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Mean return</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0040</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0036</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0015</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0013</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0013</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0020</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0016</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0011</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0009</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0009</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0003</p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Standard error</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0003</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0002</p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s66" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">t<span class="s24">-statistic</span></p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">11.9814</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">11.5662</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">5.7083</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">5.1998</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">4.9941</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">5.9313</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">5.1980</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">4.1749</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">3.6172</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">3.4622</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.8651</p></td></tr><tr style="height:10pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Minimum</p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.2176</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1504</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1261</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1156</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1246</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.2193</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1522</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1265</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1160</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.1250</span></p></td><td style="width:38pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.0895</span></p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Quartile 1</p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0064</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0064</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0068</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0064</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0068</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0084</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0084</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0072</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0068</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0072</span></p></td><td style="width:38pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0054</span></p></td></tr><tr style="height:8pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Median</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0030</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0027</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0009</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0007</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0010</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0010</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0007</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0005</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0003</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0006</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.0008</p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Quartile 3</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0136</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0124</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0092</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0082</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0089</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0116</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0104</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0088</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0078</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0085</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0064</p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Maximum</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1837</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1700</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2050</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1814</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1997</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1815</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1678</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2045</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1810</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1993</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1135</p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Share  <span class="s71">&gt; </span>0</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5847</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5807</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5337</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5299</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5379</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5276</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5212</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5216</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5120</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5234</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5384</p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Standard  dev.</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0224</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0208</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0185</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0177</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0181</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0224</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0208</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0185</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0177</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0181</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0127</p></td></tr><tr style="height:10pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Skewness</p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.0682</span></p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4293</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.9199</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.6518</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.8163</p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.0682</span></p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4293</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.9195</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.6515</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.8160</p></td><td style="width:38pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 9pt;text-align: left;">−<span class="s24">0.0737</span></p></td></tr><tr style="height:10pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Kurtosis</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">10.9634</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">6.1028</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">12.3432</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">9.5637</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">12.7913</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">10.9634</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">6.1028</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">12.3409</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">9.5620</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">12.7897</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">6.7662</p></td></tr><tr style="height:12pt"><td style="width:17pt"><p class="s24" style="padding-top: 1pt;padding-right: 1pt;text-indent: 0pt;text-align: center;">C</p></td><td style="width:74pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">1-percent VaR</p></td><td style="width:39pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0571</span></p></td><td style="width:39pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0524</span></p></td><td style="width:39pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0516</span></p></td><td style="width:39pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0470</span></p></td><td style="width:39pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0493</span></p></td><td style="width:39pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0591</span></p></td><td style="width:39pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0544</span></p></td><td style="width:39pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0520</span></p></td><td style="width:39pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0474</span></p></td><td style="width:39pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0496</span></p></td><td style="width:38pt"><p class="s25" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">−<span class="s24">0.0341</span></p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">1-percent CVaR</p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0861</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0717</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0662</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0659</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0673</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0880</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0736</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0666</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0663</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0676</span></p></td><td style="width:38pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0491</span></p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">5-percent VaR</p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0271</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0268</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0251</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0239</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0252</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0291</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0287</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0255</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0243</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0256</span></p></td><td style="width:38pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0195</span></p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">5-percent CVaR</p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0468</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0432</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0412</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0395</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0403</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0487</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0452</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0416</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0399</span></p></td><td style="width:39pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0407</span></p></td><td style="width:38pt"><p class="s25" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">−<span class="s24">0.0297</span></p></td></tr><tr style="height:10pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">Max.  drawdown</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.4660</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.3717</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.3634</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.4695</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.3622</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.5230</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.6822</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.4041</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.5808</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.3794</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: left;">0.5467</p></td></tr><tr style="height:11pt"><td style="width:17pt"><p class="s24" style="padding-top: 1pt;text-indent: 0pt;text-align: center;">D</p></td><td style="width:74pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">Return p.a.</p></td><td style="width:39pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">1.5439</p></td><td style="width:39pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">1.3639</p></td><td style="width:39pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.3939</p></td><td style="width:39pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.3384</p></td><td style="width:39pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.3328</p></td><td style="width:39pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.5376</p></td><td style="width:39pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.4287</p></td><td style="width:39pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.2604</p></td><td style="width:39pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.2103</p></td><td style="width:39pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.2052</p></td><td style="width:38pt"><p class="s24" style="padding-top: 1pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">0.0668</p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Excess return p.a.</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.4923</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.3159</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3655</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3112</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3056</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.5063</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3996</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2348</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1856</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1806</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.0450</p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Standard dev. p.a.</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3561</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3308</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2940</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2818</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2879</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3557</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.3305</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2939</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2817</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2879</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2016</p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Downside dev. p.a.</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2192</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1962</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1863</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1802</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1851</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2323</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2103</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1891</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1830</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1879</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.1424</p></td></tr><tr style="height:9pt"><td style="width:17pt"/><td style="width:74pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Sharpe ratio p.a.</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">4.1908</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">3.9777</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.2433</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.1043</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.0615</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.4233</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.2091</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.7988</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.6589</p></td><td style="width:39pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.6274</p></td><td style="width:38pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.2234</p></td></tr><tr style="height:12pt"><td style="width:17pt;border-bottom-style:solid;border-bottom-width:1pt"/><td style="width:74pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Sortino ratio p.a.</p></td><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">7.0444</p></td><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">6.9507</p></td><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">2.1145</p></td><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.8784</p></td><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.7982</p></td><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">2.3139</p></td><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">2.0380</p></td><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.3770</p></td><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.1488</p></td><td style="width:39pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">1.0916</p></td><td style="width:38pt;border-bottom-style:solid;border-bottom-width:1pt"><p class="s24" style="padding-left: 6pt;text-indent: 0pt;line-height: 8pt;text-align: left;">0.4689</p></td></tr></table><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-top: 2pt;padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><a href="#bookmark64" class="s22">term reversal strategy or </a><a href="#bookmark64" class="s15">Huck (2009, </a>2010) <span style=" color: #000;">in his machine learn- ing strategies, we introduce a weekly variant of the LSTM strategy</span></p><ul id="l13"><li style="padding-left: 6pt;text-indent: 0pt;text-align: justify;"><p class="s16" style="display: inline;"><a href="#bookmark31" class="s22">effectively bridging the gap between lower turnover (weekly vs. daily), and retaining a suﬃcient number of training examples for the LSTM to successfully extract structure from the data. The lat- ter excludes a monthly variant, without signiﬁcantly changing the study design. Speciﬁcally, we design the LSTM in full analogy to the cornerstones outlined in </a><a href="#bookmark31" class="s15">Section </a>3<a href="#bookmark59" class="s22">, but on a 5-day instead of a 1-day horizon.</a><span style=" color: #0080AC; font-family:&quot;Palatino Linotype&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt;">12</span><span class="s19"> </span><a href="#bookmark73" class="s22">Moreover, we implement ﬁve overlapping port- folios of LSTM strategies with a 5-day forecast horizon to avoid a bias introduced by the starting date (</a><a href="#bookmark73" class="s15">Jegadeesh &amp; Titman, </a>1993<span style=" color: #000;">). Thereby, each portfolio is offset to the other by one trading day, and returns are averaged across all portfolios. Note that we log the invested capital market-to-market on a daily basis for all ﬁve port- folios, so we are able to exhibit daily returns for the sake of com- parability.</span></p><p class="s16" style="padding-left: 6pt;text-indent: 11pt;text-align: justify;"><a href="#bookmark89" class="s22">Second, execution on volume-weighted-average-prices (VWAPs) is more realistic and much less susceptible to bid-ask bounce (see for example, </a><a href="#bookmark89" class="s15">Lee, Chan, Faff, &amp; Kalev, </a>2003<a href="#bookmark31" class="s22">). Hence, we use minute- binned transaction data  from  January  1998  to  October  2015  for all S&amp;P 500 stocks from QuantQuote to create VWAPs, which we use for feature engineering, for target creation, and for backtest- ing – see </a><a href="#bookmark31" class="s15">Section </a>3<a href="#bookmark60" class="s22">.</a><span style=" color: #0080AC; font-family:&quot;Palatino Linotype&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 6pt; vertical-align: 3pt;">13</span><span class="s19"> </span><span style=" color: #000;">Speciﬁcally, we divide the 391 minute-bins of each trading day (starting at 09:30 and ending at 16:00, includ-</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 1pt;text-align: left;"><span><img width="49" height="0" alt="image" src="Deep learning with long short-term memory networks for financial/Image_245.png"/></span></p><p class="s20" style="padding-top: 1pt;padding-left: 6pt;text-indent: 3pt;text-align: justify;"><a name="bookmark59">12</a><span class="s21"> </span><span class="s13">As such, the time step, the forecast horizon, and the raw returns comprise a du- ration of 5 days. In analogy, the sequence length is 52 to reﬂect one year, consisting of 52 weeks.</span><a name="bookmark60">&zwnj;</a></p><p class="s16" style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><a href="#bookmark33" class="s22">ing the opening) in 23 bins of 17 minutes duration, so we obtain 23 VWAPs. We use the 22nd VWAP as anchor point for creating features, and the 23rd VWAP for executing our trades, and create features in full analogy to </a><a href="#bookmark33" class="s15">Section </a>3.2<span style=" color: #000;">.</span></p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark105" class="s22">Third, a one-day-waiting rule as in </a><a href="#bookmark105" class="s15">Gatev et al. </a>(2006) <span style=" color: #000;">is  a proper remedy against bid-ask bounce. Speciﬁcally, we delay the execution by one entire trading day after signal generation. This rule only makes sense for the weekly strategy. In case of the daily strategy, the delay covers the entire forecast horizon, rendering the predictions null and void.</span></p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark77" class="s22">Fourth, for the sake of completeness, we use transaction costs of 5 bps per half-turn throughout this paper – a fairly robust value for U.S. large caps. For example, </a><a href="#bookmark77" class="s15">Jha </a>(2016) <span style=" color: #000;">assumes merely 2 bps for the largest 500 stocks of the U.S. stock universe over a similar time horizon.</span></p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 93%;text-align: right;">In a nutshell, we run the following robustness checks on the LSTM strategy. Model M<span class="s47">1 </span><span class="s13"> </span>is the baseline, showing the results of the standard LSTM strategy as discussed in the previous sections, i.e., with daily turnover and execution on the close, but constrained to the time frame of the QuantQuote data set from 1998 to 2015. Model M<span class="s47">2 </span><span class="s13"> </span>shows the effects when executing this strategy on the VWAP instead of the closing price. Models M<span class="s47">3</span>–M<span class="s47">5</span><span class="s13"> </span>are weekly vari- ants of the baseline strategy. Thereby, M<span class="s47">3 </span><span class="s13"> </span>is executed on the clos- ing price, M<span class="s47">4 </span><span class="s13"> </span>on the VWAP, and M<span class="s47">5 </span><span class="s13"> </span><a href="#bookmark58" class="s22">with a one-day-waiting rule on the closing price. The results of these variants are depicted in </a><a href="#bookmark58" class="s15">Table </a><span style=" color: #0080AC;">5 </span>– before and after transaction costs of 5 bps per half-turn.</p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 93%;text-align: justify;">After transaction costs, the baseline LSTM strategy <i>M</i><span class="s47">1</span><span class="s13"> </span>results in average returns of 0.20 percent per day on the  shorter  time frame from 1998 to 2015. Executing on VWAPs instead of at the</p><p class="s20" style="padding-left: 9pt;text-indent: 0pt;line-height: 8pt;text-align: left;">13<span class="s21">  </span><span class="s13">To be able to evaluate the performance of the LSTM over the whole period from</span></p><p style="padding-left: 9pt;text-indent: 0pt;line-height: 10pt;text-align: left;">closing price in case of model M<span class="s47">2</span></p><p style="padding-left: 1pt;text-indent: 0pt;line-height: 10pt;text-align: left;">leads to a deterioration to 0.16</p><p class="s13" style="padding-left: 6pt;text-indent: 0pt;line-height: 7pt;text-align: justify;">January 1998 until October 2015, we use the Thomson Reuters dataset to train the</p><p class="s13" style="padding-left: 6pt;text-indent: 0pt;text-align: justify;">model on the ﬁrst 750 days prior to January 1998. Out-of-sample prediction (trad- ing) is then performed on the VWAPs calculated from the QuantQuote data. In all following study periods, we train and predict on the QuantQuote data.</p><p style="padding-left: 6pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">percent per day – still statistically signiﬁcant with a  <i>t</i>-statistic above 5 and economically meaningful with returns  of  43  per- cent p.a. The weekly strategies generate similar returns per day,</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 9pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="631" height="176" alt="image" src="Deep learning with long short-term memory networks for financial/Image_246.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="40" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_247.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="39" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_248.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="40" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_249.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="40" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_250.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><span><img width="40" height="6" alt="image" src="Deep learning with long short-term memory networks for financial/Image_251.png"/></span></p><p class="s13" style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;line-height: 9pt;text-align: left;"><a name="bookmark61"><span class="h2">Fig. 9.  </span></a>Contrast LSTM model variants’ performance from January 1998 to October 2015 for the <i>k </i><span class="s45">= </span>10 portfolio, i.e., development of cumulative proﬁts on 1 USD average investment per day after transaction costs.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">i.e., 0.11 percent in case of M<span class="s47">3</span><span class="s13"> </span>(execution on close), 0.09 percent in case of M<span class="s47">4</span><span class="s13"> </span>(execution on VWAP), and 0.09 percent in case of M<span class="s47">5</span><span class="s13"> </span>(execution on close, one-day-waiting) – all of them statistically and economically signiﬁcant with <i>t</i><a href="#bookmark47" class="s22">-statistics above 3 and annual- ized returns above 20 percent. The rest of the table reads in full analogy to </a><a href="#bookmark47" class="s15">Table </a><span style=" color: #0080AC;">3</span>, and shows a relative outperformance of the LSTM strategy compared to the general market, after robustness checks.</p><p class="s16" style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;"><a href="#bookmark61" class="s22" name="bookmark23">In recent years, however, as depicted in </a><a href="#bookmark61" class="s15">Fig. </a>9<span style=" color: #000;">, we see that re- turns ﬂatten out, so the LSTM edge seems to have been arbitraged away. Despite of this fact, model performance is robust in light of market frictions over an extended period of time, i.e., from 1998 up until 2009, with particular upward spikes in returns around the ﬁnancial crisis.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ul></li></ol></li></ol></li><li style="padding-left: 16pt;text-indent: -10pt;text-align: justify;"><h1 style="display: inline;"><a name="bookmark62">Conclusion</a></h1></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 5pt;text-indent: 11pt;line-height: 11pt;text-align: justify;">In this paper, we apply long-short term memory networks to a large-scale ﬁnancial market prediction task on the S&amp;P 500, from December 1992 until October 2015. With our work, we make three key contributions to the literature: the ﬁrst contribution focuses on the large-scale empirical application of LSTM networks to ﬁnancial time series prediction tasks. We provide an in-depth guide, closely following the entire data science value chain. Speciﬁcally, we frame a proper prediction task, derive sensible features in the form of 240-day return sequences, standardize the features during prepro- cessing to facilitate model training, discuss a suitable LSTM archi- tecture and training algorithm, and derive a trading strategy based on the predictions, in line with the existing literature. We compare the results of the LSTM against a random forest, a standard deep net, as well as a simple logistic regression. We ﬁnd the LSTM, a methodology inherently suitable for this domain, to beat the stan- dard deep net and the logistic regression by a very clear margin. Most of the times – with the exception of the global ﬁnancial crisis</p><ul id="l14"><li style="padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;"><p style="display: inline;"><a name="bookmark24">the random forest is also outperformed. Our ﬁndings of statisti- cally and economically signiﬁcant returns of 0.46 percent per day prior to transaction costs posit a clear challenge to the semi-strong form of market eﬃciency, and show that deep learning could have been an effective predictive modeling technique in this domain up until 2010. These ﬁndings are largely robust in light of market fric- tions, given that proﬁtability remains statistically and economically signiﬁcant when executing the daily LSTM strategy on VWAPs in- stead of closing prices, and when running a weekly variant of the LSTM strategy with a one-day waiting period after signal genera-</a></p></li></ul><p style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;line-height: 11pt;text-align: justify;">tion. As of 2010, the markets exhibit an increase in eﬃciency with respect to the machine learning methods we deploy, with LSTM proﬁtability ﬂuctuating around zero and RAF proﬁtability dipping strictly into the negative domain.</p><p style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">Also, the conceptual and empirical aspects on LSTM networks outlined in this paper go beyond a pure ﬁnancial market applica- tion, but are intended as guideline for other researchers, wishing to deploy this effective methodology to other time series predic- tion tasks with large amounts of training data.</p><p style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">Second, we disentangle the black-box “LSTM”, and unveil com- mon patterns of stocks that are selected for proﬁtable trading. We ﬁnd that the LSTM portfolio consist of stocks with below-mean momentum, strong short-term reversal characteristics, high volatil- ity and beta. All these  ﬁndings  relate  to  some  extent  to  exist- ing capital market  anomalies.  It  is  impressive  to  see  that  some of them are independently extracted by the LSTM from a 240-day sequence of standardized raw returns. It is subject to future re- search to identify further, more subtle patterns LSTM neural net- works learn from ﬁnancial market data, and to validate the proﬁt potential of these patterns in more reﬁned, rules-based trading strategies.</p><p style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">Third, based on the common patterns of the LSTM portfolio, we devise a simpliﬁed rules-based trading strategy. Speciﬁcally, we short short-term winners and buy short-term losers, and hold the position for one day – just like in the LSTM application. With this transparent, simpliﬁed strategy, we achieve returns of 0.23 percent per day prior to transaction costs – about 50 percent of the LSTM returns. Further regression analysis on common sources of system- atic risk unveil a remaining alpha of 0.42 percent of the LSTM prior to transaction costs and generally a lower risk exposure compared to the other models we deploy.</p><p style="padding-left: 5pt;text-indent: 11pt;text-align: justify;">Overall, we have successfully demonstrated that an LSTM net- work is able to effectively extract meaningful information from noisy ﬁnancial time series data. Compared to random forests, stan- dard deep nets, and logistic regression, it is the method of choice with respect to predictional accuracy and with respect to daily re- turns after transaction costs. As it turns out, deep learning – in the form of LSTM networks – hence seems to constitute an advance- ment in this domain as well.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 5pt;text-indent: 0pt;text-align: justify;">Appendix. Detailed industry breakdown</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s16" style="padding-left: 17pt;text-indent: 0pt;text-align: left;"><a href="#bookmark63" class="s15">Fig. </a>A1<span style=" color: #000;">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 30pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="293" height="163" alt="image" src="Deep learning with long short-term memory networks for financial/Image_252.png"/></span>	<span><img width="293" height="161" alt="image" src="Deep learning with long short-term memory networks for financial/Image_253.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 30pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="293" height="161" alt="image" src="Deep learning with long short-term memory networks for financial/Image_254.png"/></span>	<span><img width="293" height="163" alt="image" src="Deep learning with long short-term memory networks for financial/Image_255.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 30pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="294" height="163" alt="image" src="Deep learning with long short-term memory networks for financial/Image_256.png"/></span>	<span><img width="293" height="163" alt="image" src="Deep learning with long short-term memory networks for financial/Image_257.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 30pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="294" height="163" alt="image" src="Deep learning with long short-term memory networks for financial/Image_258.png"/></span>	<span><img width="293" height="163" alt="image" src="Deep learning with long short-term memory networks for financial/Image_259.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s59" style="padding-left: 30pt;text-indent: 0pt;line-height: 10pt;text-align: left;"><span><img width="294" height="163" alt="image" src="Deep learning with long short-term memory networks for financial/Image_260.png"/></span>	<span><img width="293" height="163" alt="image" src="Deep learning with long short-term memory networks for financial/Image_261.png"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><h2 style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark63">Fig. A1.  </a><span class="s13">Time-varying share of industries in the “top-10” and “ﬂop-10” portfolio minus share of these industries in the S&amp;P 500, calculated over number of stocks. A positive value indicates that the industry is overweighted and vice versa.</span></h2><h1 style="padding-top: 2pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><a name="bookmark25">References</a><a name="bookmark64">&zwnj;</a><a name="bookmark65">&zwnj;</a></h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s19" style="padding-left: 17pt;text-indent: -12pt;line-height: 8pt;text-align: justify;"><a href="http://tensorflow.org/" class="s83" target="_blank" name="bookmark66">Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., et al., (2015). Tensor- Flow: Large-scale machine learning on heterogeneous systems. Software avail- able from tensorﬂow.org, </a><a href="http://tensorflow.org/" class="a" target="_blank">http://tensorﬂow.org</a>/<span style=" color: #000;">.</span><a name="bookmark67">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0001" class="a" target="_blank" name="bookmark68">Atsalakis, G. S., &amp; Valavanis, K. P. (2009). Surveying stock market forecasting tech-  niques – Part II: Soft computing methods. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0001" class="s82" target="_blank">Expert  Systems  with  Applications, 36</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0001" class="a" target="_blank">(3),    5932–5941.</a><a name="bookmark69">&zwnj;</a></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0002" class="a" target="_blank" name="bookmark70">Avellaneda, M., &amp; Lee, J.-H. (2010). Statistical arbitrage in the US equities market.</a><a name="bookmark71">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0002" class="s82" target="_blank">Quantitative Finance, 10</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0002" class="a" target="_blank">(7), 761–782.</a></p><p style="padding-left: 5pt;text-indent: 0pt;text-align: right;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0003" class="a" target="_blank" name="bookmark72">Baker, M., Bradley, B., &amp; Wurgler, J. (2011). Benchmarks as limits to arbitrage: Un- derstanding the low-volatility anomaly. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0003" class="s82" target="_blank">Financial Analysts Journal, 67</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0003" class="a" target="_blank">(1), </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0004" class="a" target="_blank">40–54.   Bali, T. G., Cakici, N., &amp; Whitelaw, R. F. (2011). Maxing out: Stocks as lotteries and the cross-section of expected returns. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0004" class="s82" target="_blank">Journal of Financial Economics, 99</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0004" class="a" target="_blank">(2), 427–446.</a><a name="bookmark73">&zwnj;</a><a name="bookmark74">&zwnj;</a><a name="bookmark75">&zwnj;</a></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;text-align: right;"><a name="bookmark76">Bogomolov, T. (2013). Pairs trading based on statistical variability of the spread pro- cess.  </a><i>Quantitative  Finance,  13</i><a href="https://doi.org/10.1080/14697688.2012.748934" class="s83" target="_blank">(9),  1411–1430.  doi:</a><span style=" color: #0080AC;">10.1080/14697688.2012.748934.</span><a name="bookmark77">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0006" class="a" target="_blank" name="bookmark78">Boyer, B., Mitton, T., &amp; Vorkink, K. (2010). Expected idiosyncratic skewness. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0006" class="s82" target="_blank">Review of  Financial  Studies,  23</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0006" class="a" target="_blank">(1),  169–202.</a><a name="bookmark79">&zwnj;</a><a name="bookmark80">&zwnj;</a></p><p class="s19" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0007" class="a" target="_blank" name="bookmark81">Breiman, L. (2001). Random forests. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0007" class="s82" target="_blank">Machine learning, 45</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0007" class="a" target="_blank">(1), </a>5–32.</p><p style="padding-left: 17pt;text-indent: -12pt;text-align: left;"><a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/" class="s83" target="_blank" name="bookmark82">Britz,  D.  (2015).  Recurrent  neural  network  tutorial,  part  4  –  Implementing  a GRU/LSTM RNN with Python and Theano. </a><a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/" class="a" target="_blank">http://www.wildml.com/2015/10/  recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with- python-and-theano/</a><a href="http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/" class="s83" target="_blank">.</a><a name="bookmark83">&zwnj;</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a name="bookmark84">Carhart, M. M. (1997). On persistence in mutual fund performance. </a><i>The Journal of Finance,  52</i><a href="https://doi.org/10.2307/2329556" class="s83" target="_blank">(1),  57.  doi:</a><span style=" color: #0080AC;">10.2307/2329556.</span><a name="bookmark85">&zwnj;</a><a name="bookmark86">&zwnj;</a></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="https://github.com/fchollet/keras" class="s83" target="_blank" name="bookmark87">Chollet, F. (2016). Keras. </a><a href="https://github.com/fchollet/keras" class="a" target="_blank">https://github.com/fchollet/keras</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a name="bookmark88">Clegg, M., &amp; Krauss, C. (2018). Pairs trading with partial cointegration. </a><i>Quantitative Finance,    18</i><a href="https://doi.org/10.1080/14697688.2017.1370122" class="s83" target="_blank">(1),    121–138.    doi:</a><span style=" color: #0080AC;">10.1080/14697688.2017.1370122.</span><a name="bookmark89">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0010" class="a" target="_blank" name="bookmark90">Conrad, J., &amp; Kaul, G. (1989). Mean reversion in short-horizon expected returns. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0010" class="s82" target="_blank">Re- view  of  Financial  Studies,  2</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0010" class="a" target="_blank">(2),  225–240.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0011" class="a" target="_blank" name="bookmark91">Diebold, F. X., &amp; Mariano, R. S. (1995). Comparing predictive accuracy. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0011" class="s82" target="_blank">Journal of Business  &amp;  Economic  Statistics, 13</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0011" class="a" target="_blank">(3),  253–263.</a><a name="bookmark92">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0012" class="a" target="_blank" name="bookmark93">Dixon, M., Klabjan, D., &amp; Bang, J. H. (2015). Implementing deep neural networks for ﬁnancial market prediction on the  Intel Xeon Phi. In </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0012" class="s82" target="_blank">Proceedings of the eighth workshop  on  high  performance  computational  ﬁnance  </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0012" class="a" target="_blank">(pp.  1–6).</a><a name="bookmark94">&zwnj;</a><a name="bookmark95">&zwnj;</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a name="bookmark96">Engelberg, J., Reed, A. V., &amp; Ringgenberg, M. (2017). Short selling risk. </a><i>Journal of Finance</i><a href="https://doi.org/10.2139/ssrn.2312625" class="s83" target="_blank">.   doi:</a><span style=" color: #0080AC;">10.2139/ssrn.2312625.   </span>(forthcoming)<a name="bookmark97">&zwnj;</a></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a name="bookmark98">Fama, E. F. (1970). Eﬃcient capital markets: A review of theory and empirical work.</a></p><p class="s11" style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a name="bookmark99">The Journal of Finance, 25</a><a href="https://doi.org/10.2307/2325486" class="s83" target="_blank">(2), 383–417. doi:</a><span class="s19">10.2307/2325486.</span></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a name="bookmark100">Fama, E. F., &amp; French, K. R. (1996). Multifactor explanations of asset pricing anoma- lies.  </a><i>The  Journal  of  Finance,  51</i><a href="https://doi.org/10.2307/2329302" class="s83" target="_blank">(1),  55–84.  doi:</a><span style=" color: #0080AC;">10.2307/2329302.</span><a name="bookmark101">&zwnj;</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a name="bookmark102">Frazzini, A., &amp; Pedersen, L. H. (2014). Betting against beta. </a><i>Journal of Financial Eco- nomics,   111</i><a href="https://doi.org/10.1016/j.jfineco.2013.10.005" class="s83" target="_blank">(1),   1–25.   doi:</a><span style=" color: #0080AC;">10.1016/j.jﬁneco.2013.10.005.</span><a name="bookmark103">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0017" class="a" target="_blank" name="bookmark104">Gal, Y., &amp; Ghahramani, Z. (2016). A theoretically grounded application of dropout in recurrent neural networks. In </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0017" class="s82" target="_blank">Proceedings of the 2016 advances  in  neural  infor- mation  processing  systems  </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0017" class="a" target="_blank">(pp.  1019–1027).</a><a name="bookmark105">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0018" class="a" target="_blank" name="bookmark106">Gatev, E., Goetzmann, W. N., &amp; Rouwenhorst, K. G. (2006). Pairs trading: Per-  formance of a relative-value arbitrage rule. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0018" class="s82" target="_blank">Review of Financial Studies, 19</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0018" class="a" target="_blank">(3), 797–827.</a><a name="bookmark107">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0019" class="a" target="_blank" name="bookmark108">Gers, F. A., Schmidhuber, J., &amp; Cummins, F. (2000). Learning to forget: Continual prediction with LSTM. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0019" class="s82" target="_blank">Neural Computation, 12</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0019" class="a" target="_blank">(10), 2451–2471.</a><a name="bookmark109">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0020" class="a" target="_blank" name="bookmark110">Giles, C. L., Lawrence, S., &amp; Tsoi, A. C. (2001). Noisy time series prediction using recurrent neural networks and grammatical inference. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0020" class="s82" target="_blank">Machine Learning, 44</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0020" class="a" target="_blank">(1), 161–183.</a><a name="bookmark111">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref1767" class="a" target="_blank" name="bookmark112">Goodfellow, I., Warde-Farley, D., Mirza, M., Courville, A., &amp; Bengio, Y. (2013). Maxout  networks. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref1767" class="s82" target="_blank">Proceedings of the 30th  International  Conference  on  Machine  Learning </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref1767" class="a" target="_blank">(pp.   1319–1327).</a><a name="bookmark113">&zwnj;</a></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0021" class="a" target="_blank" name="bookmark114">Granger, C. W. (1993). Strategies for modelling nonlinear time-series relationships.</a><a name="bookmark115">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0021" class="s82" target="_blank">Economic Record, 69</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0021" class="a" target="_blank">(3), 233–238.</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a name="bookmark116">Graves, A. (2013). Generating sequences with recurrent neural networks. </a><i>CoRR</i>, arXiv preprint   arXiv:<span style=" color: #0080AC;">1308.0850</span>.<a name="bookmark117">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0022" class="a" target="_blank">Graves, A., Liwicki, M., Fernández,  S.,  Bertolami,  R.,  Bunke,  H.,  &amp;  Schmidhu- ber, J. (2009). A novel connectionist system for unconstrained handwriting recognition. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0022" class="s82" target="_blank">IEEE Transactions on Pattern Analysis and Machine Intelligence, 31</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0022" class="a" target="_blank">(5), 855–868.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0023" class="a" target="_blank" name="bookmark118">Graves, A., Mohamed, A.-r., &amp; Hinton, G. (2013). Speech recognition with deep re- current neural networks. In </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0023" class="s82" target="_blank">Proceedings of the 2013 IEEE international conference on acoustics, speech and  signal processing </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0023" class="a" target="_blank">(pp.  6645–6649). IEEE.</a><a name="bookmark119">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0024" class="a" target="_blank" name="bookmark120">Graves, A., &amp; Schmidhuber, J. (2005). Framewise phoneme classiﬁcation with bidi-  rectional LSTM and other neural network architectures. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0024" class="s82" target="_blank">Neural Networks, 18</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0024" class="a" target="_blank">(5), 602–610.</a><a name="bookmark121">&zwnj;</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a name="bookmark122">Green, J., Hand, J. R. M., &amp; Zhang, X. F. (2017). The characteristics that provide in-  dependent information about average U.S. monthly stock returns. </a><i>The Review of Financial  Studies,  30</i><a href="https://doi.org/10.1093/rfs/hhx019" class="s83" target="_blank">(12),  4389–4436.  doi:</a><span style=" color: #0080AC;">10.1093/rfs/hhx019.</span><a name="bookmark123">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="https://doi.org/10.1007/s11142-013-9231-1" class="s83" target="_blank" name="bookmark124">Green, J., Hand, J. R. M., &amp; Zhang, X. F. (2013).  The  supraview  of  return  pre- dictive signals. </a><a href="https://doi.org/10.1007/s11142-013-9231-1" class="s84" target="_blank">Review of Accounting Studies, 18</a><a href="https://doi.org/10.1007/s11142-013-9231-1" class="s83" target="_blank">(3), 692–730. doi:</a><a href="https://doi.org/10.1007/s11142-013-9231-1" class="a" target="_blank">10.1007/ s11142-013-9231-1.</a><a name="bookmark125">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0027" class="a" target="_blank" name="bookmark126">Gregoriou, G. N. (2012). </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0027" class="s82" target="_blank">Handbook of short selling</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0027" class="a" target="_blank">. Amsterdam and Boston, MA: Aca- demic Press.</a><a name="bookmark127">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://h2o-release.s3.amazonaws.com/h2o/rel-tukey/4/docs-website/h2o-docs/index.html" class="s83" target="_blank" name="bookmark128">H2O (2016). H2O documentation. </a><a href="http://h2o-release.s3.amazonaws.com/h2o/rel-tukey/4/docs-website/h2o-docs/index.html" class="a" target="_blank">http://h2o.ai/docs</a><a href="http://h2o-release.s3.amazonaws.com/h2o/rel-tukey/4/docs-website/h2o-docs/index.html" class="s83" target="_blank">, </a><a href="http://h2o-release.s3.amazonaws.com/h2o/rel-tukey/4/docs-website/h2o-docs/index.html" class="a" target="_blank">http://h2o-release.s3. amazonaws.com/h2o/rel-tukey/4/docs-website/h2o-docs/index.html</a><a href="http://h2o-release.s3.amazonaws.com/h2o/rel-tukey/4/docs-website/h2o-docs/index.html" class="s83" target="_blank">.</a><a name="bookmark129">&zwnj;</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0028" class="a" target="_blank" name="bookmark130">Ho, T. K. (1995). Random decision forests. In </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0028" class="s82" target="_blank">Proceedings of the third international conference  on  document  analysis  and  recognition:  1  </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0028" class="a" target="_blank">(pp.  278–282).  IEEE.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0029" class="a" target="_blank" name="bookmark131">Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0029" class="s82" target="_blank">Neural computa- tion,  9</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0029" class="a" target="_blank">(8),  1735–1780.</a></p><p style="padding-top: 3pt;padding-left: 17pt;text-indent: -12pt;line-height: 8pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0030" class="a" target="_blank">Hong, H., &amp; Sraer, D. A. (2016). Speculative betas. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0030" class="s82" target="_blank">The Journal of Finance, 71</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0030" class="a" target="_blank">(5), 2095–2144.</a></p><p style="padding-left: 17pt;text-indent: -12pt;line-height: 8pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0031" class="a" target="_blank">Huck, N. (2009). Pairs selection and outranking: An application to the S&amp;P 100 in- dex.  </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0031" class="s82" target="_blank">European  Journal  of  Operational  Research,  196</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0031" class="a" target="_blank">(2),  819–825.</a></p><p style="padding-left: 17pt;text-indent: -12pt;line-height: 8pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0032" class="a" target="_blank">Huck, N. (2010). Pairs trading and  outranking:  The  multi-step-ahead  forecasting case.  </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0032" class="s82" target="_blank">European  Journal  of  Operational  Research,  207</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0032" class="a" target="_blank">(3),  1702–1716.</a></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Jacobs, H. (2015). What explains the dynamics of 100 anomalies? <i>Journal of Banking</i></p><p class="s11" style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: left;">&amp; Finance, 57<a href="https://doi.org/10.1016/j.jbankfin.2015.03.006" class="s83" target="_blank">, 65–85. doi:</a><span class="s19">10.1016/j.jbankﬁn.2015.03.006.</span></p><p class="s13" style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Jacobs, H., &amp; Weber, M. (2015). On the determinants of pairs trading proﬁtability.</p><p class="s11" style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: left;">Journal of Financial Markets, 23<a href="https://doi.org/10.1016/j.finmar.2014.12.001" class="s83" target="_blank">, 75–97. doi:</a><a href="https://doi.org/10.1016/j.finmar.2014.12.001" class="a" target="_blank">10.1016/j.ﬁnmar.</a><span class="s19">2014.12.001.</span></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;">Jegadeesh, N. (1990). Evidence of predictable behavior of security returns. <i>The Jour- nal of Finance, 45</i><a href="https://doi.org/10.2307/2328797" class="s83" target="_blank">(3), 881–898. doi:</a><span style=" color: #0080AC;">10.2307/2328797.</span></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0036" class="a" target="_blank">Jegadeesh, N., &amp; Titman, S. (1993). Returns to buying winners and selling losers: Implications for stock market eﬃciency. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0036" class="s82" target="_blank">The Journal of Finance, 48</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0036" class="a" target="_blank">(1), 65–91.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0037" class="a" target="_blank">Jegadeesh, N., &amp; Titman, S. (1995). Overreaction, delayed reaction, and contrarian proﬁts. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0037" class="s82" target="_blank">Review of Financial Studies, 8</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0037" class="a" target="_blank">(4), 973–993.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0038" class="a" target="_blank">Jha, V. (2016). Timing equity quant positions with short-horizon alphas. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0038" class="s82" target="_blank">The Journal of  Trading,  11</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0038" class="a" target="_blank">(3),  53–59.</a></p><p class="s19" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" class="s83" target="_blank">Karpathy, A. (2015). The unreasonable effectiveness of recurrent neural networks. </a><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" class="a" target="_blank">http://karpathy.github.io/2015/05/21/rnn-effectiv</a>eness/<span style=" color: #000;">.</span></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0039" class="a" target="_blank">Krauss, C., Do, X. A., &amp; Huck, N. (2017). Deep neural networks, gradient-boosted trees, random forests: Statistical arbitrage on the S&amp;P 500. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0039" class="s82" target="_blank">European Journal of Operational  Research,  259</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0039" class="a" target="_blank">(2),  689–702.</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;">Kumar, A. (2009). Who gambles in the stock market? <i>The Journal of Finance, 64</i><a href="https://doi.org/10.1111/j.1540-6261.2009.01483.x" class="s83" target="_blank">(4), 1889–1933.     doi:</a><a href="https://doi.org/10.1111/j.1540-6261.2009.01483.x" class="a" target="_blank">10.1111/j.1540-6261.2009.01483.</a><span style=" color: #0080AC;">x.</span></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0041" class="a" target="_blank">LeBaron, B. (1992). Some relations between volatility and serial correlations in stock market returns. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0041" class="s82" target="_blank">The Journal of Business, 65</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0041" class="a" target="_blank">(2), 199–219.</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;">LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). Deep learning. <i>Nature, 521</i><a href="https://doi.org/10.1038/nature14539" class="s83" target="_blank">(7553), 436– 444.    doi:</a><span style=" color: #0080AC;">10.1038/nature14539.</span></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0043" class="a" target="_blank">Lee, D. D., Chan, H., Faff, R. W., &amp; Kalev, P. S. (2003). Short-term contrarian invest- ing – Is it proﬁtable?... Yes and No. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0043" class="s82" target="_blank">Journal of Multinational Financial Manage- ment,  13</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0043" class="a" target="_blank">(4),  385–404.</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;">Lehmann, B. N. (1990). Fads, martingales, and market eﬃciency. <i>The Quarterly Jour- nal of Economics, 105</i><a href="https://doi.org/10.2307/2937816" class="s83" target="_blank">(1), 1. doi:</a><span style=" color: #0080AC;">10.2307/2937816.</span></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0045" class="a" target="_blank">Lo, A. W., &amp; MacKinlay, A. C. (1990). When are contrarian proﬁts due to stock mar- ket overreaction? </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0045" class="s82" target="_blank">Review of Financial Studies, 3</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0045" class="a" target="_blank">(2), 175–205.</a></p><p class="s19" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="https://cran.r-project.org/package%3DRmpfr" class="s83" target="_blank">Maechler, M. (2016). Rmpfr: R MPFR – multiple precision ﬂoating-point reliable. R package.  </a><a href="https://cran.r-project.org/package%3DRmpfr" class="a" target="_blank">https://cran.r-project.org/package</a>=Rmpfr<span style=" color: #000;">.</span></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0046" class="a" target="_blank">Malkiel, B. G. (2007). </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0046" class="s82" target="_blank">A random walk down Wall Street: The time-tested strategy for successful investing</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0046" class="a" target="_blank">. WW Norton &amp; Company.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0047" class="a" target="_blank">McKinney, W. (2010). Data structures for statistical computing in Python. In </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0047" class="s82" target="_blank">Pro- ceedings of the ninth Python in science conference: 445 </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0047" class="a" target="_blank">(pp. 51–56).</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0048" class="a" target="_blank">Medsker, L. (2000). Recurrent neural networks: Design  and  applications.  </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0048" class="s82" target="_blank">Interna- tional series  on computational  intelligence</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0048" class="a" target="_blank">. CRC-Press.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0049" class="a" target="_blank">Moritz, B., &amp; Zimmermann, T. (2014). Deep conditional portfolio sorts: The relation between past and future stock returns. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0049" class="s82" target="_blank">Working paper</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0049" class="a" target="_blank">. LMU Munich and Harvard University.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" class="s83" target="_blank">Olah, C. (2015). Understanding LSTM Networks. </a><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" class="a" target="_blank">http://colah.github.io/posts/ 2015-08-Understanding-   LSTMs/</a><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" class="s83" target="_blank">.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0050" class="a" target="_blank">Pedregosa, F.,  Varoquaux,  G.,  Gramfort,  A.,  Michel,  V.,  Thirion,  B.,  Grisel,  O., et al. (2011). Scikit-learn: Machine learning in python. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0050" class="s82" target="_blank">Journal of Machine Learn- ing  Research,  12</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0050" class="a" target="_blank">,  2825–2830.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://CRAN.R-project.org/package%3DPerformanceAnalytics" class="s83" target="_blank">Peterson, B. G., &amp; Carl, P. (2014). PerformanceAnalytics: Econometric tools for performance and risk analysis. R package, </a><a href="http://CRAN.R-project.org/package%3DPerformanceAnalytics" class="a" target="_blank">http://CRAN.R-project.org/package= PerformanceAnalytics</a><a href="http://CRAN.R-project.org/package%3DPerformanceAnalytics" class="s83" target="_blank">.</a></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="https://docs.python.org/3.5/" class="s83" target="_blank">Python Software Foundation (2016). Python 3.5.2 documentation. Available at </a><a href="https://docs.python.org/3.5/" class="a" target="_blank">https:</a></p><p style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="https://docs.python.org/3.5/" class="a" target="_blank">//docs.python.org/3.5/</a><a href="https://docs.python.org/3.5/" class="s83" target="_blank">.</a></p><p style="padding-left: 5pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="http://www.R-project.org/" class="s83" target="_blank">R Core Team (2016). R: A language and environment for statistical computing. </a><a href="http://www.R-project.org/" class="a" target="_blank">http:</a></p><p style="padding-left: 17pt;text-indent: 0pt;line-height: 8pt;text-align: left;"><a href="http://www.R-project.org/" class="a" target="_blank">//www.R-project.org/</a><a href="http://www.R-project.org/" class="s83" target="_blank">.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0051" class="a" target="_blank">Rad, H., Low, R. K. Y., &amp; Faff, R. (2016). The proﬁtability of pairs trading strate- gies: Distance, cointegration  and copula  methods. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0051" class="s82" target="_blank">Quantitative  Finance, 16</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0051" class="a" target="_blank">(10), 1541–1558.</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;">Sak, H., Senior, A.W., &amp; Beaufays, F. (2014). Long short-term memory based recur- rent neural network architectures for large vocabulary speech recognition. <i>CoRR</i>, arXiv  preprint  arXiv:<span style=" color: #0080AC;">1402.1128</span>.</p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0052" class="a" target="_blank">Schmidhuber, J. (2015). Deep learning in neural networks: An overview. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0052" class="s82" target="_blank">Neural Net- works,  61</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0052" class="a" target="_blank">,  85–117.</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;">Sermpinis, G., Theoﬁlatos, K., Karathanasopoulos, A., Georgopoulos, E. F., &amp; Du- nis, C. (2013). Forecasting foreign exchange rates with adaptive neural networks using radial-basis functions and particle swarm optimization. <i>European Journal of  Operational  Research,  225</i><a href="https://doi.org/10.1016/j.ejor.2012.10.020" class="s83" target="_blank">(3),  528–540.  doi:</a><span style=" color: #0080AC;">10.1016/j.ejor.2012.10.020.</span></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://kienwei.mit.edu/sites/default/files/images/stock-market-prediction.pdf" class="s83" target="_blank">Siah,  K.  W.,  &amp;  Myers,   P.   (2016).   Stock   market   prediction   through   technical and public sentiment analysis. </a><a href="http://kienwei.mit.edu/sites/default/files/images/stock-market-prediction.pdf" class="a" target="_blank">http://kienwei.mit.edu/sites/default/ﬁles/images/ stock-market-prediction.pdf</a><a href="http://kienwei.mit.edu/sites/default/files/images/stock-market-prediction.pdf" class="s83" target="_blank">.</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;">Takeuchi, L., &amp; Lee, Y.-Y. (2013). Applying deep learning to enhance momentum trad- ing  strategies  in  stocks.  Working  paper,  Stanford  University.</p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0054" class="a" target="_blank">Tieleman, T., &amp; Hinton, G. (2012). Lecture 6.5-rmsprop: Divide the gradient by a run- ning average of its recent magnitude. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0054" class="s82" target="_blank">COURSERA: Neural Networks for Machine Learning,  4</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0054" class="a" target="_blank">(2),  26–30.</a></p><p style="padding-left: 17pt;text-indent: -12pt;text-align: justify;"><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0055" class="a" target="_blank">Van Der Walt, S., Colbert, S. C., &amp; Varoquaux, G. (2011). The numpy array: a structure for eﬃcient numerical computation. </a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0055" class="s82" target="_blank">Computing in Science &amp; Engineering, 13</a><a href="http://refhub.elsevier.com/S0377-2217(17)31065-2/sbref0055" class="a" target="_blank">(2), 22–30.</a></p><p class="s13" style="padding-left: 17pt;text-indent: -12pt;text-align: justify;">Xiong, R., Nichols, E. P., &amp; Shen, Y. (2015). Deep learning stock volatility with Google domestic  trends.  arXiv  e-prints  arXiv:<span style=" color: #0080AC;">1512.04916</span>.</p></body></html>
