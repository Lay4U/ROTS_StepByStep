
우리는 ImageNet LSVRC-2010 경연 대회에서 120 만 개의 고해상도 이미지를 1000 개의 다른 클래스로 분류하기 위해 크고 깊은 컨볼 루션 신경망을 훈련했습니다. 테스트 데이터에서 각각 최고 37.5 % 및 최고 5 %의 오류율을 달성했으며 이는 이전의 최첨단 기술보다 훨씬 뛰어납니다. 6 천만 개의 매개 변수와 65 만 개의 뉴런을 가진 신경 회로망은 5 개의 컨볼루션 층으로 구성되며, 그 중 일부는 최대 풀링 층과 3 개의 완전히 연결된 층과 최후의 1000 방향 소프트 맥스로 구성됩니다. 교육을 더 빠르게하기 위해 비 포화 뉴런과 컨볼 루션 작업의 매우 효율적인 GPU 구현을 사용했습니다. 완벽하게 연결된 레이어의 초과 적용을 줄이기 위해 우리는 최근에 개발 된 "드롭 아웃 (dropout)"이라는 정규화 메서드를 사용하여 매우 효과적임이 입증되었습니다. 우리는 또한 ILSVRC-2012 대회에서이 모델의 변형을 입력했으며, 2 위 항목으로 26.2 %에 비해 15.3 %의 우승 5 위 테스트 오류율을 달성했습니다.

맨 위로


1. 프롤로그
4 년 전 얀 르쿤 (Yann LeCun)과 그의 동료들에 의한 논문은 신경망을 사용하여 비전 시스템을 설계하는 방법에 대한 통찰력을 제공하지 못했다는 이유로 컴퓨터 비전 컨퍼런스에서 거부당했습니다. 당시 대부분의 컴퓨터 비전 연구자들은 비전 시스템이 작업의 성격을 자세히 이해하여 신중하게 손으로 설계해야한다고 믿었습니다. 그들은 자연 이미지에서 객체를 분류하는 작업이이 훈련 데이터로부터 모든 지식을 획득 한 신경망에 포함 된 객체의 이름과 이미지의 예를 단순히 제시함으로써 해결되지 않는다고 가정했습니다.

비전 연구 커뮤니티의 많은 사람들이 인식하지 못했던 것은 도메인을 이해하는 프로그래머가 신중한 수동 공학을 필요로하는 방법은 프로그래머를 강력한 범용 학습 절차로 대체하는 방법뿐만 아니라 확장되지 않는다는 것입니다. 충분한 계산과 충분한 데이터가 있으면 학습은 여러 가지 다른 잡음이 많은 신호의 통합을 필요로하는 복잡한 작업에 대한 프로그래밍보다 우수합니다.

4 년 전 토론토 대학교에있는 동안 SuperVision이라는 깊은 신경 네트워크는 자연 이미지의 물체를 인식하는 오류율을 거의 절반으로 줄였으며 컴퓨터 비전에서 지나치게 패러다임이 바뀌 었습니다. 그림 4는 SuperVision이 할 수있는 몇 가지 예를 보여줍니다.

SuperVision은 1980 년대에 널리 연구 된 다층 신경망에서 진화했습니다. 이 네트워크는 교육 데이터에서 모두 배운 피처 감지기의 여러 레이어를 사용했습니다. 신경 과학자들과 심리학자들은 그러한 피쳐 탐지기의 계층 구조가 객체를 인식하는 강력한 방법을 제공 할 것이라고 가정했지만 그러한 계층 구조가 어떻게 배울 수 있는지 전혀 알지 못했다. 여러 다른 연구 그룹이 특징 탐지기의 다중 계층이 각각의 이미지에 대해 backpropagation이라는 비교적 직선적 인 알고리즘을 사용하여 효율적으로 학습 될 수 있다는 것을 발견했기 때문에 1980 년대에 큰 흥분이있었습니다. 전체 네트워크는 각 연결의 가중치에 따라 달라집니다.

백 프로 퍼 게이션은 다양한 작업에서 잘 작동했지만 1980 년대에는 지지자의 기대치가 높지 않았습니다. 특히, 많은 레이어를 가진 네트워크를 배우는 것은 매우 어렵다는 것을 증명했으며, 이는 정확하게 가장 인상적인 결과를 가져다 줄 네트워크였습니다. 많은 연구자들은 무작위 초기 가중치로부터 심 신경 네트워크를 학습하는 것이 너무 어렵다는 결론을 부정확하게 결론 내렸다. 20 년이 지난 지금, 우리는 무엇이 잘못되었는지 알았습니다. 깊은 신경 네트워크가 빛나기 위해서는 더 많은 라벨이 붙은 데이터와 엄청나게 많은 계산이 필요했습니다.

맨 위로


2. 소개
현재 객체 인식에 대한 접근 방식은 기계 학습 방법을 필수적으로 사용합니다. 성능을 향상시키기 위해 더 큰 데이터 세트를 수집하고,보다 강력한 모델을 학습하고, 과잉 방지를위한보다 나은 기술을 사용할 수 있습니다. 최근까지 레이블이 붙은 이미지의 데이터 세트는 수만 이미지의 순서로 비교적 작았습니다 (예 : NORB, 19Caltech-101 / 256,8,10 및 CIFAR-10 / 10014). 이 크기의 데이터 세트로 간단한 인식 작업을 아주 잘 처리 할 수 있습니다. 특히 레이블 보존 변환으로 보완되는 경우 더욱 그렇습니다. 예를 들어, MNIST 숫자 인식 작업 (<0.3 %)에서 현재 가장 좋은 오류율은 인간의 성능에 접근합니다 .5 그러나 현실적인 설정의 개체는 상당한 변동성을 나타내므로이를 인식하는 법을 배우려면 훨씬 더 큰 교육 집합 . 실제로 작은 이미지 데이터 세트의 단점은 광범위하게 인식되어 왔지만 (예 : Ref.25), 수백만 개의 이미지로 라벨링 된 데이터 세트를 수집하는 것은 최근에 가능 해졌습니다. 새로운 대용량 데이터 세트에는 수십만 개의 완전히 분할 된 이미지로 구성된 LabelMe (28)와 22,000 개 카테고리의 1,500 만 개가 넘는 고해상도 이미지로 구성된 ImageNet (7)이 포함됩니다.

수백만 개의 이미지에서 수천 가지의 객체를 배우려면 학습 능력이 큰 모델이 필요합니다. 그러나 객체 인식 작업의 엄청난 복잡성은이 문제가 ImageNet만큼 큰 데이터 세트로도 지정 될 수 없다는 것을 의미하므로 모델에는 우리가 보유하지 않은 모든 데이터를 보완하기위한 사전 지식이 많이 있어야합니다. Convolutional Neural Network (CNNs)는 이러한 종류의 모델 중 하나를 구성합니다. 9, 15, 17, 19, 21, 26, 32 그들의 용량은 깊이와 폭을 다양하게 조절할 수 있으며 또한 자연에 대해 강력하고 대부분 올바른 가정을합니다 (즉, 통계의 정적 성 및 픽셀 의존성의 지역성). 따라서 유사한 크기의 레이어를 가진 표준 피드 포워드 신경망과 비교하여 CNN은 연결 및 매개 변수가 훨씬 적기 때문에 훈련하기가 더 쉽습니다. 이론적으로 최상의 성능은 약간 악화 될 수 있습니다.

CNN의 매력적인 특성에도 불구하고 로컬 아키텍처의 상대적 효율성에도 불구하고 고해상도 이미지에 대규모로 적용하는 데 엄청난 비용이 소요되었습니다. 다행히 현재의 GPU는 2D 컨볼 루션의 고도로 최적화 된 구현과 결합하여 흥미로운 대규모 CNN의 교육을 용이하게 할만큼 강력하며 ImageNet과 같은 최근 데이터 세트는 심한 과장없이 이러한 모델을 학습 할 수있는 충분한 레이블이있는 예제를 포함합니다.

본 백서의 구체적인 기여 내용은 다음과 같습니다. 우리는 ImageNet Large Scale Visual Recognition Challenge (ILSVRC) -2010 및 ILSVRC-2012 대회 2에서 사용 된 ImageNet의 하위 세트에 대해 최대 규모의 CNN 중 하나를 훈련하여 지금까지 최고로 달성했습니다 결과는 이러한 데이터 세트에 대해보고되었습니다. 우리는 2D 컨볼 루션의 고도로 최적화 된 GPU 구현과 CNN 교육에 내재 된 모든 다른 작업을 공개적으로 제공합니다. 우리 네트워크에는 성능을 향상시키고 교육 시간을 단축시키는 많은 새롭고 특이한 기능이 포함되어 있습니다. 섹션 4. 우리 네트워크의 크기는 120 만 개의 레이블이있는 교육 사례에서도 심각한 문제를 뛰어 넘었습니다. 그래서 우리는 섹션 5에서 설명하는 과잉 방지를위한 몇 가지 효과적인 기술을 사용했습니다. 최종 네트워크에는 5 개의 컨볼 루션 레이어와 3 개의 완전히 연결된 레이어가 포함되어 있습니다.이 깊이는 중요하게 여겨집니다. 각각의 컨벌루션 레이어를 제거하면 성능이 떨어집니다.

결국 네트워크의 크기는 현재 GPU에서 사용할 수있는 메모리 양과 허용 할 수있는 교육 시간으로 제한됩니다. 우리의 네트워크는 GTX 580 3GB GPU 2 대를 훈련 시키는데 5 일에서 6 일 걸립니다. 우리의 모든 실험은 더 빠른 GPU와 더 큰 데이터 세트가 사용 가능할 때까지 기다리는 것으로 결과가 개선 될 수 있음을 시사합니다.

맨 위로


삼. 데이터 세트
ImageNet은 대략 22,000 개의 범주에 속하는 1,500 만 개 이상의 고해상도 이미지 데이터 세트입니다. 이미지는 웹에서 수집되어 Amazon의 Mechanical Turk 군중 소싱 도구를 사용하여 인간 라벨러에 의해 분류되었습니다. 2010 년부터 Pascal Visual Object Challenge의 일환으로 ILSVRC (ImageNet Large Scale Visual Recognition Challenge)라는 대회가 개최되었습니다. ILSVRC는 1000 개의 범주에 약 1000 개의 이미지가있는 ImageNet 하위 집합을 사용합니다. 전체적으로 약 120 만 개의 교육 이미지, 50,000 개의 유효성 검사 이미지 및 150,000 개의 테스트 이미지가 있습니다.

ILSVRC-2010은 테스트 세트 레이블을 사용할 수있는 유일한 버전의 ILSVRC이므로 이것이 대부분의 실험을 수행 한 버전입니다. 우리는 또한 ILSVRC-2012 대회에서 모델을 입력 했으므로 7 절에서 테스트 세트 레이블을 사용할 수없는이 버전의 데이터 세트에 대한 결과도보고합니다. ImageNet에서 top-1과 top-5의 두 가지 오류율을보고하는 것이 일반적입니다. 여기서 오류 5 개는 모델에서 가장 가능성이 있다고 여겨지는 다섯 개의 레이블 중에서 올바른 레이블이없는 테스트 이미지의 비율입니다 .

ImageNet은 가변 해상도 이미지로 구성되며 시스템은 일정한 입력 차원을 필요로합니다. 따라서 이미지를 256 × 256의 고정 해상도로 다운 샘플링했습니다. 직사각형 이미지가 주어지면 짧은 쪽의 길이가 256이되도록 이미지의 크기를 조정 한 다음 결과 이미지에서 중앙 256 × 256 패치를 잘라 냈습니다. 각 픽셀에서 트레이닝 세트에 대한 평균 활동을 빼는 경우를 제외하고는 다른 방법으로 이미지를 사전 처리하지 않았습니다. 그래서 우리는 네트워크의 픽셀 중심 RGB 값을 훈련 시켰습니다.

맨 위로


4. 건축
우리 네트워크의 아키텍처는 그림 2에 요약되어 있습니다. 여기에는 8 개의 학습 된 레이어가 포함되어 있습니다. 5 개의 컨볼루션 된 레이어와 3 개의 완전히 연결된 레이어입니다. 아래에서는 네트워크 아키텍처의 새롭거나 특이한 기능에 대해 설명합니다. 섹션 4.1-4.4는 중요성에 대한 우리의 추정에 따라 정렬되며, 가장 중요한 것이 먼저 있습니다.

* 4.1. 정류 된 선형 유닛 비선형 성

입력 x의 함수로서 뉴런의 출력 f를 모델링하는 표준 방법은 f (x) = tanh (x) 또는 f (x) = (1 + e-x) -1이다. 그라디언트 디센트가있는 교육 시간 측면에서 이러한 포화 비선형 성은 비 포화 비선형 성 f (x) = max (0, x)보다 훨씬 느립니다. Nair와 Hinton에 따르면, 우리는 정류 된 선형 단위 (ReLUs)로서이 비선형 성을 가진 뉴런을 참조한다. ReLUs를 가진 깊은 CNNs는 tanh 단위를 가진 그들의 동등 물보다는 몇 시간 빨리 훈련한다. 이는 그림 1에 나와 있으며 특정 4 계층 컨볼 루션 네트워크에 대해 CIFAR-10 데이터 세트에서 25 %의 교육 오류에 도달하는 데 필요한 반복 횟수를 보여줍니다. 이 음모는 전통적인 포화 뉴런 모델을 사용했다면 우리가이 작업을 위해 그러한 거대한 신경망을 실험하지 못했음을 보여줍니다.

우리는 CNN의 전통적인 뉴런 모델에 대한 대안을 처음으로 고려하지 않습니다. 예를 들어, Jarrett 등 13)은 비선형 성 f (x) = | tanh (x) | 는 Caltech-101 데이터 세트의 로컬 평균 풀링에 이어 콘트라스트 정규화 유형에 특히 효과적입니다. 그러나이 데이터 세트에서 주요 관심사는 초과 맞춤을 방지하는 것이므로 관찰하는 효과는 ReLUs를 사용할 때보고하는 교육 세트에 맞게 가속화 된 능력과 다릅니다. 보다 빠른 학습은 대형 데이터 세트에서 교육 된 대형 모델의 성능에 큰 영향을 미칩니다.

* 4.2. 여러 GPU 교육

하나의 GTX 580 GPU에는 3GB의 메모리 만있어 훈련 할 수있는 네트워크의 최대 크기를 제한합니다. 120 만 가지의 교육 사례가 너무 커서 한 GPU에 맞출 수없는 네트워크를 훈련시키는 것으로 나타났습니다. 따라서 우리는 그물을 두 개의 GPU에 분산시킵니다. 현재 GPU는 GPU 병렬 처리에 특히 적합합니다. 호스트 시스템 메모리를 거치지 않고 직접 서로의 메모리를 읽고 쓸 수 있기 때문입니다. 본질적으로 채택한 병렬화 계획은 각 GPU에 커널 (또는 뉴런)의 절반을 넣고 추가 트릭을 추가합니다. GPU는 특정 계층에서만 통신합니다. 예를 들어, 레이어 3의 커널은 레이어 2의 모든 커널 맵에서 입력을받습니다. 그러나 레이어 4의 커널은 동일한 GPU에있는 레이어 3의 커널 맵에서만 입력을받습니다. 연결 패턴을 선택하는 것은 교차 유효성 검사에 대한 문제이지만 계산량의 허용되는 비율이 될 때까지 의사 소통의 양을 정확하게 조정할 수 있습니다.

결과적인 구조는 Cirean et al., 4에 의해 사용 된 "원주 형"CNN의 구조와 다소 유사하지만, 우리의 열은 독립적이지 않다는 점이 다릅니다 (그림 2 참조). 이 구성표는 하나의 GPU에서 교육 된 각 컨볼 루션 계층에서 커널의 절반을 차지하는 네트워크와 비교할 때 최상위 1 및 상위 5 오류율을 1.7 % 및 1.2 % 각각 줄입니다. 2-GPU 네트는 하나의 GPU net.b보다 훈련 시간이 약간 적습니다.

* 4.3. 로컬 응답 정규화

ReLU는 포화되지 않도록 입력 정규화를 필요로하지 않는 바람직한 특성을 가지고 있습니다. 적어도 일부 훈련 예제가 ReLU에 긍정적 인 입력을 발생시키는 경우 학습은 해당 뉴런에서 발생합니다. 그러나, 우리는 여전히 다음의 로컬 정규화 체계가 일반화를 돕는다는 것을 발견한다. aix, y를 위치 (x, y)에 커널 i를 적용한 다음 ReLU 비선형 성을 적용하여 계산 한 뉴런의 활동을 나타낼 때, 반응 정규화 된 활동 bix, y는

ueq01.gif

여기서 합계는 동일한 공간 위치에서 n 개의 "인접한"커널 맵을 통해 실행되며 N은 레이어의 총 커널 수입니다. 물론 커널 맵의 순서는 훈련이 시작되기 전에 임의로 결정됩니다. 이러한 종류의 반응 정상화는 실제 뉴런에서 발견 된 유형에 영향을받은 횡단 억제 형태를 구현하여 서로 다른 커널을 사용하여 계산 된 뉴런 출력 간의 큰 활동을위한 경쟁을 만듭니다. 상수 k, n, α 및 β는 검증 집합을 사용하여 값이 결정되는 하이퍼 매개 변수입니다. 우리는 k = 2, n = 5, α = 10-4 및 β = 0.75를 사용했다. 우리는 특정 레이어에서 ReLU 비선형 성을 적용한 후에 이러한 정규화를 적용했습니다 (4.5 절 참조).

이 기법은 Jarrett et al., 13의 국부 대비 정규화 기법과 어느 정도 유사하지만, 우리는 평균 활동을 빼지 않기 때문에 더 정확하게 "밝기 표준화"라고 불릴 것이다. 응답 정상화는 우리의 top-1과 top-5 오류율을 각각 1.4 %와 1.2 % 감소시킵니다. 우리는 또한 CIFAR-10 데이터 세트에서이 기법의 효과를 검증했다. 4 층 CNN은 정규화없이 13 %의 테스트 오류율을 얻었고 정규화를 통해 11 %의 테스트 오류율을 달성했다.

* 4.4. 오버랩 풀링

CNN의 풀링 레이어는 동일한 커널 맵에서 인접한 뉴런 그룹의 출력을 요약합니다. 전통적으로 인접한 풀링 단위에 의해 요약 된 이웃은 겹치지 않는다 (예, 참고 문헌 5, 13, 20). 보다 정확하게 말하면, 풀링 층은 풀링 유닛의 위치를 중심으로하는 크기 z × z의 이웃을 요약하는, 각각 이격 된 풀링 유닛의 그리드로 구성되는 것으로 생각할 수있다. s = z로 설정하면 CNN에서 일반적으로 사용되는 전통적인 로컬 풀링을 얻습니다. s <z로 설정하면 오버랩 풀이됩니다. 이것은 우리의 네트워크에서 s = 2 및 z = 3으로 사용합니다. 이 방식은 비 중첩 방식 인 s = 2, z = 2와 비교하여 각각 top-1 및 top-5 오류율을 0.4 % 및 0.3 % 줄입니다. 우리는 일반적으로 풀링이 겹치는 모델을 훈련 중에 관찰하여 과장하기가 약간 어렵다고 판단합니다.

* 4.5. 전반적인 아키텍처

이제 CNN의 전반적인 아키텍처를 설명 할 준비가되었습니다. 그림 2에서 묘사 된 것처럼 그물은 가중치가있는 8 개의 레이어를 포함합니다. 처음 5 개는 컨볼루션이고 나머지 3 개는 완전히 연결됩니다. 마지막으로 완전히 연결된 레이어의 출력은 1000 개의 클래스 레이블을 통해 분포를 생성하는 1000 방향 softmax로 공급됩니다. 우리의 네트워크는 다차원 회귀 회귀 목적을 극대화합니다. 이는 예측 분포 하에서 올바른 라벨의 로그 확률에 대한 교육 사례 전반의 평균을 최대화하는 것과 같습니다.

두 번째, 네 번째 및 다섯 번째 컨벌루션 계층의 커널은 동일한 GPU에있는 이전 계층의 커널 맵에만 연결됩니다 (그림 2 참조). 세 번째 컨볼 루션 계층의 커널은 두 번째 계층의 모든 커널 맵에 연결됩니다. 완전히 연결된 레이어의 뉴런은 이전 레이어의 모든 뉴런에 연결됩니다. 응답 정규화 계층은 첫 번째 및 두 번째 컨벌루션 계층을 따릅니다. 4.4 절에서 설명 된 종류의 최대 - 풀링 계층은 응답 정규화 계층과 다섯 번째 컨벌루션 계층을 따른다. ReLU 비선형 성은 모든 컨볼 루션 및 완전히 연결된 레이어의 출력에 적용됩니다.

첫 번째 컨볼루션 레이어는 224 x 224 x 3 입력 이미지를 4 x 4 픽셀의 크기로 11 x 11 x 3 크기의 96 개 커널로 필터링합니다 (커널 맵에서 이웃하는 뉴런의 수용 필드 중심 사이의 거리입니다). 제 2 컨볼 루션 계층은 제 1 컨볼 루션 계층의 (응답 - 정규화되고 풀링 된) 출력을 입력으로서 취하고 그것을 5 × 5 × 48 크기의 256 개의 커널로 필터링한다. 제 3, 제 4 및 제 5 컨볼 루션 계층들은 어떠한 풀링 또는 표준화 계층을 개재시키지 않고 서로 접속된다. 세 번째 컨볼 루션 계층은 3x3x256 크기의 384 개 커널을 두 번째 컨벌루션 계층의 정규화 된 풀링 된 출력에 연결합니다. 제 4 콘볼 루션 층은 3 × 3 × 192 크기의 384 개의 커널을 가지며, 제 5 콘볼 루션 층은 3 × 3 × 192 크기의 256 개의 커널을 갖는다. 완전히 연결된 레이어에는 각각 4096 개의 뉴런이 있습니다.

맨 위로


5. 오버 피팅 줄이기
우리의 신경 네트워크 아키텍처에는 6 천만 개의 매개 변수가 있습니다. ILSVRC의 1000 클래스가 각 트레이닝 예제를 이미지에서 레이블로 매핑하는 데 10 비트의 제약을 부과하지만, 이는 과도하게 지나치게 많은 파라미터를 배울 정도로 부족합니다. 아래에서 우리는 우리가 지나치게 싸우는 두 가지 기본 방법을 설명합니다.

* 5.1. 데이터 증가

이미지 데이터의 초과 맞춤을 줄이는 가장 쉽고 가장 일반적인 방법은 레이블 보존 변환 (예 : Refs.4, 5, 30)을 사용하여 인위적으로 데이터 세트를 확대하는 것입니다. 우리는 두 가지 형태의 데이터 확대 방법을 사용합니다. 둘 다 매우 작은 계산량으로 원본 이미지에서 변환 된 이미지를 생성 할 수 있으므로 변환 된 이미지를 디스크에 저장할 필요가 없습니다. 우리의 구현에서 변환 된 이미지는 CPU의 파이썬 코드로 생성되는 반면 GPU는 이전 이미지 배치에 대해 교육을합니다. 따라서 이러한 데이터 증가 체계는 사실상 계산 상 자유 롭습니다.

데이터 확대의 첫 번째 형태는 이미지 번역 및 수평 반사를 생성하는 것입니다. 우리는 256 × 256 이미지에서 임의의 224 × 224 패치 (및 그 수평 반사)를 추출하고 이러한 추출 된 패치에 대한 네트워크를 훈련함으로써이 작업을 수행합니다. 이로 인해 우리 교육 세트의 크기가 2048 배 증가하지만 결과 트레이닝 예는 물론 상호 의존성이 높습니다. 이 계획이 없으면 우리 네트워크는 상당한 초과 수용으로 고통을 겪습니다. 그러면 우리는 훨씬 더 작은 네트워크를 사용해야 할 것입니다. 테스트 시간에 네트워크는 224 × 224 패치 (4 개의 코너 패치와 중앙 패치)와 수평 반사 (따라서 10 개의 패치)를 추출하고 네트워크의 softmax 레이어에 의해 만들어진 예측을 평균하여 예측을합니다 10 개의 패치에.

데이터 증가의 두 번째 형태는 교육 이미지에서 RGB 채널의 강도를 변경하는 것입니다. 특히 ImageNet 교육 세트에서 RGB 픽셀 값 집합에 대해 PCA를 수행합니다. 각 학습 이미지에 대해 발견 된 주성분의 배수를 해당 고유 값에 비례하는 크기와 평균 0 및 표준 편차 0.1의 가우시안에서 가져온 임의의 변수에 곱합니다. 따라서 각 RGB 이미지 픽셀 cacm6006_a.gif에 다음 수량을 추가합니다.

ueq02.gif

여기서 pi와 λi는 각각 RGB 픽셀 값의 3x3 공분산 행렬의 i 번째 고유 벡터와 고유 값이고, αi는 상기 확률 변수이다. 각 αi는 특정 훈련 이미지의 모든 픽셀에 대해 한 번만 그려지며 그 이미지가 다시 훈련을 위해 사용될 때까지 다시 그려집니다. 이 체계는 대략 자연스러운 이미지의 중요한 속성을 캡처합니다. 즉, 객체 정체성은 조명의 강도와 색상의 변화에 변하지 않습니다. 이 계획은 상위 1 오류율을 1 % 이상 줄입니다.

* 5.2. 탈락

많은 다른 모델의 예측을 결합하는 것은 테스트 오류를 줄이기위한 매우 성공적인 방법입니다. 1, 3 그러나 큰 뉴럴 네트워크에서는 이미 훈련하는 데 며칠이 걸리는데 너무 비싸 보입니다. 그러나 훈련 중에는 2 배 정도의 비용 만 소요되는 매우 효율적인 모델 조합 버전이 있습니다. 최근 도입 된 기술인 "dropout"은 확률 0.5로 각 숨겨진 뉴런의 출력을 0으로 설정하는 것으로 구성됩니다. 이런 식으로 "떨어 뜨린"뉴런은 순방향 전달에 기여하지 않으며 역 전파에 참여하지 않습니다. 따라서 입력이 제공 될 때마다 신경망은 다른 아키텍처를 샘플링하지만 이러한 모든 아키텍처는 가중치를 공유합니다. 이 기술은 뉴런이 특정 다른 뉴런의 존재에 의존 할 수 없기 때문에 뉴런의 복잡한 동시 적응을 감소시킵니다. 그러므로 다른 뉴런의 많은 다른 무작위 부분 집합과 함께 유용한 더 강력한 특징을 배우게됩니다. 테스트 시간에, 우리는 모든 뉴런을 사용하지만 그들의 출력에 0.5를 곱합니다. 이것은 기하 급수적 인 많은 누락 네트워크에 의해 생성 된 예측 분포의 기하 평균을 취하는 것에 대한 합리적인 근사입니다.

그림 2의 처음 두 개의 완전히 연결된 레이어에서 드롭 아웃을 사용합니다. 중도 이탈이 없으면 우리 네트워크는 상당한 초과 수용력을 보여줍니다. 드롭 아웃은 수렴하는 데 필요한 반복 횟수를 대략 두 배로 늘립니다.

맨 위로


6. 학습 내용
우리는 모델의 모집단 크기 128, 모멘텀 0.9, 체중 감량 0.0005의 확률적인 그래디언트 디센트를 사용하여 모델을 교육했습니다. 우리는이 작은 양의 체중 감소가 모델이 배우는 데 중요하다는 것을 발견했습니다. 다시 말해, 여기서의 체중 감량은 정규화가가 아니라 모델의 학습 오류를 줄이는 것입니다. 가중치 w의 업데이트 규칙은

ueq03.gif

여기서 i는 반복 인덱스이고, v는 모멘텀 변수이며, 학습 속도이며, cacm6006_b.gif는 wi에 대해 w와 관련하여 목표의 미분의 i 번째 배치 Di에 대한 평균입니다.

표준 편차 0.01의 제로 평균 가우스 분포로부터 각 계층의 가중치를 초기화했습니다. 우리는 두 번째, 네 번째, 다섯 번째 컨벌루션 레이어와 완전히 연결된 숨겨진 레이어에서 뉴런 편향을 상수 1로 초기화했습니다. 이 초기화는 ReLUs에 양수 입력을 제공하여 학습 초기 단계를 가속화합니다. 나머지 레이어의 뉴런 편향을 상수 0으로 초기화했습니다.

우리는 모든 레이어에 평등 한 학습 속도를 사용했습니다. 우리는 교육을 통해 수동으로 조정했습니다. 우리가 따라온 경험적 방법은 유효 오류율이 현재 학습률로 개선되지 않을 때 학습률을 10으로 나누는 것입니다. 학습 속도는 0.01으로 초기화되었으며 종료하기 전에 3 회 감소되었습니다. 우리는 두 개의 NVIDIA GTX 580 3GB GPU에서 5-6 일이 걸린 120 만 개의 이미지 트레이닝 세트를 통해 약 90 사이클 동안 네트워크를 교육했습니다.

맨 위로


7. 결과
ILSVRC-2010에 대한 우리의 결과는 표 1에 요약되어 있습니다. 우리의 네트워크는 37.5 %와 17.0 %의 top-1과 top-5 테스트 세트 오류율을 각각 달성합니다 .e ILSVRC-2010 경쟁 기간 동안 달성 된 최상의 성능은 6 개에서 생성 된 예측을 평균하여 47.1 %와 28.2 %였습니다 2 가지 유형으로 조밀하게 샘플링 된 스파 스 코딩 모델은 2 가지 유형의 조밀하게 샘플링 된 피쳐로부터 계산 된 피셔 벡터 (Fisher Vector, FV)에서 트레이닝 된 2 개의 분류기에 대한 예측을 평균화하는 접근 방식으로 45.7 %와 25.7 %를 나타냅니다.

우리는 또한 ILSVRC-2012 대회에서 모델을 입력하고 우리의 결과를 표 2에보고했습니다. ILSVRC-2012 테스트 세트 레이블은 공개적으로 제공되지 않으므로 테스트 한 모든 모델에 대해 테스트 오류율을보고 할 수는 없습니다. 이 단락의 나머지 부분에서는 우리의 경험에서 0.1 % 이상 차이가 나지 않기 때문에 검증과 테스트 오류율을 서로 바꿔 사용할 수 있습니다 (표 2 참조). 이 백서에 설명 된 CNN은 최고 5 %의 오류율 18.2 %를 달성합니다. 유사한 5 개의 CNN에 대한 예측을 평균하면 오류율은 16.4 %입니다. 마지막 풀링 레이어에 여섯 번째 컨볼루션 레이어가 추가 된 하나의 CNN을 교육하여 ILSVRC-2012 전체 ImageNet Fall 2011 버전 (15M 이미지, 22K 카테고리)을 분류 한 다음 ILSVRC-2012에서 "미세 조정"하여 16.6의 오류율을 제공합니다 %. 2011 년 가을 출시 된 모든 CNN에 대해 사전 교육을받은 2 대의 CNN 예측을 평균하면 오류율은 15.3 %입니다. 두 번째로 우수한 컨테스트 출품작은 서로 다른 유형의 조밀하게 샘플링 된 피쳐로부터 계산 된 FV에 대해 훈련 된 여러 분류 자의 예측을 평균하는 접근 방식으로 26.2 %의 오류율을 달성했습니다.

마지막으로 우리는 또한 2009 년 가을 ImageNet의 오류율을 10,184 가지 범주와 890 만 가지 이미지로보고합니다. 이 데이터 세트에서 우리는 교육을 위해 이미지의 절반을 사용하고 테스트를 위해 이미지의 절반을 사용하는 것에 관한 규정을 따릅니다. 확정 된 테스트 세트가 없기 때문에, 우리의 분리는 필자가 이전에 사용했던 분리와 필연적으로 다르지만, 이는 결과에 상당한 영향을 미치지 않습니다. 이 데이터 세트의 top-1 및 top-5 오류율은 67.4 % 및 40.9 %이며 위에서 설명한 넷에 의해 달성되지만 마지막 풀링 레이어 위에 추가로 여섯 번째 컨볼루션 레이어가 있습니다. 이 데이터 세트에서 가장 잘 출판 된 결과는 78.1 %와 60.9 %입니다.

* 7.1. 정성 평가

그림 3은 네트워크의 두 개의 데이터 연결 계층에서 학습 한 컨볼루션 커널을 보여줍니다. 네트워크는 다양한 주파수 및 방향 선택성 커널뿐만 아니라 다양한 색 얼룩을 배웠습니다. 섹션 4.5에 설명 된 제한된 연결성의 결과로 두 GPU가 전시 한 전문화에 주목하십시오. GPU 1의 커널은 색상에 영향을받지 않지만 GPU 2의 커널은 색상에 따라 크게 다릅니다. 이러한 종류의 특수화는 모든 실행 중에 발생하며 특정 임의의 가중치 초기화 (GPU 번호 재 지정)와는 독립적입니다.

그림 4의 왼쪽 패널에서 우리는 네트워크가 8 개의 테스트 이미지에서 상위 5 가지 예측을 계산하여 얻은 것을 질적으로 평가합니다. 왼쪽 상단의 진드기와 같은 중심에서 벗어난 물체도 그물에 의해 인식 될 수 있습니다. 상위 5 개 레이블의 대부분은 합리적인 것처럼 보입니다. 예를 들어 다른 유형의 고양이 만 표범에 대한 그럴싸한 레이블로 간주됩니다. 어떤 경우에는 (그릴, 체리) 사진의 의도 된 초점에 대한 진정한 모호함이 있습니다.

네트워크의 시각적 지식을 조사하는 또 다른 방법은 마지막 4096 차원 숨겨진 계층에서 이미지에 의해 유도 된 기능 활성화를 고려하는 것입니다. 두 이미지가 유클리드 분리 (Euclidean separation)가 작은 특징 활성화 벡터를 생성한다면, 신경망의 상위 레벨이 그것들을 유사하다고 생각할 수 있습니다. 그림 4는 테스트 세트의 다섯 이미지와이 측정에 따라 각각에 가장 유사한 훈련 세트의 여섯 이미지를 보여줍니다. 픽셀 수준에서 검색된 학습 이미지는 일반적으로 L2에서 첫 번째 열의 쿼리 이미지와 가까이 있지 않습니다. 예를 들어, 검색된 개와 코끼리는 다양한 포즈로 나타납니다. 우리는 보충 자료에 더 많은 테스트 이미지에 대한 결과를 제시합니다.

4096 차원의 실수 벡터 두 개 사이의 유클리드 거리를 사용하여 유사성을 계산하는 것은 비효율적이지만이 벡터를 짧은 바이너리 코드로 압축하도록 자동 엔코더를 교육하면 효율적으로 만들 수 있습니다. 이것은 이미지 라벨을 사용하지 않으므로 유사한 의미의 패턴을 가진 이미지를 검색하는 경향이있는 원시 픽셀에 자동 인코더를 적용하는 것보다 훨씬 더 나은 이미지 검색 방법을 생성해야합니다.

맨 위로


8. 토론
우리의 결과는 크고 깊은 CNN이 순전히 감독 된 학습을 사용하여 매우 어려운 데이터 세트에서 기록적인 결과를 달성 할 수 있음을 보여줍니다. 단일 컨볼 루션 계층이 제거되면 우리 네트워크의 성능이 저하됩니다. 예를 들어, 중간 계층 중 하나를 제거하면 네트워크의 최상위 1 성능에 대해 약 2 %의 손실이 발생합니다. 깊이는 실제로 결과를 달성하는 데 중요합니다.

실험을 단순화하기 위해, 특히 우리가 라벨 데이터의 양을 증가시키지 않으면 서 네트워크의 크기를 크게 늘릴 수있는 충분한 계산 능력을 얻는다면 도움이 될 것으로 예상 되긴하지만 감독되지 않은 사전 훈련을 사용하지 않았습니다. 지금까지 우리의 네트워크는 더 커지고 길게 훈련되었으므로 우리의 결과는 향상되었지만 인간의 시각 체계의 지각 적 시간 경로와 일치시키기 위해서는 여전히 많은 진도가있다. 궁극적으로 우리는 시간 구조가 매우 유용한 정보를 제공하는 비디오 시퀀스에 매우 크고 깊은 컨볼 루션 그물을 사용하고자합니다. 즉 정적 이미지에서 누락되거나 덜 명확합니다.

맨 위로


9. 발문
SuperVision의 성공에 대한 컴퓨터 비전 커뮤니티의 반응은 인상적이었습니다. 향후 1 ~ 2 년 동안 이들은 깊은 신경 네트워크를 사용하기로 전환했으며, 현재 Google, Facebook, Microsoft, Baidu 및 기타 여러 회사에서 광범위하게 배포하고 있습니다. 2015 년에는 더 나은 하드웨어, 숨겨진 레이어 및 많은 기술적 진보로 인해 깊은 컨볼 루션 신경망의 오류율이 3 배 더 감소하여 정지 이미지의 인적 성능에 매우 가깝습니다. 이 혁명에 대한 크레딧은 CNN 기술 개발에 수년을 투자 한 개척자들에게 돌아 가야하지만, 필연적으로 부족한 성분은 FeiFei 등 7에 의해 제공되었으며, 최종적으로 보여줄만큼 큰 라벨 데이터 세트를 생산하는데 많은 노력을 기울였습니다 신경 네트워크가 실제로 할 수있는 것.